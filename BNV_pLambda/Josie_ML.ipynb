{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bb1df9-3427-4b87-928b-5318f0e0d365",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Bellis's Lecture\n",
    "\n",
    "https://colab.research.google.com/drive/12LHs9cL8-gXKr_ypaNfnwaO9bLF3I9tQ?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c16eb-8bf4-4f99-b5ad-4bc3a7d64f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "from hist import Hist\n",
    "\n",
    "import babar_analysis_tools as bat\n",
    "from analysis_variables import *\n",
    "import myPIDselector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbdf0cf-7892-426b-9805-8bb0b6fe019d",
   "metadata": {},
   "outputs": [],
   "source": [
    "start= time.time()\n",
    "\n",
    "## My laptop\n",
    "topdir= \"/Users/josieswann/BaBar_analyses/BNV_pLambda/\"\n",
    "\n",
    "## Bellis computer\n",
    "#topdir= \"/home/bellis/babar_data/bnv_plambda\"\n",
    "\n",
    "\n",
    "filename= f\"{topdir}/Background_and_signal_SP_modes_Only_Run_1.parquet\"\n",
    "#filename= f\"{topdir}/Background_and_signal_SP_modes_All_runs.parquet\" ## this won't run on mine \n",
    "\n",
    "data= ak.from_parquet(filename)\n",
    "\n",
    "print(f\"Took {time.time()-start} seconds\")\n",
    "\n",
    "IS_MC= True\n",
    "\n",
    "#Collision data \n",
    "\n",
    "#filename = f'{topdir}/Background_SP_modes_Only_Run_1.parquet'\n",
    "filename = f'{topdir}/Data_Only_Run_1_BLINDED.parquet'\n",
    "#filename = f'{topdir}/Data_All_runs_BLINDED.parquet'\n",
    "#filename = f'{topdir}/Data_All_runs_BLINDED.parquet'\n",
    "\n",
    "start= time.time()\n",
    "data_collision= ak.from_parquet(filename)\n",
    "\n",
    "print(f\"took {time.time()-start} seconds\")\n",
    "\n",
    "print(type(data_collision))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a340dd1f-f80f-4b99-8ec1-319e8f14aae1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cross section info - scaling values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e50eef6-c228-461f-95f2-87733e88b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_information= pd.read_csv(\"dataset_statistics.csv\")\n",
    "cs_data= pd.read_csv(\"SP_cross_sections_and_labels.csv\")\n",
    "\n",
    "no_notes= cs_data.drop([\"Uncertainty\",\"Note: cross sections found at https://babar-wiki.heprc.uvic.ca/bbr_wiki/index.php/Physics/Cross_sections,_luminosities,_and_other_vital_stats\"], axis= 1)\n",
    "no_notes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ddfbbf8-41dd-429e-9c9e-eca6fef1735f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## SP info and Region Defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca986e8-fbf3-47ff-ae05-b97f672c7ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp= data[\"spmode\"]\n",
    "\n",
    "splist= np.unique(sp.to_list())\n",
    "splist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82874330-32c1-4d3d-93b3-0d53e082c0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4707a7e-16b8-4d76-add4-de7f9c7e9c2e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Tag Side B (ask about this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47fd231-1381-47e6-8287-1ebc44a5f4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "bat.fill_new_entry_with_tag_side_B(data)\n",
    "data[\"BtagSideMes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3c5a17-07c5-450d-995c-b210b051f1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hists= bat.create_empty_histograms(hist_defs)\n",
    "\n",
    "bkg_spmodes= [\"998\",\"1005\",\"3981\",\"1235\",\"1237\"]\n",
    "sig_spmodes= [\"-999\"]\n",
    "\n",
    "spmodes= bkg_spmodes+sig_spmodes\n",
    "\n",
    "weights= {}\n",
    "for sp in spmodes: \n",
    "    weights[sp]= bat.scaling_value(int(sp),dataset_information=dataset_information, cs_data= cs_data, plot= False, verbose= False)\n",
    "    #weights[sp]=1\n",
    "\n",
    "weights[\"-999\"]= 1000 #scales signal higher \n",
    "weights[\"0\"]= 1 #idk what this is for;;; ASK\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfc4416-49cc-4bbf-909a-37826cc7ee28",
   "metadata": {},
   "source": [
    "## Making the masks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee1094-55d8-4804-b9e9-527db5f12576",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcuts= bat.get_final_masks(data, region_definitions= region_definitions)\n",
    "\n",
    "print([dcuts.keys()])\n",
    "print()\n",
    "\n",
    "for key in dcuts.keys():\n",
    "    print(f'{key:3d} {dcuts[key][\"name\"]}')\n",
    "\n",
    "dcuts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a306ed7e-db14-4732-8b89-3837697eb59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask_event= dcuts[1][\"event\"]\n",
    "#mask_event= dcuts[2][\"event\"]\n",
    "mask_event= dcuts[3][\"event\"]\n",
    "#mask_event= dcuts[4][\"event\"] ## individual cuts\n",
    "#mask_event= dcuts[-1][\"event\"] ## all cuts\n",
    "\n",
    "#mask_event= dcuts[2][\"event\"] & dcuts[3][\"event\"] & dcuts[4][\"event\"] ## combo of cuts\n",
    "\n",
    "### ASK WHAT THESE MEAN\n",
    "tag= \"EARLY_CUT\"\n",
    "#tag= \"FINAL_CUTS\"\n",
    "\n",
    "mask= mask_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95e3755-b890-4ed9-a3e6-23fe36bc2cff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b91175-0700-447c-be56-9c88a8b548b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "          'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "          'R2', 'R2All', \\\n",
    "          'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "          'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "          'BThrustROE']\n",
    "\n",
    "ak_array_type= type(data[\"spmode\"])\n",
    "\n",
    "df_dict={}\n",
    "for var in subset: \n",
    "    x= data[mask][var] ##in each event, cut on the above cuts and pull out the info from each of the variables listed above\n",
    "    if type(x[0]) == ak_array_type:\n",
    "        x= ak.flatten(data[mask][var])\n",
    "    df_dict[var] = x\n",
    "\n",
    "df_out= pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "outfilename= f\"output_variables_{tag}.parquet\"\n",
    "df_out.to_parquet(outfilename)\n",
    "\n",
    "df= df_out\n",
    "\n",
    "df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98cecef8-56b4-4015-b819-e0d1a66ff786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"spmode\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a8d484-f18b-4639-937d-f1da3134b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa652a5-2439-4a69-9d1e-6313bc93fe07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6e84d4-94c8-4e50-9677-8e448cb331ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter= df[\"spmode\"]== \"-999\"\n",
    "\n",
    "g= sns.PairGrid(df[filter].sample(500), vars= [\"BpostFitMes\",\"BpostFitDeltaE\"], hue= \"spmode\")\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760fc35a-17b8-42d7-adf7-bd0e2e1cbadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns= df.columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b703c3-1e5e-470e-b501-20d03e13af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df['spmode'] != '-999'\n",
    "\n",
    "#g = sns.PairGrid(df[filter].sample(500), vars=['BpostFitMes', 'BpostFitDeltaE'], hue='spmode')\n",
    "g = sns.PairGrid(df[filter].sample(50), vars=columns[1:6], hue='spmode')\n",
    "\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad67aeaa-3b40-438d-bad8-996608f5b73d",
   "metadata": {},
   "source": [
    "## Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2e28d7-94f0-46f3-b6cb-8018dbbcd3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c623ab4-ac67-4691-a697-b1f9f6bd87f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names= columns[1:] ##exclude spmode\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0597eb-e2da-4246-923f-c6567a432d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(\"spmode\").count()[\"R2\"] ## R2 doesn't matter we just want to see how many of each sp mode are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932dc955-d56a-41fb-a80b-ec75ee4055f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sig= df[\"spmode\"]== \"-999\"\n",
    "filter_bkg= df[\"spmode\"]== \"998\"\n",
    "\n",
    "df_sig= df[filter_sig].dropna().sample(6000)\n",
    "df_bkg= df[filter_bkg].dropna().sample(6000)\n",
    "\n",
    "\n",
    "df_ML= pd.concat([df_sig,df_bkg])\n",
    "\n",
    "x= df_ML.drop(columns= [\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\"BtagSideMes\"])\n",
    "\n",
    "y=df_ML[\"spmode\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09b05bf-2772-4075-ae0a-2dd745d1b84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names= x.columns ##disc vars\n",
    "labels= y.unique() ##diff sp modes\n",
    "\n",
    "print(\"Training features:\")\n",
    "print(feature_names)\n",
    "print()\n",
    "\n",
    "print(\"Labels (Outcome):\")\n",
    "print(labels)\n",
    "print()\n",
    "\n",
    "print(\"The dataset (x) is the numbers without column names---\")\n",
    "print(\"The variable y is truth info about the data (signal or bkg)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375dee3-03e5-414d-befa-005c7ea671df",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.4, random_state= 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "444fe32e-67c1-478b-a4ea-3b633f1ae824",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1182bc97-427b-4c7a-97e9-036e3e0c8f3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b05702-118b-4cae-b1e2-d0c52e188101",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5f5f0-027f-4e2b-ad0a-23e2f7ede3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_train[y_train=='-999']))\n",
    "print(len(y_train[y_train=='998']))\n",
    "\n",
    "## This should be about half and half since we used the same amount of data for each case (sig and bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dd4bb0-cfb6-4f41-9046-06091cd69061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Neural Network Classifier\n",
    "model = MLPClassifier(max_iter= 300, random_state= 3, activation= \"relu\", solver= \"adam\") #n_iter_no_change= 15)\n",
    "\n",
    "# Training the model on the training data and labels\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068c59da-4cde-4964-ae2b-5a783d8127c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model i.e. predicting the labels of the test data.\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluating the results of the model\n",
    "accuracy = accuracy_score(y_test,y_pred)*100 ### returns the fraction of correctly classified samples \n",
    "confusion_mat = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13acce5d-2f7d-48cf-a890-99444c32831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for Neural Network is:\",accuracy)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_mat)\n",
    "\n",
    "tot_correct= confusion_mat[1][1] + confusion_mat[0][0]\n",
    "tot_wrong= confusion_mat[1][0] + confusion_mat[0][1]\n",
    "\n",
    "#print(tot_correct/(tot_correct+tot_wrong))\n",
    "\n",
    "## The accuracy score is the total number classified correctly over the total number of classifications \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404bd20f-a9b7-4893-8076-fbe5fd365219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a dataframe\n",
    "matrix_df = pd.DataFrame(confusion_mat)\n",
    "\n",
    "# Plot the result\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "\n",
    "#labels = df['target_names'].tolist()\n",
    "#labels = ['998', '-999'] # NEED TO FIX THIS SO IT IS NOT HARDCODED\n",
    "\n",
    "# Formatting details here\n",
    "# Set axis titles\n",
    "ax.set_title('Confusion Matrix - MLP')\n",
    "ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "ax.set_yticklabels(labels, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc6aa87-a1a7-499b-baa6-75bb4bfc0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the predictions for the training and testing samples\n",
    "\n",
    "decisions = []\n",
    "for X, y in ((x_train, y_train), (x_test, y_test)):\n",
    "\n",
    "  # Use the outcome to select the truth information (>0.5 or <0.5)\n",
    "  d1 = model.predict_proba(X[y == '998'])[:, 1]\n",
    "  d2 = model.predict_proba(X[y == '-999'])[:, 1]\n",
    "  decisions += [d1, d2]\n",
    "\n",
    "# Use this for the histogram ranges\n",
    "low = min(np.min(d) for d in decisions)\n",
    "high = max(np.max(d) for d in decisions)\n",
    "low_high = (low, high)\n",
    "\n",
    "\n",
    "print(decisions)\n",
    "# Make a plot of the training sample predictions\n",
    "bins = 50\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(decisions[0],\n",
    "          color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Bkg (train)')\n",
    "plt.hist(decisions[1],\n",
    "          color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Sig (train)')\n",
    "\n",
    "\n",
    "# Make a plot with error bars for the testing samples\n",
    "hists, bins = np.histogram(decisions[2],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hists)\n",
    "err = np.sqrt(hists * scale) / scale\n",
    "\n",
    "width = (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "plt.errorbar(center, hists, yerr=err, fmt='o', c='r', label='Bkg (test)')\n",
    "\n",
    "hists, bins = np.histogram(decisions[3],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hists)\n",
    "err = np.sqrt(hists * scale) / scale\n",
    "\n",
    "plt.errorbar(center, hists, yerr=err, fmt='o', c='b', label='Sig (test)')\n",
    "\n",
    "plt.xlabel(\"Classifer output\")\n",
    "plt.ylabel(\"Arbitrary units\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b03aaaf-6f82-48c1-b371-303d6c5665fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decisions\n",
    "#y_test\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "sig_bkg = np.ones_like(y_test, dtype=int)\n",
    "sig_bkg[y_test=='-999'] = 0\n",
    "\n",
    "print(sig_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e0d2a5-c01b-45f8-90fa-51f373b6fd29",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and area under the curve\n",
    "fpr, tpr, thresholds = roc_curve(sig_bkg, decisions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % (roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715935cf-3a72-4a23-8890-bd8ff524458f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5054558a-18d1-41fe-96f6-99693bcfd641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = x_test.copy()\n",
    "print(y_test.values)\n",
    "df_plot['spmode'] = y_test.values\n",
    "\n",
    "df_plot\n",
    "\n",
    "print(len(x_test), len(y_test))\n",
    "print(len(df_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799a09e-a01f-498b-ab23-908bf6762886",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 4)    # axes is 2d array (3x3)\n",
    "axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "for ax, col in zip(axes, df_plot.columns):\n",
    "  sns.histplot(df_plot, x=col, ax = ax, hue='spmode', stat='density', common_norm=False)\n",
    "  ax.set_title(col)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1558e8-42f4-4b45-a1a2-b993d7a9865b",
   "metadata": {},
   "source": [
    "# Bellis suggestions for next step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc61cd53-0c3f-4b0a-a953-82ac85fdeecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_event= dcuts[-1][\"event\"] ## all cuts\n",
    "\n",
    "tag= \"FINAL_CUTS\"\n",
    "\n",
    "mask= mask_event\n",
    "\n",
    "subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "          'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "          'R2', 'R2All', \\\n",
    "          'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "          'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "          'BThrustROE']\n",
    "\n",
    "ak_array_type= type(data[\"spmode\"])\n",
    "\n",
    "df_dict={}\n",
    "for var in subset: \n",
    "    x= data[mask][var] ##in each event, cut on the above cuts and pull out the info from each of the variables listed above\n",
    "    if type(x[0]) == ak_array_type:\n",
    "        x= ak.flatten(data[mask][var])\n",
    "    df_dict[var] = x\n",
    "\n",
    "df_final= pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "outfilename= f\"output_variables_{tag}.parquet\"\n",
    "df_final.to_parquet(outfilename)\n",
    "\n",
    "df_final\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6433834e-ce85-49b7-ad73-a9712330af8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.groupby(\"spmode\").count()[\"R2\"] ## R2 doesn't matter we just want to see how many of each sp mode are there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62668260-6ea4-4df6-b109-cdb7ed285aff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_final_sp = df_final['spmode']=='998'\n",
    "x_final_bkg= df_final[mask_final_sp].drop(columns= [\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\"BtagSideMes\"]).dropna()\n",
    "\n",
    "mask_final_sp = df_final['spmode']=='-999'\n",
    "x_final_sig= df_final[mask_final_sp].drop(columns= [\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\"BtagSideMes\"]).dropna()\n",
    "\n",
    "\n",
    "proba_final_bkg = model.predict_proba(x_final_bkg)\n",
    "proba_final_sig = model.predict_proba(x_final_sig)\n",
    "\n",
    "\n",
    "proba_final_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ced6000-3730-49e1-875b-a33d9bc3eb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(proba_final_bkg[:,0],bins=20, range=(0,1), alpha=0.5, label='bkg', density=True)\n",
    "plt.hist(proba_final_sig[:,0],bins=20, range=(0,1), alpha=0.5, label='sig', density=True)\n",
    "\n",
    "\n",
    "#plt.hist(proba_final[:,1],bins=10, range=(0,1), alpha=0.5)\n",
    "\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cef0437-feb0-4963-949e-0e6266c0ed05",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7ba6ca3-b9d4-43bd-88ef-df85e5d580c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sig= df[\"spmode\"]== \"-999\"\n",
    "filter_bkg= df[\"spmode\"]== \"998\"\n",
    "\n",
    "df_sig= df[filter_sig].dropna().sample(3000)\n",
    "df_bkg= df[filter_bkg].dropna().sample(3000)\n",
    "\n",
    "\n",
    "df_ML= pd.concat([df_sig,df_bkg])\n",
    "\n",
    "x= df_ML.drop(columns= [\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\n",
    "                       ])\n",
    "\n",
    "y=df_ML[\"spmode\"]\n",
    "\n",
    "feature_names= x.columns ##disc vars\n",
    "labels= y.unique() ##diff sp modes\n",
    "\n",
    "print(\"Training features:\")\n",
    "print(feature_names)\n",
    "print()\n",
    "\n",
    "print(\"Labels (Outcome):\")\n",
    "print(labels)\n",
    "print()\n",
    "\n",
    "print(\"The dataset (x) is the numbers without column names---\")\n",
    "print(\"The variable y is truth info about the data (signal or bkg)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3b2e2-15d1-4ddd-b719-f24ed28cd3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.06, random_state= 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170f9480-1323-4e82-aa0f-f40ad838d0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Neural Network Classifier\n",
    "model = MLPClassifier(max_iter= 50, random_state= 3, activation= \"identity\", solver= \"adam\", hidden_layer_sizes=2) #n_iter_no_change= 15)\n",
    "\n",
    "# Training the model on the training data and labels\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07132722-60cd-42ca-a2d0-2c5fbc95eca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model i.e. predicting the labels of the test data.\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluating the results of the model\n",
    "accuracy = accuracy_score(y_test,y_pred)*100 ### returns the fraction of correctly classified samples \n",
    "confusion_mat = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90c11d4-b069-4663-9cb9-312c9af2f1e9",
   "metadata": {},
   "source": [
    "# Collision data stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97fe2990-1fca-444f-b035-9f8a7c20065b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_collision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd45a3d-8325-4d4a-986d-ccd64a88d692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This seems to not work\n",
    "#BPFM= data_collision[\"BpostFitMes\"]\n",
    "#BPFDE= data_collision[\"BpostFitDeltaE\"]\n",
    "\n",
    "#############################################################\n",
    "# Bellis edits\n",
    "#############################################################\n",
    "# Can we read in the Monte Carlo data?\n",
    "BPFM= data[\"BpostFitMes\"]\n",
    "BPFDE= data[\"BpostFitDeltaE\"]\n",
    "\n",
    "# Can we plot the Monte Carlo data if we flatten it??\n",
    "BPFM_sp= ak.flatten(data[\"BpostFitMes\"])\n",
    "BPFDE_sp= ak.flatten(data[\"BpostFitDeltaE\"])\n",
    "\n",
    "# Can we plot the collision data if we flatten it??\n",
    "BPFM_coll= ak.flatten(data_collision[\"BpostFitMes\"])\n",
    "BPFDE_coll= ak.flatten(data_collision[\"BpostFitDeltaE\"])\n",
    "#############################################################\n",
    "\n",
    "print(type(BPFM_coll))\n",
    "\n",
    "plt.figure(figsize= (16,8))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.title(\"B post fit MES\")\n",
    "plt.hist(BPFM_coll, bins= 100, range= (3.5,5.5));\n",
    "plt.xlabel(\"Mass [GeV/c^2]\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.title(\"B post fit Delta E\")\n",
    "plt.hist(BPFDE_coll, bins= 100, range=(-1,1));\n",
    "plt.xlabel(\"E [GeV]\")\n",
    "\n",
    "#print(type(BPFM))\n",
    "\n",
    "#plt.scatter(BPFM_coll, BPFDE_coll)\n",
    "\n",
    "print(BPFM_coll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "086aaa4b-9b8d-4f1c-8854-14746afdac9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(BPFM)\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bc1c84-7209-4a2c-8ea8-159e798e19d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bat.plot_mes_vs_DeltaE(BPFM_coll, BPFDE_coll)\n",
    "\n",
    "\n",
    "import hist as hist\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4729222-df15-4deb-b78c-1a6c175f6d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hist import Hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfae5529-aca7-41e5-b203-4a7de5234a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "h= Hist(\n",
    "    hist.axis.Regular(400,3,7,name= \"BPFM\", label= \"mass [GeV/c^2]\", flow= True),\n",
    "    hist.axis.Regular(350,-.75,1,name= \"BPFMDE\", label= \"energy [GeV]\", flow= True),\n",
    ")\n",
    "\n",
    "# normal fill\n",
    "h.fill(BPFM_coll, BPFDE_coll)\n",
    "\n",
    "h.plot2d_full(\n",
    "    main_cmap=\"coolwarm\",\n",
    "    top_ls=\"--\",\n",
    "    top_color=\"orange\",\n",
    "    top_lw=2,\n",
    "    side_ls=\":\",\n",
    "    side_lw=2,\n",
    "    side_color=\"steelblue\",\n",
    ")\n",
    "\n",
    "plt.xlim(5.1,5.3)\n",
    "plt.ylim(-.5,.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8ccfed-3080-4a16-a26b-b22adf00a00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcuts= bat.get_final_masks(data_collision, region_definitions= region_definitions)\n",
    "\n",
    "print([dcuts.keys()])\n",
    "print()\n",
    "\n",
    "for key in dcuts.keys():\n",
    "    print(f'{key:3d} {dcuts[key][\"name\"]}')\n",
    "\n",
    "dcuts[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ddf0d8b-630c-4e83-9c43-fb46e07a8dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "          'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "          'R2', 'R2All',\\\n",
    "          'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "          'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "          'BThrustROE']\n",
    "\n",
    "ak_array_type= type(data_collision[\"spmode\"])\n",
    "\n",
    "mask_event= dcuts[-1][\"event\"] ## all cuts\n",
    "mask= mask_event\n",
    "\n",
    "df_dict={}\n",
    "for var in subset: \n",
    "    x= data_collision[mask][var] ##in each event, cut on the above cuts and pull out the info from each of the variables listed above\n",
    "    if type(x[0]) == ak_array_type:\n",
    "        x= ak.flatten(data_collision[mask][var])\n",
    "    df_dict[var] = x\n",
    "\n",
    "df_out= pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "outfilename= f\"output_variables_{tag}.parquet\"\n",
    "df_out.to_parquet(outfilename)\n",
    "\n",
    "df= df_out\n",
    "\n",
    "df_out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6683e6-1028-4e27-a16d-6c7f306faa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import hist as hist\n",
    "from hist import Hist\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "\n",
    "h= Hist(\n",
    "    hist.axis.Regular(400,3,7,name= \"BPFM\", label= \"mass [GeV/c^2]\", flow= True),\n",
    "    hist.axis.Regular(350,-.75,1,name= \"BPFMDE\", label= \"energy [GeV]\", flow= True),\n",
    ")\n",
    "\n",
    "# normal fill\n",
    "h.fill(df_out[\"BpostFitMes\"], df_out[\"BpostFitDeltaE\"])\n",
    "\n",
    "h.plot2d_full(\n",
    "    main_cmap=\"coolwarm\",\n",
    "    top_ls=\"--\",\n",
    "    top_color=\"orange\",\n",
    "    top_lw=2,\n",
    "    side_ls=\":\",\n",
    "    side_lw=2,\n",
    "    side_color=\"steelblue\",\n",
    ")\n",
    "\n",
    "plt.xlim(5.1,5.3)\n",
    "plt.ylim(-.5,.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f6452-946b-4d65-8151-42f9d02f2858",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test= df_out.drop(columns= [\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11a90ec4-82df-4dc0-bc97-cbf2d5b0f328",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(df_test)  #### Change x_test to the correct data from df_out\n",
    "y_test = \n",
    "# Evaluating the results of the model\n",
    "accuracy = accuracy_score(y_test,y_pred)*100 ### returns the fraction of correctly classified samples \n",
    "confusion_mat = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a235ca-92a1-45dc-a07e-c78a49f57434",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy for Neural Network is:\",accuracy)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_mat)\n",
    "\n",
    "tot_correct= confusion_mat[1][1] + confusion_mat[0][0]\n",
    "tot_wrong= confusion_mat[1][0] + confusion_mat[0][1]\n",
    "\n",
    "#print(tot_correct/(tot_correct+tot_wrong))\n",
    "\n",
    "## The accuracy score is the total number classified correctly over the total number of classifications \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6124268-1509-46cf-8905-e5e31eb6374c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a dataframe\n",
    "matrix_df = pd.DataFrame(confusion_mat)\n",
    "\n",
    "# Plot the result\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "\n",
    "#labels = df['target_names'].tolist()\n",
    "#labels = ['998', '-999'] # NEED TO FIX THIS SO IT IS NOT HARDCODED\n",
    "\n",
    "# Formatting details here\n",
    "# Set axis titles\n",
    "ax.set_title('Confusion Matrix - MLP')\n",
    "ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "ax.set_yticklabels(labels, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc74c18-09a0-4615-89a6-5da4db1d5e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the predictions for the training and testing samples\n",
    "\n",
    "decisions = []\n",
    "for X, y in ((x_train, y_train), (x_test, y_test)):\n",
    "\n",
    "  # Use the outcome to select the truth information (>0.5 or <0.5)\n",
    "  d1 = model.predict_proba(X[y == '998'])[:, 1]\n",
    "  d2 = model.predict_proba(X[y == '-999'])[:, 1]\n",
    "  decisions += [d1, d2]\n",
    "\n",
    "# Use this for the histogram ranges\n",
    "low = min(np.min(d) for d in decisions)\n",
    "high = max(np.max(d) for d in decisions)\n",
    "low_high = (low, high)\n",
    "\n",
    "\n",
    "print(decisions)\n",
    "# Make a plot of the training sample predictions\n",
    "bins = 50\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(decisions[0],\n",
    "          color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Bkg (train)')\n",
    "plt.hist(decisions[1],\n",
    "          color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Sig (train)')\n",
    "\n",
    "\n",
    "# Make a plot with error bars for the testing samples\n",
    "hists, bins = np.histogram(decisions[2],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hists)\n",
    "err = np.sqrt(hists * scale) / scale\n",
    "\n",
    "width = (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "plt.errorbar(center, hists, yerr=err, fmt='o', c='r', label='Bkg (test)')\n",
    "\n",
    "hists, bins = np.histogram(decisions[3],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hists)\n",
    "err = np.sqrt(hists * scale) / scale\n",
    "\n",
    "plt.errorbar(center, hists, yerr=err, fmt='o', c='b', label='Sig (test)')\n",
    "\n",
    "plt.xlabel(\"Classifer output\")\n",
    "plt.ylabel(\"Arbitrary units\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930cf84c-3546-4f83-9cc7-099e15520cea",
   "metadata": {},
   "source": [
    "# TRYING TO BIAS/OVERFIT/UNDERFIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cf836f7-a892-4dda-8488-e8d1cce75532",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy for Neural Network is: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_mat)\n",
    "\n",
    "tot_correct= confusion_mat[1][1] + confusion_mat[0][0]\n",
    "tot_wrong= confusion_mat[1][0] + confusion_mat[0][1]\n",
    "\n",
    "#print(tot_correct/(tot_correct+tot_wrong))\n",
    "\n",
    "## The accuracy score is the total number classified correctly over the total number of classifications \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c23ce7b-1e34-45fa-8a06-0ab3765b6f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a dataframe\n",
    "matrix_df = pd.DataFrame(confusion_mat)\n",
    "\n",
    "# Plot the result\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "\n",
    "#labels = df['target_names'].tolist()\n",
    "#labels = ['998', '-999'] # NEED TO FIX THIS SO IT IS NOT HARDCODED\n",
    "\n",
    "# Formatting details here\n",
    "# Set axis titles\n",
    "ax.set_title('Confusion Matrix - MLP')\n",
    "ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "ax.set_yticklabels(labels, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ca0c1-823d-4731-b800-6da21ddaf63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdde01-a8c5-4738-9c80-c6cd9b9c3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= svm.SVC(kernel=\"linear\", C=1, random_state=2).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2326926b-4cdc-428e-9551-919a7928a110",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CV score: {clf.score(x_test,y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140ff2c9-2070-4d44-8ee6-b492c6670833",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the predictions for the training and testing samples\n",
    "\n",
    "decisions = []\n",
    "for X, y in ((x_train, y_train), (x_test, y_test)):\n",
    "\n",
    "  # Use the outcome to select the truth information (>0.5 or <0.5)\n",
    "  d1 = model.predict_proba(X[y == '998'])[:, 1]\n",
    "  d2 = model.predict_proba(X[y == '-999'])[:, 1]\n",
    "  decisions += [d1, d2]\n",
    "\n",
    "# Use this for the histogram ranges\n",
    "low = min(np.min(d) for d in decisions)\n",
    "high = max(np.max(d) for d in decisions)\n",
    "low_high = (low, high)\n",
    "\n",
    "# Make a plot of the training sample predictions\n",
    "bins = 50\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(decisions[0],\n",
    "          color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Bkg (train)')\n",
    "plt.hist(decisions[1],\n",
    "          color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Sig (train)')\n",
    "\n",
    "\n",
    "# Make a plot with error bars for the testing samples\n",
    "hist, bins = np.histogram(decisions[2],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hist)\n",
    "err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "width = (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "plt.errorbar(center, hist, yerr=err, fmt='o', c='r', label='Bkg (test)')\n",
    "\n",
    "hist, bins = np.histogram(decisions[3],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hist)\n",
    "err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "plt.errorbar(center, hist, yerr=err, fmt='o', c='b', label='Sig (test)')\n",
    "\n",
    "plt.xlabel(\"Classifer output\")\n",
    "plt.ylabel(\"Arbitrary units\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad78c8e0-2cc0-465a-8fbd-4d99f39ec248",
   "metadata": {},
   "source": [
    "## BIAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fac65d-cacf-4f4d-a52c-05ed31efc1d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3899e467-4b23-460a-847f-a8962f9900a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_sig= df[\"spmode\"]== \"-999\"\n",
    "filter_bkg= df[\"spmode\"]== \"998\"\n",
    "\n",
    "df_sig= df[filter_sig].dropna().sample(3000)\n",
    "df_bkg= df[filter_bkg].dropna().sample(3000)\n",
    "\n",
    "\n",
    "df_ML= pd.concat([df_sig,df_bkg])\n",
    "\n",
    "x= df_ML.drop(columns= [\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\\\n",
    "                       'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll',\\\n",
    "                        'sphericityAll', 'BCosSphr', 'BCosThetaT', 'BCosThrust', \\\n",
    "                        'BLegendreP2','BR2ROE', 'BSphrROE', 'BThrustROE',\"R2\",\\\n",
    "                        \"BtagSideMes\", \"BSphr\"\n",
    "                       ])\n",
    "\n",
    "y=df_ML[\"spmode\"]\n",
    "\n",
    "feature_names= x.columns ##disc vars\n",
    "labels= y.unique() ##diff sp modes\n",
    "\n",
    "print(\"Training features:\")\n",
    "print(feature_names)\n",
    "print()\n",
    "\n",
    "print(\"Labels (Outcome):\")\n",
    "print(labels)\n",
    "print()\n",
    "\n",
    "print(\"The dataset (x) is the numbers without column names---\")\n",
    "print(\"The variable y is truth info about the data (signal or bkg)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780d1c7-07a9-4769-992f-12f7c3e3fcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= 0.06, random_state= 4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c314daf4-b8b3-42ba-ae9b-bda7e7eed671",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Neural Network Classifier\n",
    "model = MLPClassifier(max_iter= 50, random_state= 3, activation= \"identity\", solver= \"adam\", hidden_layer_sizes=3) #n_iter_no_change= 15)\n",
    "\n",
    "# Training the model on the training data and labels\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace45cb7-b6c1-40e9-bc3e-dad2d758eb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model i.e. predicting the labels of the test data.\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Evaluating the results of the model\n",
    "accuracy = accuracy_score(y_test,y_pred)*100 ### returns the fraction of correctly classified samples \n",
    "confusion_mat = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7684172-cda2-4185-b2c8-e6c08c06035c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Accuracy for Neural Network is: {accuracy:.2f}\")\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_mat)\n",
    "\n",
    "tot_correct= confusion_mat[1][1] + confusion_mat[0][0]\n",
    "tot_wrong= confusion_mat[1][0] + confusion_mat[0][1]\n",
    "\n",
    "#print(tot_correct/(tot_correct+tot_wrong))\n",
    "\n",
    "## The accuracy score is the total number classified correctly over the total number of classifications \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d29942-2bbc-4fc5-a9b3-81f2cca2d899",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a dataframe\n",
    "matrix_df = pd.DataFrame(confusion_mat)\n",
    "\n",
    "# Plot the result\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "\n",
    "#labels = df['target_names'].tolist()\n",
    "#labels = ['998', '-999'] # NEED TO FIX THIS SO IT IS NOT HARDCODED\n",
    "\n",
    "# Formatting details here\n",
    "# Set axis titles\n",
    "ax.set_title('Confusion Matrix - MLP')\n",
    "ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "ax.set_yticklabels(labels, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca3954-1b66-4109-93cf-a00940809ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf= svm.SVC(kernel=\"linear\", C=1, random_state=2).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70b613a-0252-41de-8fcb-21b6f31dc7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"CV score: {clf.score(x_test,y_test):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1401c7-afe2-49d6-bfae-1f9571dbef26",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the predictions for the training and testing samples\n",
    "\n",
    "decisions = []\n",
    "for X, y in ((x_train, y_train), (x_test, y_test)):\n",
    "\n",
    "  # Use the outcome to select the truth information (>0.5 or <0.5)\n",
    "  d1 = model.predict_proba(X[y == '998'])[:, 1]\n",
    "  d2 = model.predict_proba(X[y == '-999'])[:, 1]\n",
    "  decisions += [d1, d2]\n",
    "\n",
    "# Use this for the histogram ranges\n",
    "low = min(np.min(d) for d in decisions)\n",
    "high = max(np.max(d) for d in decisions)\n",
    "low_high = (low, high)\n",
    "\n",
    "# Make a plot of the training sample predictions\n",
    "bins = 50\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(decisions[0],\n",
    "          color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Bkg (train)')\n",
    "plt.hist(decisions[1],\n",
    "          color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Sig (train)')\n",
    "\n",
    "\n",
    "# Make a plot with error bars for the testing samples\n",
    "hist, bins = np.histogram(decisions[2],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hist)\n",
    "err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "width = (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "plt.errorbar(center, hist, yerr=err, fmt='o', c='r', label='Bkg (test)')\n",
    "\n",
    "hist, bins = np.histogram(decisions[3],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hist)\n",
    "err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "plt.errorbar(center, hist, yerr=err, fmt='o', c='b', label='Sig (test)')\n",
    "\n",
    "plt.xlabel(\"Classifer output\")\n",
    "plt.ylabel(\"Arbitrary units\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be07a78-9c71-4465-b31e-a472f7692379",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25b64f50-aeb5-421b-9c3b-4ee58006b23d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49a588a0-ff06-4af8-a64e-ad6aae226076",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffacdb5-b2a9-4408-9894-7e763c50e870",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c2722e-c493-4601-a8c5-c337e7894b27",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3678eb52-c44e-4f02-9f07-decf82f40a25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e1c34f-4928-40b4-8c41-b21bbc82e281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d2daff-09fa-4a72-8552-fe99e99bcc82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d0c1e1-d588-4056-b7b2-a66500e26a78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b10ecf34-fd82-4450-9cbb-c36d8fceadf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f537c040-b50e-4ddf-b3a2-796ea5701580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ff2072-38fd-442b-916f-7a783502f14a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
