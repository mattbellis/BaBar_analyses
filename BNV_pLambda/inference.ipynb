{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b886daa3-e834-4c6b-bf04-055b56f58155",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from hist import Hist\n",
    "\n",
    "import babar_analysis_tools as bat\n",
    "\n",
    "from analysis_variables import *\n",
    "\n",
    "import myPIDselector\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d08ec81-725f-4a78-8db6-d4142ce7d7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# At Siena\n",
    "#topdir = '/mnt/qnap/babar_data/bnv_plambda'\n",
    "\n",
    "##josie laptop \n",
    "#topdir = \"/Users/josieswann/Desktop/important documents\"\n",
    "\n",
    "# On Bellis' laptop\n",
    "#topdir = '/home/bellis/babar_data/bnv_plambda/'\n",
    "\n",
    "# At Bellis' home\n",
    "topdir = '/home/bellis/babar_data/bnv_plambda'\n",
    "\n",
    "# On Bellis' laptop\n",
    "#topdir = './'\n",
    "\n",
    "filename = f'{topdir}/Background_and_signal_SP_modes_Only_Run_1.parquet'\n",
    "#filename = f'{topdir}/Background_and_signal_SP_modes_All_runs.parquet'\n",
    "\n",
    "data = ak.from_parquet(filename)\n",
    "\n",
    "print(f\"Took {time.time() - start} s\")\n",
    "IS_MC=True\n",
    "\n",
    "\n",
    "#'''\n",
    "# Collision data\n",
    "#filename = f'{topdir}/Background_SP_modes_Only_Run_1.parquet'\n",
    "filename = f'{topdir}/Data_Only_Run_1_BLINDED.parquet'\n",
    "#filename = f'{topdir}/Data_All_runs_BLINDED.parquet'\n",
    "#filename = f'{topdir}/Data_All_runs_BLINDED.parquet'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "data_collision = ak.from_parquet(filename)\n",
    "#data_collision = ak.from_parquet(filename)\n",
    "\n",
    "print(f\"Took {time.time() - start} s\")\n",
    "\n",
    "print(type(data_collision))\n",
    "#'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4a4357-d104-4f85-b5d5-48075feb009e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### information about cross section --> what we'll use to calculate scaling values for histograms \n",
    "\n",
    "dataset_information = pd.read_csv(\"dataset_statistics.csv\")\n",
    "cs_data= pd.read_csv(\"SP_cross_sections_and_labels.csv\")\n",
    "\n",
    "no_notes= cs_data.drop([\"Uncertainty\",\"Note: cross sections found at https://babar-wiki.heprc.uvic.ca/bbr_wiki/index.php/Physics/Cross_sections,_luminosities,_and_other_vital_stats\"], axis= 1)\n",
    "no_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a50019-fe15-4dfb-b975-b85aa7f87743",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = data['spmode']\n",
    "\n",
    "np.unique(sp.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aab19c10-9cb5-4831-be8c-f0651ef15ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff01af16-099d-4a4e-8fcf-5c29d779f645",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bat.fill_new_entry_with_tag_side_B(data)\n",
    "#data['BtagSideMes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b435096-d9fb-4c5a-a522-e38d3cb13892",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our histograms\n",
    "all_hists = bat.create_empty_histograms(hist_defs)\n",
    "\n",
    "bkg_spmodes = ['998', '1005', '1235', '1237', '3981']\n",
    "sig_spmodes = ['-999']\n",
    "\n",
    "spmodes = bkg_spmodes + sig_spmodes\n",
    "\n",
    "weights = {}\n",
    "for sp in spmodes:\n",
    "    weights[sp] = bat.scaling_value(int(sp), dataset_information=dataset_information, cs_data=cs_data, plot=False, verbose=False)\n",
    "    #weights[sp] = 1\n",
    "\n",
    "### bat.scaling_value is in Babar_analysis_tools.py \n",
    "\n",
    "# Scale the signal higher\n",
    "weights['-999'] = 1000\n",
    "weights['0'] = 1\n",
    "\n",
    "print(weights)\n",
    "print()\n",
    "print(spmodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93669cef-73fb-4870-89a0-7d9f5d3aee8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to get the original duplicates mask for any other cuts we might generate outside the function\n",
    "dcuts = bat.get_final_masks(data, region_definitions=region_definitions)\n",
    "\n",
    "print([dcuts.keys()])\n",
    "print()\n",
    "\n",
    "for key in dcuts.keys():\n",
    "    print(f'{key:3d} {dcuts[key][\"name\"]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4db0279-7b84-465f-9331-afe522eb2e99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fea1a9-8e7e-4224-8740-2ec0322af2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# Make the masks\n",
    "#mask_event = dcuts[3]['event']\n",
    "#mask_event = dcuts[4]['event']\n",
    "mask_event = dcuts[1]['event']\n",
    "#mask_event = dcuts[-1]['event']\n",
    "#mask_event = dcuts[2]['event'] & dcuts[3]['event'] & dcuts[4]['event']\n",
    "\n",
    "spmode = '998'\n",
    "\n",
    "mask_sp = data['spmode']==spmode\n",
    "\n",
    "#mask = mask_event & mask_sp\n",
    "mask = mask_sp\n",
    "\n",
    "# Make the plot\n",
    "mes =    ak.flatten(data[mask]['BpostFitMes'])\n",
    "DeltaE = ak.flatten(data[mask]['BpostFitDeltaE'])\n",
    "\n",
    "bat.plot_mes_vs_DeltaE(mes, DeltaE, region_definitions=region_definitions, draw_signal_region=True)\n",
    "\n",
    "#print(len(mes),len(DeltaE))\n",
    "\n",
    "## Other HISTOGRAMS \n",
    "all_hists = bat.create_empty_histograms(hist_defs)\n",
    "\n",
    "x = ak.flatten(data[mask]['Lambda0_unc_Mass'])\n",
    "weight = weights[spmode]\n",
    "all_hists['Lambda0_unc_Mass'].fill(var=x, SP= spmode, cuts= f\"{0}\", weight= weight)\n",
    "\n",
    "plt.figure()\n",
    "all_hists['Lambda0_unc_Mass'].project('var').plot(histtype=\"fill\", color='red', label= spmode)\n",
    "all_hists['Lambda0_unc_Mass'].project('var').plot(histtype=\"step\", color='black')\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2b886d-eb54-44f3-a6c6-d547a1ee86a1",
   "metadata": {},
   "source": [
    "# pyhf\n",
    "\n",
    "https://pyhf.github.io/pyhf-tutorial/HelloWorld.html\n",
    "\n",
    "https://pyhf.github.io/pyhf-tutorial/IntroToHiFa.html\n",
    "\n",
    "\n",
    "## A one-bin example\n",
    "\n",
    "https://pyhf.readthedocs.io/en/v0.7.6/\n",
    "\n",
    "## Dummy 2D thing\n",
    "\n",
    "https://pyhf.readthedocs.io/en/v0.7.6/examples/notebooks/multiBinPois.html\n",
    "\n",
    "## 2D distributions\n",
    "\n",
    "https://stackoverflow.com/questions/66038864/2d-distributions-in-the-histfactory\n",
    "\n",
    "Maybe this thread?\n",
    "\n",
    "\n",
    "https://github.com/scikit-hep/pyhf/discussions/2070\n",
    "\n",
    "Use `ravel`\n",
    "\n",
    "Drawing on some work I did here\n",
    "\n",
    "https://colab.research.google.com/drive/1J4IQ8DDkKKQPxQH2A06l1Z350YlWqTL7?usp=sharing\n",
    "\n",
    "\n",
    "## My old stackoverflow question\n",
    "\n",
    "https://stackoverflow.com/questions/64257667/trying-to-put-together-a-teaching-example-with-pyhf\n",
    "\n",
    "## BELLE question that might be relevant\n",
    "\n",
    "Has some discussions about how 0-bins are handled.\n",
    "\n",
    "https://github.com/scikit-hep/pyhf/discussions/2070\n",
    "\n",
    "\n",
    "## Multiple backgrounds\n",
    "\n",
    "https://pyhf.readthedocs.io/en/v0.7.6/examples/notebooks/multichannel-coupled-histo.html\n",
    "\n",
    "## Toy simulations\n",
    "\n",
    "https://pyhf.readthedocs.io/en/v0.7.6/examples/notebooks/learn/TestStatistics.html\n",
    "\n",
    "## Raveling / unravel\n",
    "\n",
    "Return to original shape\n",
    "\n",
    "https://stackoverflow.com/questions/52046347/unravel-1d-list-back-to-3d-array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de0c60-aba1-4dd7-bee0-25617b0a36e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyhf\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "import logging\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pyhf\n",
    "from pyhf import Model, optimizer\n",
    "from pyhf.simplemodels import uncorrelated_background\n",
    "from pyhf.contrib.viz import brazil\n",
    "\n",
    "from scipy.interpolate import griddata\n",
    "import scrapbook as sb\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3005b2e1-b109-433e-b061-bdf503eb5cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_plot_dm(mu=1, bins=[], observed=[], background=[], signal=[]):\n",
    "    #bins = [5, 55, 550]\n",
    "    #observed = [60, 43, 40]\n",
    "    #background = [58.0, 42.5, 36.0]\n",
    "    #signal = [i * mu for i in [2, 4, 3]]\n",
    "\n",
    "    print(f\"signal: {signal}\")\n",
    "    print(f\"background: {background}\")\n",
    "    print(f\"observed: {observed}\\n\")\n",
    "\n",
    "    width = bins[1] - bins[0]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(bins, background, width=width, label=r\"Background\", edgecolor=\"red\", alpha=0.5)\n",
    "    ax.bar(\n",
    "        bins,\n",
    "        signal,\n",
    "        width=width,\n",
    "        label=r\"Signal\",\n",
    "        edgecolor=\"blue\",\n",
    "        bottom=background,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.scatter(bins, observed, color=\"black\", label=\"Observed\")\n",
    "    #ax.set_ylim(0, 6)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(r\"$p_T$ [GeV/c]\", fontsize=12)\n",
    "    ax.set_ylabel(\"Count\", fontsize=12);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f1a48f-ce01-4c45-afcf-69447f381465",
   "metadata": {},
   "source": [
    "# Fitting BaBar data\n",
    "\n",
    "### References\n",
    "\n",
    "https://pyhf.github.io/pyhf-tutorial/HelloWorld.html\n",
    "\n",
    "This documentation mentions how the uncertainties are set for 0 bins\n",
    "\n",
    "https://pyhf.readthedocs.io/en/v0.7.6/likelihood.html#luminosity-lumi\n",
    "\n",
    "\"For bins in the model where:\n",
    "\n",
    "the samples nominal expected rate is zero, or\n",
    "\n",
    "the scale factor is zero.\n",
    "\n",
    "nuisance parameters will be allocated, but will be fixed to 1 in the calculation (as staterror is a multiplicative modifier this results in multiplying by 1).\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac1b27-0b4d-4d55-ab2e-69cba222a1fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet('inference_region_counts_SP998_FINAL_CUT.parquet')\n",
    "Nbkg = df['N'].values\n",
    "\n",
    "df = pd.read_parquet('inference_region_counts_SIGNAL_FINAL_CUT.parquet')\n",
    "Nsig = df['N'].values\n",
    "\n",
    "df = pd.read_parquet('inference_region_counts_COLLISION_DATA_FINAL_CUT.parquet')\n",
    "Nobs = df['N'].values\n",
    "\n",
    "print(Nobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71be3483-934c-4dc2-b242-3b31d7364a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=(Nsig/15000).tolist(), bkg=(Nbkg).tolist(), bkg_uncertainty=(Nbkg).tolist()\n",
    ")\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da25af6b-6b5f-49cc-9d56-d83c81001cfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0006758a-d942-49ec-b813-a104442505f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(json.dumps(model.spec, indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada0c601-19a0-445e-aa37-328d960e4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"  channels: {model.config.channels}\")\n",
    "print(f\"     nbins: {model.config.channel_nbins}\")\n",
    "print(f\"   samples: {model.config.samples}\")\n",
    "print(f\" modifiers: {model.config.modifiers}\")\n",
    "print(f\"parameters: {model.config.parameters}\")\n",
    "print(f\"  nauxdata: {model.config.nauxdata}\")\n",
    "print(f\"   auxdata: {model.config.auxdata}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d274a8f-c9c0-44fb-876e-af47868c7afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 more than the number of bins\n",
    "model.expected_data([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae71a43-a8fe-4c40-af20-e8eb2d87949e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.spec['channels'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b054ff6-ef80-43c2-8caa-4ff9b2907db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.spec['channels'][0]['samples'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aab4402-24e0-45af-8fc8-873e7fc89b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = model.config.channel_nbins['singlechannel']\n",
    "bins = np.linspace(0,nbins,nbins)\n",
    "#obs = model.expected_data\n",
    "\n",
    "sig = model.spec['channels'][0]['samples'][0]['data']\n",
    "bkg = model.spec['channels'][0]['samples'][1]['data']\n",
    "\n",
    "# Set some signal\n",
    "Nobs[0] = 2\n",
    "\n",
    "print(len(bins), bins)\n",
    "print(len(sig), sig)\n",
    "print(len(bkg), bkg)\n",
    "print(len(Nobs), Nobs)\n",
    "print()\n",
    "\n",
    "#print(obs)\n",
    "\n",
    "draw_plot_dm(mu=1, bins=bins, observed=Nobs, background=bkg, signal=sig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdf07c0-c6d5-4b70-855b-5c49419f23d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = model.config.auxdata\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715b2c8f-3513-45ef-b008-10983ce92178",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pyhf.tensorlib.astensor(Nobs.tolist() + model.config.auxdata)\n",
    "\n",
    "print(data)\n",
    "\n",
    "\n",
    "ul = pyhf.infer.intervals.upper_limits.upper_limit(data, model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83efabd4-607a-46f5-b909-4e1682634d7e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a629d135-fe10-405c-a7c2-e54835d6b6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a6a2598-4023-47d7-ae07-ba89686da92b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = model.config\n",
    "\n",
    "c.auxdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2cf1446-580d-4cb2-98f5-7da7366ada2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.auxdata_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab8f278-b9da-4d5f-b506-97785a1cd640",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.par_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5f7e4b-8869-4c64-9ac2-ecadd2285083",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.nmaindata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3ad6a-94e7-409e-a945-b69aff3d5bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85efe633-796a-4f5b-8eb0-479afaea8d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(c.channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb5c143-69ee-4862-8539-4e3d0f3407d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288bb1e5-8ad7-464e-a98f-eb8e4d1f7df4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b70aef9-d1d1-44ae-bb8e-fe2cc8fcc9d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287b64dd-aed7-47db-97f7-1045fc2d5689",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98365a-4d71-4ecc-bfa7-c528861e4403",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dd4835b-1aa8-4c71-ad6c-6feb6502757d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5250d3b-889c-49f3-b09d-371d94e15013",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de755232-d8ac-4831-87bb-067622949708",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pyhf.github.io/pyhf-tutorial/IntroToHiFa.html\n",
    "\n",
    "def draw_plot_dm(mu=1):\n",
    "    bins = [5, 55, 550]\n",
    "    observed = [60, 43, 40]\n",
    "    background = [58.0, 42.5, 36.0]\n",
    "    signal = [i * mu for i in [2, 4, 3]]\n",
    "\n",
    "    print(f\"signal: {signal}\")\n",
    "    print(f\"background: {background}\")\n",
    "    print(f\"observed: {observed}\\n\")\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(bins, background, width=[10.0, 90, 900], label=r\"Background\", edgecolor=\"red\", alpha=0.5)\n",
    "    ax.bar(\n",
    "        bins,\n",
    "        signal,\n",
    "        width=[10.0, 90, 900],\n",
    "        label=r\"Signal\",\n",
    "        edgecolor=\"blue\",\n",
    "        bottom=background,\n",
    "        alpha=0.5,\n",
    "    )\n",
    "    ax.scatter(bins, observed, color=\"black\", label=\"Observed\")\n",
    "    #ax.set_ylim(0, 6)\n",
    "    ax.legend()\n",
    "    ax.set_xlabel(r\"$p_T$ [GeV/c]\", fontsize=12)\n",
    "    ax.set_ylabel(\"Count\", fontsize=12);\n",
    "\n",
    "\n",
    "draw_plot_dm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedc69b9-d4e8-48f7-b6af-acbf33c89f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286ae09e-9635-478d-bd32-9e180d5cac25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "\n",
    "# Make the masks\n",
    "#mask_event = dcuts[3]['event']\n",
    "#mask_event = dcuts[4]['event']\n",
    "#mask_event = dcuts[1]['event']\n",
    "mask_event = dcuts[-1]['event']\n",
    "#mask_event = dcuts[2]['event'] & dcuts[3]['event'] & dcuts[4]['event']\n",
    "\n",
    "\n",
    "vals = {}\n",
    "for spmode in ['998', '-999']:\n",
    "    \n",
    "    #spmode = '998'\n",
    "    \n",
    "    mask_sp = data['spmode']==spmode\n",
    "    \n",
    "    mask = mask_event & mask_sp\n",
    "    #mask = mask_sp\n",
    "    \n",
    "    # Make the plot\n",
    "    mes =    ak.flatten(data[mask]['BpostFitMes'])\n",
    "    DeltaE = ak.flatten(data[mask]['BpostFitDeltaE'])\n",
    "    \n",
    "    n = 100\n",
    "    if n>len(mes):\n",
    "        n = len(mes)\n",
    "    print(n,len(mes))\n",
    "    mes = np.random.choice(mes.to_numpy(), n, replace=False)\n",
    "    DeltaE = np.random.choice(DeltaE.to_numpy(), n, replace=False)\n",
    "    \n",
    "    print(len(mes), mes[:5])\n",
    "    print(len(DeltaE), DeltaE[:5])\n",
    "\n",
    "    vals[spmode] = {\"mes\": mes, \"DeltaE\": DeltaE}\n",
    "\n",
    "#vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9733d9d8-6a1a-4003-a7e9-9ca4446d0455",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(vals['998'][\"mes\"], vals['998']['DeltaE'], '.')\n",
    "plt.plot(vals['-999'][\"mes\"], vals['-999']['DeltaE'], '.')\n",
    "plt.xlabel('mES')\n",
    "plt.ylabel('DeltaE')\n",
    "plt.xlim(5.2, 5.3)\n",
    "plt.ylim(-0.2, 0.2)\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b027be-118b-4aeb-8ee3-f32a399bd825",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbinsx = 2\n",
    "nbinsy = 3\n",
    "mes_lo = 5.2\n",
    "mes_hi = 5.3\n",
    "de_lo = -0.2\n",
    "de_hi =  0.2\n",
    "\n",
    "hvals = {}\n",
    "\n",
    "epsilon = 0.001\n",
    "\n",
    "hvals['sig'], xedges, yedges = np.histogram2d(vals['-999'][\"mes\"], vals['-999'][\"DeltaE\"], bins=[nbinsx, nbinsy], range=[[mes_lo, mes_hi], [de_lo, de_hi]])\n",
    "#print(hvals)\n",
    "org_shape = hvals['sig'].copy()\n",
    "\n",
    "hvals['sig'] = np.ravel(hvals['sig']+epsilon).tolist()\n",
    "\n",
    "hvals['bkg'], xedges, yedges = np.histogram2d(vals['998'][\"mes\"], vals['998'][\"DeltaE\"], bins=[nbinsx, nbinsy], range=[[mes_lo, mes_hi], [de_lo, de_hi]])\n",
    "#print(hvals)\n",
    "hvals['bkg'] = np.ravel(hvals['bkg']+epsilon).tolist()\n",
    "\n",
    "# IF THE UNCERTAINTIES ARE TOO SMALL, IT BREAKS DOWN  #NOPE\n",
    "#hvals['bkg_uncert'] = np.sqrt(np.array(hvals['bkg'])).tolist()\n",
    "hvals['bkg_uncert'] = (0.5*np.ones_like(hvals['bkg'], dtype=float)).tolist()\n",
    "\n",
    "\n",
    "print(hvals)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d091163-fa76-4ba5-9203-bab882849c6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array(hvals['sig'])\n",
    "\n",
    "np.reshape(x, org_shape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae99b65c-9e08-402b-a5d5-267d565f9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(org_shape.shape)\n",
    "\n",
    "org_shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d018b99-537b-4a24-99db-3f3e9ca3d464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unravel / ravel example\n",
    "\n",
    "# https://stackoverflow.com/questions/52046347/unravel-1d-list-back-to-3d-array\n",
    "\n",
    "# raveled = np.ravel(arr)\n",
    "# new_arr = raveled.reshape(*arr.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7131a5d-bcc2-488d-aa77-657279760989",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_scale_factor = 0.05\n",
    "\n",
    "signal = (np.array(hvals['sig'])*sig_scale_factor).tolist()\n",
    "\n",
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=signal, bkg=hvals['bkg'], bkg_uncertainty=hvals['bkg_uncert']\n",
    ")\n",
    "\n",
    "print(\"aux data\")\n",
    "print(model.config.auxdata)\n",
    "print(\"\\nsignal: \",signal)\n",
    "print(\"\\nbkg   : \",hvals['bkg'])\n",
    "\n",
    "print()\n",
    "print(len(model.config.auxdata))\n",
    "print(len(hvals['sig']))\n",
    "print(len(hvals['bkg']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0518b49-8cd0-4558-a763-e2de5291a547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mock data\n",
    "#observed_data = (np.array(hvals['bkg']) + np.random.normal(1,0.05,len(hvals['bkg']))).tolist()  + model.config.auxdata\n",
    "#observed_data = (np.array(hvals['bkg']) + np.random.randint(0,1,len(hvals['bkg']))).tolist()  + model.config.auxdata\n",
    "\n",
    "# Add in some signal\n",
    "mock_signal = np.array(hvals['sig'])+np.random.randint(1,2,len(hvals['sig']))\n",
    "mock_signal[np.array(hvals['sig'])<1] = 0 \n",
    "mock_signal[np.array(hvals['sig'])>=1] = 1 \n",
    "\n",
    "print(\"sig        : \",   hvals['sig'])\n",
    "print(\"mock signal: \",   mock_signal)\n",
    "observed_data = (np.array(hvals['bkg']) + np.random.randint(0,1,len(hvals['bkg'])) + mock_signal).tolist()  + model.config.auxdata\n",
    "\n",
    "# MAKE SURE DATA IS POSITIVE\n",
    "print(\"observed_data: \",observed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dafb110-2f8f-4ef6-b05c-1e292523e843",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_mu = 1.0\n",
    "\n",
    "print(\"model\")\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "print(\"observed_data\")\n",
    "\n",
    "print(observed_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee63955-2c1b-4937-b867-bc6feced5715",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    test_mu, observed_data, model, test_stat=\"qtilde\", return_expected=True\n",
    ")\n",
    "\n",
    "print(f\"Observed: {CLs_obs}, Expected: {CLs_exp}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5387ef-f073-4bf8-9849-f95697f6427f",
   "metadata": {},
   "outputs": [],
   "source": [
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    test_mu,  # null hypothesis\n",
    "    observed_data,\n",
    "    model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed34ddf-289d-4c2a-abf2-2edb10a5a733",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0.1, 5, 50)\n",
    "obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(\n",
    "    observed_data, model, poi_values, level=0.05, return_results=True\n",
    ")\n",
    "print(f\"Upper limit (obs): μ = {obs_limit:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbcd623-d84d-40c3-ab0c-8cf4e688c11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.5, 7)\n",
    "ax.set_title(\"Hypothesis Tests\")\n",
    "\n",
    "artists = brazil.plot_results(poi_values, results, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a67c4-5015-4e41-b9f2-5d9b6500323e",
   "metadata": {},
   "source": [
    "# Toys?\n",
    "\n",
    "https://pyhf.readthedocs.io/en/v0.7.6/examples/notebooks/toys.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec181bc3-a4a6-444d-b7ae-2d394dc4b263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu' = 0: background-like\n",
    "pars_bkg = model.config.suggested_init()\n",
    "pars_bkg[model.config.poi_index] = 0.0\n",
    "print(f\"Background parameters: {list(zip(model.config.parameters, pars_bkg))}\")\n",
    "\n",
    "# mu' = 1: signal-like\n",
    "pars_sig = model.config.suggested_init()\n",
    "pars_sig[model.config.poi_index] = 1.0\n",
    "print(f\"Signal parameters: {list(zip(model.config.parameters, pars_sig))}\")\n",
    "\n",
    "# make the pdfs\n",
    "pdf_bkg = model.make_pdf(pyhf.tensorlib.astensor(pars_bkg))\n",
    "pdf_sig = model.make_pdf(pyhf.tensorlib.astensor(pars_sig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd6a7dd-57b3-4abb-a93f-1b13f33c9cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: pdf.sample takes in a \"shape\" N=(10000,) given the number of samples\n",
    "n_samples = 100\n",
    "\n",
    "# mu' = 0\n",
    "mc_bkg = pdf_bkg.sample((n_samples,))\n",
    "# mu' = 1\n",
    "mc_sig = pdf_sig.sample((n_samples,))\n",
    "\n",
    "print(mc_bkg.shape)\n",
    "print(mc_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d55c21-e491-4600-9cd0-a0cc6152b18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mc_bkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e4fc4a2-69b4-4761-9dbd-49e5da8983f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_pars = model.config.suggested_init()\n",
    "par_bounds = model.config.suggested_bounds()\n",
    "fixed_params = model.config.suggested_fixed()\n",
    "\n",
    "qtilde_bkg = pyhf.tensorlib.astensor(\n",
    "    [\n",
    "        pyhf.infer.test_statistics.qmu_tilde(\n",
    "            1.0, mc, model, init_pars, par_bounds, fixed_params\n",
    "        )\n",
    "        for mc in mc_bkg\n",
    "    ]\n",
    ")\n",
    "qtilde_sig = pyhf.tensorlib.astensor(\n",
    "    [\n",
    "        pyhf.infer.test_statistics.qmu_tilde(\n",
    "            1.0, mc, model, init_pars, par_bounds, fixed_params\n",
    "        )\n",
    "        for mc in mc_sig\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f27ddb6e-ccac-46d4-9b7b-bfa53b954341",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_calculator_qtilde = pyhf.infer.utils.create_calculator(\n",
    "    \"toybased\",\n",
    "    model.expected_data(pars_sig),\n",
    "    model,\n",
    "    ntoys=n_samples,\n",
    "    test_stat=\"qtilde\",\n",
    ")\n",
    "qtilde_sig, qtilde_bkg = toy_calculator_qtilde.distributions(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b24b2a-1632-458d-8e5b-b4fc36757f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "qmu_bounds = model.config.suggested_bounds()\n",
    "print(f\"Old bounds: {qmu_bounds}\")\n",
    "qmu_bounds[model.config.poi_index] = (-10, 10)\n",
    "print(f\"New bounds: {qmu_bounds}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e7138e-c3f1-4df6-8ceb-f631d666bed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "toy_calculator_qmu = pyhf.infer.utils.create_calculator(\n",
    "    \"toybased\",\n",
    "    model.expected_data(model.config.suggested_init()),\n",
    "    model,\n",
    "    par_bounds=qmu_bounds,\n",
    "    ntoys=n_samples,\n",
    "    test_stat=\"q\",\n",
    ")\n",
    "qmu_sig, qmu_bkg = toy_calculator_qmu.distributions(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e1f27e-a893-4b30-a2bb-294c648e58e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=2)\n",
    "for ax in axes:\n",
    "    ax.set_xticks(np.arange(0, 10))\n",
    "ax0, ax1 = axes.flatten()\n",
    "\n",
    "bins = np.linspace(0, 10, 26)\n",
    "\n",
    "ax0.hist(\n",
    "    qmu_sig.samples,\n",
    "    bins=bins,\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    label=\"$f(q_1|1)$ signal-like\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax0.hist(\n",
    "    qmu_bkg.samples,\n",
    "    bins=bins,\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    label=\"$f(q_1|0)$ background-like\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax0.set_xlabel(r\"(a) $q_1$\", fontsize=18)\n",
    "ax0.set_ylabel(r\"$f\\,(q_1|\\mu')$\", fontsize=18)\n",
    "ax0.set_title(r\"Test statistic $(q_1)$ distributions\")\n",
    "ax0.legend()\n",
    "\n",
    "ax1.hist(\n",
    "    qtilde_sig.samples,\n",
    "    bins=bins,\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    label=r\"$f(\\tilde{q}_1|1)$ signal-like\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax1.hist(\n",
    "    qtilde_bkg.samples,\n",
    "    bins=bins,\n",
    "    histtype=\"step\",\n",
    "    density=True,\n",
    "    label=r\"$f(\\tilde{q}_1|0)$ background-like\",\n",
    "    linewidth=2,\n",
    ")\n",
    "ax1.set_xlabel(r\"(b) $\\tilde{q}_1$\", fontsize=18)\n",
    "ax1.set_ylabel(r\"$f\\,(\\tilde{q}_1|\\mu')$\", fontsize=18)\n",
    "ax1.set_title(r\"Alternative test statistic $(\\tilde{q}_1)$ distributions\")\n",
    "ax1.legend()\n",
    "\n",
    "\n",
    "plt.setp(axes, xlim=(0, 9), ylim=(1e-3, 2), yscale=\"log\")\n",
    "fig.set_size_inches(14, 6)\n",
    "fig.tight_layout(pad=2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f282e4-cbd3-450b-9cc5-85a05cfb11be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa09092c-4b56-45ba-b5a0-55bbfb94eb8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cc63c5b-ec48-4a2b-85c6-1e0cbbfdde8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a363a0-ac68-47b2-aa22-c062a77ed993",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b9e22-a52b-4c0b-a40b-468a4ae48b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D\n",
    "\n",
    "sig = np.ravel([[12.0, 11.0], [5, 6]]).tolist()\n",
    "bkg = np.ravel([[50.0, 52.0],[7, 7]]).tolist()\n",
    "bkg_uncert = np.ravel([[3.0, 7.0], [1, 2]]).tolist()\n",
    "\n",
    "print(sig)\n",
    "print(bkg)\n",
    "print(bkg_uncert)\n",
    "print()\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=sig, bkg=bkg, bkg_uncertainty=bkg_uncert\n",
    ")\n",
    "\n",
    "print(\"aux data\")\n",
    "print(model.config.auxdata,'\\n')\n",
    "\n",
    "observed_data = np.ravel([[51, 48], [8, 4]]).tolist() + model.config.auxdata\n",
    "print(\"observed_data\")\n",
    "print(observed_data,'\\n')\n",
    "\n",
    "test_mu = 1.0\n",
    "\n",
    "print(\"model\")\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "print(\"observed_data\")\n",
    "\n",
    "print(observed_data)\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    test_mu, observed_data, model, test_stat=\"qtilde\", return_expected=True\n",
    ")\n",
    "\n",
    "print(f\"Observed: {CLs_obs}, Expected: {CLs_exp}\")\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf978c77-6a99-4570-886d-65631945776f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D - small signals\n",
    "\n",
    "sig = np.ravel([[0.30, 0.40], [0.2, 0.1]]).tolist()\n",
    "bkg = np.ravel([[1, 2],[1, 0]]).tolist()\n",
    "bkg_uncert = np.ravel([[1.1, 1.0], [1, 1]]).tolist()\n",
    "\n",
    "print(sig)\n",
    "print(bkg)\n",
    "print(bkg_uncert)\n",
    "print()\n",
    "\n",
    "\n",
    "#'''\n",
    "\n",
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=sig, bkg=bkg, bkg_uncertainty=bkg_uncert\n",
    ")\n",
    "\n",
    "print(\"aux data\")\n",
    "print(model.config.auxdata,'\\n')\n",
    "print(model.config.auxdata,'\\n')\n",
    "\n",
    "\n",
    "observed_data = np.ravel([[1, 2], [0, 1]]).tolist() + model.config.auxdata\n",
    "print(\"observed_data\")\n",
    "print(observed_data,'\\n')\n",
    "\n",
    "test_mu = 1.0\n",
    "\n",
    "print(\"model\")\n",
    "print(model)\n",
    "print()\n",
    "\n",
    "print(\"observed_data\")\n",
    "\n",
    "print(observed_data)\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    test_mu, observed_data, model, test_stat=\"qtilde\", return_expected=True\n",
    ")\n",
    "\n",
    "print(f\"Observed: {CLs_obs}, Expected: {CLs_exp}\")\n",
    "\n",
    "#'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef4dcfdc-2723-4c5a-89ba-69db0f38107f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca616993-65d1-47d2-9d9a-12643958039d",
   "metadata": {},
   "source": [
    "# Playing with toys and upper limits\n",
    "https://pyhf.github.io/pyhf-tutorial/Toys.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a97df1-58b0-4040-8dec-7648e42afe53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original\n",
    "#'''\n",
    "observed = [51, 48]\n",
    "background = [50.0, 52.0]\n",
    "background_uncert = [3.0, 7.0]\n",
    "signal = [12.0, 11.0]\n",
    "#'''\n",
    "\n",
    "# Small numbers\n",
    "#'''\n",
    "observed = [0, 1]\n",
    "background = [0.5, 0.5]\n",
    "background_uncert = [1.0, 1.0]\n",
    "signal = [0.0, 2.0]\n",
    "#'''\n",
    "\n",
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=signal, bkg=background, bkg_uncertainty=background_uncert\n",
    ")\n",
    "observed_data = observed + model.config.auxdata\n",
    "print(\"observed_data: \",observed_data)\n",
    "\n",
    "test_mu = 1.0\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    test_mu, observed_data, model, test_stat=\"qtilde\", return_expected=True\n",
    ")\n",
    "print(f\"Observed: {CLs_obs:.8f}, Expected: {CLs_exp:.8f}\")\n",
    "\n",
    "print(\"Hypothesis\")\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    observed + model.config.auxdata,\n",
    "    model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")\n",
    "\n",
    "print()\n",
    "print(\"More\")\n",
    "print()\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    observed + model.config.auxdata,\n",
    "    model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    "    calctype=\"toybased\",\n",
    "    ntoys=1_000,\n",
    "    track_progress=False,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8ccdbe-a0b3-4625-818c-436af2f8e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=[12.0, 11.0], bkg=[50.0, 52.0], bkg_uncertainty=[3.0, 7.0]\n",
    ")\n",
    "observed_data = [51, 48] + model.config.auxdata\n",
    "print(\"observed_data: \",observed_data)\n",
    "\n",
    "test_mu = 1.0\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    test_mu, observed_data, model, test_stat=\"qtilde\", return_expected=True\n",
    ")\n",
    "print(f\"Observed: {CLs_obs:.8f}, Expected: {CLs_exp:.8f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1146c456-67e2-42d9-afb3-9219c52e6220",
   "metadata": {},
   "source": [
    "# Hypothesis testing - low stats\n",
    "\n",
    "https://pyhf.github.io/pyhf-tutorial/Toys.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8313195e-6b9b-4d41-ab53-cd1da4e4fd5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Small numbers\n",
    "# From example\n",
    "#'''\n",
    "observed = [5, 7]\n",
    "background = [5.0, 6.0]\n",
    "background_uncert = [0.5, 1.2]\n",
    "signal = [0.5, 1.0]\n",
    "#'''\n",
    "\n",
    "#'''\n",
    "observed = [0, 1]\n",
    "background = [0.0, 1.0]\n",
    "background_uncert = [0.5, 1.2]\n",
    "signal = [0.5, 1.0]\n",
    "#'''\n",
    "\n",
    "\n",
    "\n",
    "model_low = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=signal, bkg=background, bkg_uncertainty=background_uncert\n",
    ")\n",
    "\n",
    "observed_data = observed + model.config.auxdata\n",
    "print(\"observed_data: \",observed_data)\n",
    "\n",
    "#model_low = pyhf.simplemodels.uncorrelated_background(\n",
    "#    signal=[0.5, 1.0], bkg=[5.0, 6.0], bkg_uncertainty=[0.5, 1.2]\n",
    "#)\n",
    "\n",
    "\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    observed + model_low.config.auxdata,\n",
    "    model_low,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    "    calctype=\"asymptotics\",\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")\n",
    "\n",
    "print(\"\\nWith toys...\")\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    observed + model_low.config.auxdata,\n",
    "    model_low,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    "    calctype=\"toybased\",\n",
    "    ntoys=1_000,\n",
    "    track_progress=True,\n",
    ")\n",
    "\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58e7317b-e311-49ac-9f42-4388a1fad8ab",
   "metadata": {},
   "source": [
    "Discussions about 0-rate bins.\n",
    "\n",
    "https://github.com/scikit-hep/pyhf/issues/293\n",
    "\n",
    "https://github.com/scikit-hep/pyhf/issues/180\n",
    "\n",
    "\n",
    "## Variable-width bins\n",
    "https://stackoverflow.com/questions/66165423/pyhf-support-for-variable-bin-width-histograms\n",
    "\n",
    "Here is a discussion of the error that I get with some 0-rate bins. \n",
    "\n",
    "https://stackoverflow.com/questions/60514470/minimal-pyhf-example-failing-with-inequality-constraints-incompatible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e19515-58f9-4280-91bd-4fb5511f9564",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=[5.0, 10.0], bkg=[50.0, 60.0], bkg_uncertainty=[5.0, 12.0]\n",
    ")\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    [53.0, 65.0] + model.config.auxdata,\n",
    "    model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be41c4a1-907d-4a26-879f-13bb5dd7a3d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    signal=[0.5, 1.0], bkg=[5.0, 6.0], bkg_uncertainty=[1.0, 1.0]\n",
    ")\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    1.0,  # null hypothesis\n",
    "    [5.0, 6.0] + model.config.auxdata,\n",
    "    model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4611af6f-f8a4-4ca1-8ca6-648d958bc72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.001\n",
    "\n",
    "model = pyhf.simplemodels.uncorrelated_background(\n",
    "    # Works\n",
    "    #signal=[0.5, 1.0], bkg=[1.0, 1.2], bkg_uncertainty=[0.5, 0.5]\n",
    "\n",
    "    # Test 0-rate bin\n",
    "    #signal=[0.5, 1.0], bkg=[0.0, 0.5], bkg_uncertainty=[0.5, 0.5]\n",
    "    \n",
    "    # Adding an epsilon offset to 0-rate\n",
    "    signal=[0.5, 1.0], bkg=[0.0+epsilon, 0.5], bkg_uncertainty=[0.5, 0.5]\n",
    "\n",
    ")\n",
    "\n",
    "# mu is fraction of sig and bkg\n",
    "# mu = 1 --> all bkg\n",
    "# mu = 0 --> all sig\n",
    "mu = 1.0\n",
    "\n",
    "# Works\n",
    "#observations = [1.0, 2.0]\n",
    "\n",
    "# Test\n",
    "observations = [1.0, 2.0]\n",
    "\n",
    "\n",
    "CLs_obs, CLs_exp = pyhf.infer.hypotest(\n",
    "    mu,  # null hypothesis\n",
    "    observations + model.config.auxdata,\n",
    "    model,\n",
    "    test_stat=\"qtilde\",\n",
    "    return_expected_set=True,\n",
    ")\n",
    "print(f\"      Observed CLs: {CLs_obs:.4f}\")\n",
    "for expected_value, n_sigma in zip(CLs_exp, np.arange(-2, 3)):\n",
    "    print(f\"Expected CLs({n_sigma:2d} σ): {expected_value:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e91289b6-9357-4009-94ce-bde243a0211f",
   "metadata": {},
   "outputs": [],
   "source": [
    "poi_values = np.linspace(0.1, 5, 50)\n",
    "obs_limit, exp_limits, (scan, results) = pyhf.infer.intervals.upper_limits.upper_limit(\n",
    "    observations+model.config.auxdata, model, poi_values, level=0.05, return_results=True\n",
    ")\n",
    "print(f\"Upper limit (obs): μ = {obs_limit:.4f}\")\n",
    "print(f\"Upper limit (exp): μ = {exp_limits[2]:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c0f3c-8718-4ee7-8a28-e6f68f91effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10.5, 7)\n",
    "ax.set_title(\"Hypothesis Tests\")\n",
    "\n",
    "artists = brazil.plot_results(poi_values, results, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6338cb00-c238-49a6-ab48-a07fc1873087",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e26c59a-c76d-4b8f-9836-66f75e473d1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ab38ab-f69f-4c46-b067-d8b3ec1bcf1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "544667b3-7231-4f33-9074-e56cbf0fa01c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
