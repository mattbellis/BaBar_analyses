{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4db8eb-3d54-4930-9e8d-0f78b00d7263",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "from hist import Hist\n",
    "\n",
    "import babar_analysis_tools as bat\n",
    "from analysis_variables import *\n",
    "import myPIDselector\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7175c01e-d6e3-4ec3-b8d4-f93e90d564f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.__version__)\n",
    "\n",
    "print(plt.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30634a5c-dd1d-4460-a854-1f6f3a27893c",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d60000c-71ef-4a64-9431-a97afc39dfa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_train_test_split(df, bkg_spmode='998', sig_spmode='-999', n_sig_bkg=[1000,1000], \\\n",
    "                        test_size=0.4, \\\n",
    "                        columns_to_drop=[\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\"]):\n",
    "\n",
    "    columns= df.columns\n",
    "\n",
    "    print(\"columns...\")\n",
    "    print(columns)\n",
    "    print()\n",
    "\n",
    "    feature_names= columns[1:] ##exclude spmode\n",
    "    #print(feature_names)\n",
    "    \n",
    "    filter_sig= df[\"spmode\"]==sig_spmode\n",
    "    filter_bkg= df[\"spmode\"]==bkg_spmode\n",
    "\n",
    "    # Get the indices of the sig and bkg\n",
    "    idx_sig = df[filter_sig].index.values\n",
    "    idx_bkg = df[filter_bkg].index.values\n",
    "\n",
    "    print(idx_sig)\n",
    "    \n",
    "    # Shuffle them\n",
    "    np.random.shuffle(idx_sig)\n",
    "    np.random.shuffle(idx_bkg)\n",
    "\n",
    "    #df_sig= df[filter_sig].dropna().sample(n_sig_bkg[0])\n",
    "    #df_bkg= df[filter_bkg].dropna().sample(n_sig_bkg[1])\n",
    "\n",
    "    # Amount to use for both training and testing\n",
    "    n_sig = n_sig_bkg[0]\n",
    "    n_bkg = n_sig_bkg[1]\n",
    "\n",
    "    # Amount to use for testing\n",
    "    n_test_sig = int(n_sig*test_size)\n",
    "    n_train_sig = n_sig - n_test_sig\n",
    "\n",
    "    # Amount to use for training\n",
    "    n_test_bkg = int(n_bkg*test_size)\n",
    "    n_train_bkg = n_bkg - n_test_bkg\n",
    "\n",
    "    print(\"Training breakdown...\")\n",
    "    print(f\"sig:   train: {n_train_sig}    test: {n_test_sig}\") \n",
    "    print(f\"bkg:   train: {n_train_bkg}    test: {n_test_bkg}\") \n",
    "    \n",
    "    #print(len(df_sig), len(df_bkg))\n",
    "    \n",
    "    #df_ML= pd.concat([df_sig,df_bkg])\n",
    "    \n",
    "    #x=df_ML.drop(columns= columns_to_drop)\n",
    "    #y=df_ML[\"spmode\"]\n",
    "\n",
    "    idx_sig_train = idx_sig[0:n_train_sig]\n",
    "    idx_sig_test  = idx_sig[n_train_sig:n_train_sig+n_test_sig]\n",
    "    idx_sig_not_train = idx_sig[n_train_sig:]\n",
    "\n",
    "    idx_bkg_train = idx_bkg[0:n_train_bkg]\n",
    "    idx_bkg_test  = idx_bkg[n_train_bkg:n_train_bkg+n_test_bkg]\n",
    "    idx_bkg_not_train = idx_bkg[n_train_bkg:]\n",
    "\n",
    "    #print(idx_sig_train)\n",
    "    \n",
    "    x_sig_train = df.drop(columns=columns_to_drop).loc[idx_sig_train]\n",
    "    x_sig_test  = df.drop(columns=columns_to_drop).loc[idx_sig_test]\n",
    "\n",
    "    y_sig_train = df['spmode'].loc[idx_sig_train]\n",
    "    y_sig_test  = df['spmode'].loc[idx_sig_test]\n",
    "\n",
    "    \n",
    "    x_bkg_train = df.drop(columns=columns_to_drop).loc[idx_bkg_train]\n",
    "    x_bkg_test  = df.drop(columns=columns_to_drop).loc[idx_bkg_test]\n",
    "\n",
    "    y_bkg_train = df['spmode'].loc[idx_bkg_train]\n",
    "    y_bkg_test  = df['spmode'].loc[idx_bkg_test]\n",
    "\n",
    "    # Merge them\n",
    "    print(\"here----------------------------------------------------\")\n",
    "    #print(x_sig_train)\n",
    "    #print(x_bkg_train)\n",
    "    \n",
    "    x_train = pd.concat([x_sig_train, x_bkg_train])\n",
    "    x_test = pd.concat([x_sig_test,  x_bkg_test])\n",
    "\n",
    "    #x_train = x_train.values#.transpose()[1:]\n",
    "    #x_test = x_test.values#.transpose()[1:]\n",
    "\n",
    "    #print(x_train)\n",
    "    \n",
    "    y_train = pd.concat([y_sig_train, y_bkg_train])\n",
    "    y_test = pd.concat([y_sig_test,  y_bkg_test])\n",
    "\n",
    "    print(\"The dataset (x) is the numbers without column names---\")\n",
    "    print(\"The variable y is truth info about the data (signal or bkg)\\n\")\n",
    "\n",
    "    return x_train, x_test,y_train,  y_test, [idx_sig_train, idx_sig_not_train, idx_bkg_train, idx_bkg_not_train]\n",
    "\n",
    "\n",
    "#x_train, x_test, y_train, y_test,train_test_indices = my_train_test_split(df_sp)\n",
    "\n",
    "'''\n",
    "print(type(x_train))\n",
    "print(x_train)\n",
    "print()\n",
    "print(x_test)\n",
    "print()\n",
    "print(train_test_indices[1])\n",
    "scaler= StandardScaler()\n",
    "x_train= scaler.fit_transform(x_train)\n",
    "x_test= scaler.transform(x_test)\n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a00adcb-9e5d-465f-90f7-bd08ae063ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker(df, sig_spmode=\"-999\", bkg_spmode= \"998\", n_sig_bkg=[1000,1000], \\\n",
    "                columns_to_drop=[\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\"], \\\n",
    "                test_size_pct= 0.4, activator= \"relu\", solve_model= \"adam\", model_filename=None): \n",
    "            \n",
    "\n",
    "    #x_train, x_test, y_train, y_test= train_test_split(x,y, test_size= test_size_pct, random_state= 4)\n",
    "    x_train, x_test, y_train, y_test,train_test_indices= my_train_test_split(df, sig_spmode=sig_spmode, bkg_spmode=bkg_spmode, \\\n",
    "                                                          columns_to_drop=columns_to_drop, \\\n",
    "                                                          n_sig_bkg=n_sig_bkg, \\\n",
    "                                                          test_size= test_size_pct)\n",
    "\n",
    "    feature_names = x_train.columns\n",
    "    print(\"Feature names (model_maker)....\")\n",
    "    print(feature_names)\n",
    "    \n",
    "    # LETS TRY TO NOT DO THIS\n",
    "    #scaler= StandardScaler()\n",
    "\n",
    "    #print(type(x_train))\n",
    "    #print(x_train)\n",
    "    # Look in \"tips for practical use\"\n",
    "    # https://scikit-learn.org/stable/modules/neural_networks_supervised.html\n",
    "    # This also makes it no longer a DataFrame but an nxm numpy array\n",
    "    #x_train= scaler.fit_transform(x_train)\n",
    "\n",
    "    #print(\"x_train after........\")\n",
    "    #print(x_train)\n",
    "    \n",
    "    #x_test= scaler.transform(x_test)\n",
    "\n",
    "    #print(\"x_test after..........\")\n",
    "    #print(x_test)\n",
    "    \n",
    "    model = MLPClassifier(max_iter= 1000, random_state= 3, activation= activator, solver= solve_model ) #n_iter_no_change= 15)\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "\n",
    "    model.feature_names = feature_names\n",
    "    \n",
    "    workspace = {}\n",
    "    workspace['model'] = model\n",
    "    workspace['x_train'] = x_train\n",
    "    workspace['y_train'] = y_train\n",
    "    workspace['x_test'] = x_test\n",
    "    workspace['y_test'] = y_test\n",
    "    #[idx_sig_train, idx_sig_not_train, idx_bkg_train, idx_bkg_not_train]\n",
    "\n",
    "    workspace['idx_sig_train'] = train_test_indices[0]\n",
    "    workspace['idx_sig_not_train'] = train_test_indices[1]\n",
    "    workspace['idx_bkg_train'] = train_test_indices[2]\n",
    "    workspace['idx_bkg_not_train'] = train_test_indices[3]\n",
    "\n",
    "    if model_filename is not None:\n",
    "        joblib.dump(workspace, model_filename)\n",
    "\n",
    "    return workspace\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520fdcf1-8d75-46f4-9573-5678dd87f5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_variables(df):\n",
    "\n",
    "    #########################################################################\n",
    "    # Plot the variables for the different spmodes\n",
    "    #########################################################################\n",
    "\n",
    "    print(\"Plotting the training variables...\")\n",
    "    nvars = len(df.columns)\n",
    "\n",
    "    nrows = 5\n",
    "    ncols = int(nvars / nrows) + 1\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows = nrows, ncols = ncols)    # axes is 2d array (3x3)\n",
    "    axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "    fig.set_size_inches(ncols*3, nrows*3)\n",
    "\n",
    "    for ax, col in zip(axes, df.columns):\n",
    "      sns.histplot(df, x=col, ax = ax, hue='spmode', stat='density', common_norm=False)\n",
    "      ax.set_title(col)\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    #########################################################################\n",
    "    # Plot the correlation matrices\n",
    "    #########################################################################\n",
    "\n",
    "    spmodes_in_file = df['spmode'].unique()\n",
    "    # Drop the cuts columns\n",
    "    cols = df_temp.columns\n",
    "\n",
    "    cols_temp = []\n",
    "    for col in cols:\n",
    "        #print(col)\n",
    "        if col[0:3]!='cut':\n",
    "            cols_temp.append(col)\n",
    "    cols_temp\n",
    "\n",
    "    for spmode in spmodes_in_file:\n",
    "        print(f\"Making the correlation matrix for SP-{spmode}...\")\n",
    "        fig,ax = plt.subplots(figsize=(16,16))\n",
    "        mask = df_temp['spmode'] == spmode\n",
    "        \n",
    "        sns.heatmap(df_temp[mask][cols_temp].drop(columns=['spmode']).corr(), center=0, cmap='coolwarm', annot=True, fmt='.2f', annot_kws={\"size\": 8})\n",
    "        plt.title(f'Correlation matrix SP {spmode}')        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c592dbb5-95e0-4004-9b8c-bba34a640017",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#def model_training_quality(model, x_train, y_train, x_test, y_test):\n",
    "def model_training_quality(workspace):\n",
    "    model = workspace['model']\n",
    "    x_train = workspace['x_train']\n",
    "    y_train = workspace['y_train']\n",
    "    x_test = workspace['x_test']\n",
    "    y_test = workspace['y_test']\n",
    "    \n",
    "    #model\n",
    "    ###################################################################\n",
    "    # Get the predictions for the training and testing samples\n",
    "    ###################################################################\n",
    "    decisions = []\n",
    "    for X, y in ((x_train, y_train), (x_test, y_test)):\n",
    "\n",
    "      # Use the outcome to select the truth information (>0.5 or <0.5)\n",
    "      d1 = model.predict_proba(X[y == '998'])[:, 1]\n",
    "      d2 = model.predict_proba(X[y == '-999'])[:, 1]\n",
    "      decisions += [d1, d2]\n",
    "    \n",
    "    # Use this for the histogram ranges\n",
    "    low = min(np.min(d) for d in decisions)\n",
    "    high = max(np.max(d) for d in decisions)\n",
    "    low_high = (low, high)\n",
    "    \n",
    "    \n",
    "    #print(decisions)\n",
    "    ###################################################################\n",
    "    # Make a plot of the training sample predictions\n",
    "    ###################################################################\n",
    "\n",
    "    bins = 50\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(decisions[0],\n",
    "              color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "              histtype='stepfilled', density=True,\n",
    "              label='Bkg (train)')\n",
    "    plt.hist(decisions[1],\n",
    "              color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "              histtype='stepfilled', density=True,\n",
    "              label='Sig (train)')\n",
    "    \n",
    "    \n",
    "    # Make a plot with error bars for the testing samples\n",
    "    hists, bins = np.histogram(decisions[2],density=True,\n",
    "                              bins=bins, range=low_high)\n",
    "    scale = len(decisions[2]) / sum(hists)\n",
    "    err = np.sqrt(hists * scale) / scale\n",
    "    \n",
    "    width = (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    plt.errorbar(center, hists, yerr=err, fmt='o', c='r', label='Bkg (test)')\n",
    "    \n",
    "    hists, bins = np.histogram(decisions[3],density=True,\n",
    "                              bins=bins, range=low_high)\n",
    "    scale = len(decisions[2]) / sum(hists)\n",
    "    err = np.sqrt(hists * scale) / scale\n",
    "    \n",
    "    plt.errorbar(center, hists, yerr=err, fmt='o', c='b', label='Sig (test)')\n",
    "    \n",
    "    plt.xlabel(\"Classifer output\")\n",
    "    plt.ylabel(\"Arbitrary units\")\n",
    "    plt.legend(loc='best')\n",
    "\n",
    "    # Confusion matrix\n",
    "    # Testing the model i.e. predicting the labels of the test data.\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Evaluating the results of the model\n",
    "    accuracy = accuracy_score(y_test,y_pred)*100 ### returns the fraction of correctly classified samples \n",
    "    confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "    print(\"Accuracy for Neural Network is:\",accuracy)\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_mat)\n",
    "    \n",
    "    tot_correct= confusion_mat[1][1] + confusion_mat[0][0]\n",
    "    tot_wrong= confusion_mat[1][0] + confusion_mat[0][1]\n",
    "    \n",
    "    #print(tot_correct/(tot_correct+tot_wrong))\n",
    "    \n",
    "    ## The accuracy score is the total number classified correctly over the total number of classifications \n",
    "\n",
    "\n",
    "    # Turn this into a dataframe\n",
    "    matrix_df = pd.DataFrame(confusion_mat)\n",
    "    \n",
    "    # Plot the result\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    \n",
    "    sns.set(font_scale=1.3)\n",
    "    \n",
    "    sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "    \n",
    "    #labels = df['target_names'].tolist()\n",
    "    labels = ['998', '-999'] # NEED TO FIX THIS SO IT IS NOT HARDCODED\n",
    "    \n",
    "    # Formatting details here\n",
    "    # Set axis titles\n",
    "    ax.set_title('Confusion Matrix - MLP')\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "    ax.set_yticklabels(labels, rotation = 0)\n",
    "    #plt.show()\n",
    "\n",
    "    # ROC\n",
    "\n",
    "    decisions = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    ###################################################################\n",
    "    # Compute ROC curve and area under the curve\n",
    "    ###################################################################\n",
    "\n",
    "    sig_bkg = np.ones_like(y_test, dtype=int)\n",
    "    sig_bkg[y_test=='-999'] = 0\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(sig_bkg, decisions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % (roc_auc))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71286c3-fee2-4585-a5bc-077f0c1af73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"\"\"\"\n",
    "def add_probas_to_dfs(workspace, df_col, df_sp):\n",
    "\n",
    "    model = workspace['model']\n",
    "    x_train = workspace['x_train']\n",
    "    y_train = workspace['y_train']\n",
    "    x_test = workspace['x_test']\n",
    "    y_test = workspace['y_test']\n",
    "\n",
    "    #idx_x_train     = workspace['idx_sig_train']\n",
    "    #idx_x_not_train = workspace['idx_sig_not_train']\n",
    "\n",
    "    # Get the training vars\n",
    "    training_vars = model.feature_names\n",
    "\n",
    "    print(\"Training vars: \")\n",
    "    print(training_vars)\n",
    "    print(len(training_vars))\n",
    "\n",
    "    remove_these = ['proba', 'used_in_sig_train', 'used_in_bkg_train']\n",
    "    print(type(training_vars))\n",
    "    for r in remove_these:\n",
    "        print(f\"Checking for {r}...\")\n",
    "        if sum(training_vars.isin([r]).astype(int))>0:\n",
    "            idx = training_vars.get_loc(r)\n",
    "            print(idx, training_vars)\n",
    "            training_vars = training_vars.delete(idx)\n",
    "            print(training_vars)\n",
    "            print(f\"removed {r}\")\n",
    "    \n",
    "    #x_train = df_col[training_vars]#[idx_x_train]\n",
    "\n",
    "    #### FOR SP \n",
    "    #for i in threshold:\n",
    "    #    output_df= see_stuff(sig_samp= sig_samp,bkg_samp= bkg_samp, thresh= i, verbose= False, df=MC_data, df_col=coll_data)\n",
    "\n",
    "    # 3. Scale the test data using the same scaler\n",
    "    #scaler = StandardScaler()\n",
    "\n",
    "    # SHOULD THIS BE THE ACTUAL TRAINING SP\n",
    "    #x_dummy = scaler.fit_transform(x_train)\n",
    "\n",
    "    #print(x_dummy.T[-1])\n",
    "    #print(len(x_dummy), len(x_dummy[0]))\n",
    "\n",
    "    print(\"training vars after\" )\n",
    "    print(training_vars)\n",
    "    # Collision\n",
    "    x_test  = df_col[training_vars].values#[idx_x_not_train]\n",
    "    print(x_test.T[-1])\n",
    "\n",
    "    #x_test = scaler.transform(x_test)\n",
    "\n",
    "    \n",
    "    proba = model.predict_proba(x_test)\n",
    "\n",
    "    print(\"proba: \")\n",
    "    print(proba)\n",
    "    \n",
    "    df_col['proba'] = proba[:,0]\n",
    "    \n",
    "    print(df_col.columns)\n",
    "\n",
    "    # SP\n",
    "    # Collision\n",
    "    x_test  = df_sp[training_vars].values#[idx_x_not_train]\n",
    "    #x_test = scaler.transform(x_test)\n",
    "\n",
    "    print(x_test)\n",
    "    \n",
    "    proba = model.predict_proba(x_test)\n",
    "\n",
    "    print(\"proba: \")\n",
    "    print(proba)\n",
    "    \n",
    "    df_sp['proba'] = proba[:,0]\n",
    "    \n",
    "    print(df_sp.columns)\n",
    "\n",
    "    idx_bkg_train = workspace['idx_bkg_train']\n",
    "    idx_sig_train = workspace['idx_sig_train']\n",
    "\n",
    "    nentries = len(df_sp)\n",
    "    df_sp['used_in_sig_train'] = np.zeros(nentries, dtype=bool)\n",
    "    df_sp.loc[idx_sig_train, \"used_in_sig_train\"] = True\n",
    "\n",
    "    df_sp['used_in_bkg_train'] = np.zeros(nentries, dtype=bool)\n",
    "    df_sp.loc[idx_bkg_train, 'used_in_bkg_train'] = True\n",
    "\n",
    "    \n",
    "    #x_col_proba = model.predict_proba(df_col_tmp)\n",
    "    \n",
    "    #### FOR COLLISION\n",
    "    #y_proba_col_sig = model.predict_proba()\n",
    "    \n",
    "    #sp998= sp_data[\"spmode\"]== \"998\"\n",
    "    #N_bkg = len(sp_998_df[sp998]) ## total number of background events (sp 998) \n",
    "    #signal_before= len(sp_999_df)\n",
    "    #signal_after= len(sp_999_df)\n",
    "    #efficiency = signal_after/signal_before ## the accuracy of the model after training with the SP \n",
    "    #fom = efficiency(threshold)/(np.sqrt(N_bkg(threshold)+sig_disc/2))\n",
    "    #return fom\n",
    "    return 0\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b855ca4-b1a7-4392-8449-4ee61730223f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb3d360-61cd-468d-9dea-695fcc2239fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3b4310-305c-40a5-ac8c-eaeb64c950c4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667173f-381a-43fe-8e92-bfeff54b4f54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "19b918aa-b2bd-4b23-a0dd-39442d5843f9",
   "metadata": {},
   "source": [
    "# Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff05bf4-f9ee-4f16-b0ac-734b2c2aef34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#BNC_tag = \"\"\n",
    "#BNC_bool = False\n",
    "\n",
    "# BNC\n",
    "BNC_tag = \"_BNC\"\n",
    "BNC_bool = True\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Where are we running this?\n",
    "#####################################################################\n",
    "## Bellis computer\n",
    "#topdir= \"/home/bellis/babar_data/bnv_plambda\"\n",
    "topdir= \"/home/bellis/babar_data_local/bnv_plambda\"\n",
    "\n",
    "if BNC_bool:\n",
    "    #topdir= \"/home/bellis/babar_data/bnv_plambda_bnc\"\n",
    "    topdir= \"/home/bellis/babar_data_local/bnv_plambda_bnc\"\n",
    "\n",
    "## My laptop\n",
    "#topdir= \"/Users/josieswann/BaBar_analyses/BNV_pLambda\"\n",
    "#####################################################################\n",
    "\n",
    "#####################################################################\n",
    "# Get the BNV data\n",
    "#####################################################################\n",
    "#data, data_collision = bat.load_datasets(topdir=topdir, subset='Run1')\n",
    "#data, data_collision = bat.load_datasets(topdir=topdir, subset='all')\n",
    "\n",
    "#####################################################################\n",
    "# Get the BNC data\n",
    "#####################################################################\n",
    "#topdir= \"/home/bellis/babar_data/bnv_plambda_bnc\"\n",
    "data, data_collision = bat.load_datasets(topdir=topdir, BNC=BNC_bool, subset='all')\n",
    "#data, data_collision = bat.load_datasets(topdir=topdir, BNC=True, subset='Run1')\n",
    "#BNC_tag = \"_BNC\"\n",
    "#BNC_bool = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059631db-806e-48df-afc4-21d3906b760d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.columns\n",
    "data.fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4418888-015a-4c70-9585-cf09f58d4913",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[\"BMass\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269b5bee-4526-4b92-8c10-7b35a8edb80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_information= pd.read_csv(\"dataset_statistics.csv\")\n",
    "cs_data= pd.read_csv(\"SP_cross_sections_and_labels.csv\")\n",
    "\n",
    "no_notes= cs_data.drop([\"Uncertainty\",\"Note: cross sections found at https://babar-wiki.heprc.uvic.ca/bbr_wiki/index.php/Physics/Cross_sections,_luminosities,_and_other_vital_stats\"], axis= 1)\n",
    "no_notes\n",
    "\n",
    "sp= data[\"spmode\"]\n",
    "\n",
    "splist= np.unique(sp.to_list())\n",
    "splist\n",
    "\n",
    "'''\n",
    "dcuts= bat.get_final_masks(data, region_definitions= region_definitions)\n",
    "\n",
    "print([dcuts.keys()])\n",
    "print()\n",
    "\n",
    "for key in dcuts.keys():\n",
    "    print(f'{key:3d} {dcuts[key][\"name\"]}')\n",
    "\n",
    "dcuts[3]\n",
    "'''\n",
    "\n",
    "bat.fill_new_entry_with_tag_side_B(data)\n",
    "data[\"BtagSideMes\"]\n",
    "bat.fill_new_entry_with_tag_side_B(data_collision)\n",
    "data_collision[\"BtagSideMes\"]\n",
    "\n",
    "all_hists= bat.create_empty_histograms(hist_defs)\n",
    "\n",
    "bkg_spmodes= [\"998\",\"1005\",\"3981\",\"1235\",\"1237\"]\n",
    "sig_spmodes= [\"-999\"]\n",
    "\n",
    "spmodes= bkg_spmodes+sig_spmodes\n",
    "\n",
    "weights= {}\n",
    "for sp in spmodes: \n",
    "    weights[sp]= bat.scaling_value(int(sp),dataset_information=dataset_information, cs_data= cs_data, plot= False, verbose= False)\n",
    "    #weights[sp]=1\n",
    "\n",
    "weights[\"-999\"]= 1000 #scales signal higher \n",
    "weights[\"0\"]= 1 #idk what this is for;;; ASK\n",
    "\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "176c646f-fc2d-4b45-9130-27f8f8de7d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_sp_data = data['spmode'] == '-999'\n",
    "len(data[mask_sp_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf3e798-d6e2-4cc6-94ca-4b8bdbf85256",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "#mask_event= dcuts[1][\"event\"]\n",
    "#mask_event= dcuts[2][\"event\"]\n",
    "mask_event= dcuts[3][\"event\"]\n",
    "#mask_event= dcuts[4][\"event\"] ## individual cuts\n",
    "#mask_event= dcuts[-1][\"event\"] ## all cuts\n",
    "\n",
    "#mask_event= dcuts[1][\"event\"] & dcuts[2][\"event\"] & dcuts[3][\"event\"] & dcuts[4][\"event\"] ## combo of cuts\n",
    "mask_event= dcuts[1][\"event\"] & dcuts[2][\"event\"] & dcuts[3][\"event\"] ## combo of cuts\n",
    "'''\n",
    "### ASK WHAT THESE MEAN\n",
    "#tag= \"EARLY_CUT\"\n",
    "cuts_tag= \"CUTS_cuts_1_2_3\"\n",
    "\n",
    "#mask= mask_event"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39cae3cc-7635-41a2-9ad2-bbfac05800be",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "          'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "          'R2', 'R2All', \\\n",
    "          'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "          'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "          'BThrustROE']\n",
    "\n",
    "ak_array_type= type(data[\"spmode\"])\n",
    "\n",
    "df_dict={}\n",
    "for var in subset: \n",
    "    x= data[mask][var] ##in each event, cut on the above cuts and pull out the info from each of the variables listed above\n",
    "    if type(x[0]) == ak_array_type:\n",
    "        x= ak.flatten(data[mask][var])\n",
    "    df_dict[var] = x\n",
    "\n",
    "df_out= pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "outfilename= f\"output_variables_{tag}.parquet\"\n",
    "df_out.to_parquet(outfilename)\n",
    "\n",
    "df= df_out\n",
    "\n",
    "df_out\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1762539-eba3-4bc4-9f82-7c9f1b944d37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "filter= df[\"spmode\"]== \"-999\"\n",
    "\n",
    "g= sns.PairGrid(df[filter].sample(500), vars= [\"BpostFitMes\",\"BpostFitDeltaE\"], hue= \"spmode\")\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e91dd6-dc3b-4019-8eb5-b5b2f72fe7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "filter = df['spmode'] != '-999'\n",
    "columns= df.columns\n",
    "\n",
    "#g = sns.PairGrid(df[filter].sample(500), vars=['BpostFitMes', 'BpostFitDeltaE'], hue='spmode')\n",
    "g = sns.PairGrid(df[filter].sample(50), vars=columns[1:6], hue='spmode')\n",
    "\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc41199e-3940-4811-897f-e6e701da26d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "feature_names= columns[1:] ##exclude spmode\n",
    "print(feature_names)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ed5471c-2a64-43d7-9781-a4b554b38b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "dcuts= bat.get_final_masks(data, region_definitions= region_definitions)\n",
    "\n",
    "for key,val in dcuts.items():\n",
    "    print(key, val['name'])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5fd7e1-34f7-49cc-af0f-1163ebd85538",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cut1 = dcuts[1]['event']\n",
    "print(len(cut1))\n",
    "\n",
    "len(dcuts[3]['event'][cut1])\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603dace6-2484-407c-862b-7659ec29b728",
   "metadata": {},
   "source": [
    "# Generate the cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a5b9d7-886d-4e61-bfea-8ee66c01932f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# SP\n",
    "dcuts= bat.get_final_masks(data, region_definitions= region_definitions)\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "# Collision\n",
    "dcuts_col= bat.get_final_masks(data_collision, region_definitions= region_definitions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bcd48d-2600-4efc-8d33-39fe50acca3f",
   "metadata": {},
   "source": [
    "## Can start here when re-running a training session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0fe53c-2cff-4d5d-8f32-3900ecf5561f",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "      'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "      'R2', 'R2All', \\\n",
    "      'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "      'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "      'BThrustROE', 'BcosthCM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66939f92-25e9-45f8-a0b6-e13d0dcfc97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################\n",
    "# SP\n",
    "mask_event= dcuts[1][\"event\"]# & dcuts[2][\"event\"] & dcuts[3][\"event\"] \n",
    "mask= mask_event\n",
    "\n",
    "df_sp = bat.dump_awkward_to_dataframe(data[mask], fields_to_dump=subset)#, dropna=True)\n",
    "\n",
    "# Put the cuts into the dataframe \n",
    "cut1 = dcuts[1]['event'] # This is the main cut that gets rid of duplicates\n",
    "cuts_to_add = [2, 3, 4, 6, -1]\n",
    "for cut in cuts_to_add:\n",
    "    bools = dcuts[cut]['event']\n",
    "    colname = f'cut_{cut}'\n",
    "    print(colname, len(bools[cut1]), bools[cut1])\n",
    "\n",
    "    df_sp[colname] = bools[cut1]\n",
    "\n",
    "# Drop entries where there are nans\n",
    "print(len(df_sp))\n",
    "df_sp.dropna(inplace=True)\n",
    "print(len(df_sp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94282bbf-b2ac-4357-96ae-4eb941ba025f",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Collision\n",
    "mask_event= dcuts_col[1][\"event\"]# & dcuts[2][\"event\"] & dcuts[3][\"event\"] \n",
    "mask= mask_event\n",
    "\n",
    "df_col = bat.dump_awkward_to_dataframe(data_collision[mask], fields_to_dump=subset)\n",
    "\n",
    "# Put the cuts into the dataframe \n",
    "cut1 = dcuts_col[1]['event'] # This is the main cut that gets rid of duplicates\n",
    "cuts_to_add = [2, 3, 4, 6, -1]\n",
    "for cut in cuts_to_add:\n",
    "    bools = dcuts_col[cut]['event']\n",
    "    colname = f'cut_{cut}'\n",
    "    print(colname, len(bools[cut1]), bools[cut1])\n",
    "\n",
    "    df_col[colname] = bools[cut1]\n",
    "\n",
    "# Drop entries where there are nans\n",
    "print(len(df_col))\n",
    "df_col.dropna(inplace=True)\n",
    "print(len(df_col))\n",
    "\n",
    "\n",
    "df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d0e8a0-996e-413a-92b7-1e69874c1056",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a4a427-eb71-4ed6-ad42-c9a1556b6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp['spmode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "393a97e6-70b3-4645-b8c1-176ed72f8e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "\n",
    "df_sp['spmode'][mask].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b020476d-0363-4a15-acac-629af0bc587c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sp.iloc[1287624]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "062efd28-5302-4340-9da2-f4e84650dfc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_sp['cut_-1'] == True\n",
    "df_sp[mask].hist('BpostFitMes', bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3314bedf-bdfa-4a75-877b-2817c29d1e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################\n",
    "# Test training routine on a small subset\n",
    "###################################################\n",
    "\n",
    "'''\n",
    "mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "\n",
    "df_temp = df_sp[mask]\n",
    "\n",
    "columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                   \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                  'BSphr', 'BThrust']\n",
    "#[\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\"BtagSideMes\"]\n",
    "\n",
    "\n",
    "#model_filename = \"MODEL_MLPClassifier_CUTS_1_2_3_nsig_2000_nbkg_2000_BNC.pkl\"\n",
    "model_filename = f\"MODEL_MLPClassifier_CUTS_1_2_3_nsig_2000_nbkg_2000{BNC_tag}.pkl\"\n",
    "\n",
    "workspace = model_maker(df_temp, columns_to_drop=columns_to_drop, \\\n",
    "                                                      n_sig_bkg=[2000, 2000], model_filename=model_filename)#, \n",
    "\n",
    "model = workspace['model']\n",
    "x_train = workspace['x_train']\n",
    "y_train = workspace['y_train']\n",
    "x_test = workspace['x_test']\n",
    "y_test = workspace['y_test']\n",
    "\n",
    "model\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba2e628-360b-4ec8-b6d0-300d22b628a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment to plot the variables\n",
    "'''\n",
    "# Make a temporary dataframe with the cuts\n",
    "\n",
    "mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "\n",
    "df_temp = df_sp[mask]\n",
    "\n",
    "sp_mask = (df_temp['spmode']=='-999') | (df_temp['spmode']=='998')\n",
    "\n",
    "plot_training_variables(df_temp[sp_mask])\n",
    "'''\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "625e90c8-6da8-4be5-81c8-e3b936b8903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fig,ax = plt.subplots(figsize=(16,16))\n",
    "#mask = df_temp['spmode'] == '998'\n",
    "##corr = df_temp[mask].drop(columns=['spmode']).corr()\n",
    "##corr.style.background_gradient(cmap='coolwarm', axis=None).format(precision=2)\n",
    "\n",
    "#sns.heatmap(df_temp[mask].drop(columns=['spmode']).corr(), center=0, cmap='coolwarm', annot=True, fmt='.2f', annot_kws={\"size\": 8})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "571e6a25-0e62-4eb0-a307-ae2cad459f53",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mask = df_sp['spmode'] == '-999'\n",
    "#corr = df_sp[mask].drop(columns=['spmode']).corr()\n",
    "#corr.style.background_gradient(cmap='coolwarm', axis=None).format(precision=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1007ac4-7624-4727-81dd-07256af9582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac670b31-f2db-4651-8874-5e72d3f4b41a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                   \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                  'BSphr', 'BThrust']\n",
    "#[\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\"BtagSideMes\"]\n",
    "\n",
    "model_filename = \"TEST_MODEL_SAVE.pkl\"\n",
    "workspace = model_maker(df_temp, columns_to_drop=columns_to_drop, \\\n",
    "                                                      n_sig_bkg=[2000, 2000], model_filename=model_filename)#, \n",
    "\n",
    "model = workspace['model']\n",
    "x_train = workspace['x_train']\n",
    "y_train = workspace['y_train']\n",
    "x_test = workspace['x_test']\n",
    "y_test = workspace['y_test']\n",
    "\n",
    "model\n",
    "'''\n",
    "\n",
    "\n",
    "mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "\n",
    "df_temp = df_sp[mask]\n",
    "\n",
    "# Features 1\n",
    "'''\n",
    "columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                   \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                  'BSphr', 'BThrust']\n",
    "'''\n",
    "\n",
    "# Features 2\n",
    "'''\n",
    "columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                   \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                  'BSphr', 'BThrust', 'R2', 'R2All', 'sphericityAll', 'BtagSideMes']\n",
    "'''\n",
    "\n",
    "# Features 3\n",
    "'''\n",
    "columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                   \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                  'BSphr', 'BThrust', 'R2',  'sphericityAll', 'BtagSideMes', \\\n",
    "       'thrustMag', 'sphericityAll', 'BCosSphr', 'BCosThrust', \\\n",
    "                   'thrustCosTh', 'thrustCosThAll', \\\n",
    "       'BR2ROE', \\\n",
    "                  ]\n",
    "'''\n",
    "\n",
    "# Features 4\n",
    "'''\n",
    "columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                   \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                  'BSphr', 'BThrust', 'R2',  'sphericityAll', 'BtagSideMes', \\\n",
    "                  'thrustMag', 'sphericityAll', 'BCosSphr', 'BCosThrust', \\\n",
    "                   'thrustCosTh', 'thrustCosThAll', 'BSphrROE', \\\n",
    "                   'BThrustROE',  'BR2ROE', \\\n",
    "                  ]\n",
    "'''\n",
    "\n",
    "# Features 5\n",
    "#'''\n",
    "columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                   \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                  'BSphr', 'BThrust', 'R2',  'sphericityAll', 'BtagSideMes', \\\n",
    "                  'thrustMag', 'sphericityAll', 'BCosSphr', 'BCosThrust', \\\n",
    "                   'thrustCosTh', 'thrustCosThAll', 'BSphrROE', \\\n",
    "                   'BThrustROE',  'BR2ROE', 'R2All', 'thrustMagAll'\\\n",
    "                  ]\n",
    "#'''\n",
    "\n",
    "\n",
    "#[\"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\",\"BtagSideMes\"]\n",
    "\n",
    "#model_filename = \"TEST_MODEL_SAVE.pkl\"\n",
    "#model_filename = \"MODEL_MLPClassifier_CUTS_1_2_3_nsig_20000_nbkg_20000_BNC.pkl\"\n",
    "\n",
    "ntrain_sig = 30000\n",
    "ntrain_bkg = 30000\n",
    "trial = 4\n",
    "\n",
    "ntrain_tag = f'features_5_nsig_{ntrain_sig}_nbkg_{ntrain_bkg}_trial{trial:0d}'\n",
    "#ntrain_tag = f'features_4_nsig_{ntrain_sig}_nbkg_{ntrain_bkg}_trial{trial:0d}'\n",
    "#ntrain_tag = f'features_3_nsig_{ntrain_sig}_nbkg_{ntrain_bkg}_trial{trial:0d}'\n",
    "#ntrain_tag = f'features_2_nsig_{ntrain_sig}_nbkg_{ntrain_bkg}_trial{trial:0d}'\n",
    "#ntrain_tag = f'nsig_{ntrain_sig}_nbkg_{ntrain_bkg}_trial{trial:0d}'\n",
    "\n",
    "model_filename = f\"MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}_{BNC_tag}.pkl\"\n",
    "\n",
    "workspace = model_maker(df_temp, columns_to_drop=columns_to_drop, \n",
    "                        test_size_pct= 0.3, \\\n",
    "                        n_sig_bkg=[ntrain_sig, ntrain_bkg],\\\n",
    "                        model_filename=model_filename)#, \n",
    "\n",
    "print(f\"Saving to {model_filename}\")\n",
    "\n",
    "model = workspace['model']\n",
    "x_train = workspace['x_train']\n",
    "y_train = workspace['y_train']\n",
    "x_test = workspace['x_test']\n",
    "y_test = workspace['y_test']\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "122352cd-96e7-45f4-8882-355263c7f08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab29c60d-b838-4306-9085-e1018a9ce4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace = joblib.load(model_filename)\n",
    "#workspace\n",
    "\n",
    "model = workspace['model']\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a009e8b-e3b7-46d2-a215-d42922060401",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace\n",
    "\n",
    "### Not done yet "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e428ec5-838e-45b7-bbe1-d06e0e66ca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([10, 20, 30, 40])\n",
    "np.random.shuffle(x)\n",
    "\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707aaaae-9eca-4990-9d12-047b91bdb1b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90250c50-5417-4978-acf0-0a572717eb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#workspace = joblib.load(model_filename)\n",
    "\n",
    "#model_training_quality(workspace)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f70bb-d593-43a7-b3d8-bb587878bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sp.loc(1287624)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389cf0c0-6a6a-4cec-b277-2ae2703b778a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "#workspace['\n",
    "idx_sig_train = workspace['idx_sig_train']\n",
    "\n",
    "print(len(df_sp))\n",
    "\n",
    "print(max(idx_sig_train))\n",
    "\n",
    "#df_sp.loc[idx_sig_train, \"used_in_sig_train\"] = True\n",
    "\n",
    "print(len(df_sp.index), len(idx_sig_train))\n",
    "print()\n",
    "print()\n",
    "\n",
    "\n",
    "for idx in idx_sig_train[0:1000]:\n",
    "    print(idx)\n",
    "    print(df_sp.loc[idx]['spmode'])\n",
    "\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a199c8d-89c1-433d-8adf-be417692ba9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sp.iloc[1286295]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b3f40-1db2-4ded-934a-936d6ec8d430",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "x = df_col.columns\n",
    "\n",
    "print(len(x),x)\n",
    "idx = x.get_loc('proba')\n",
    "\n",
    "x  = x.delete(idx)\n",
    "\n",
    "print(len(x),x)\n",
    "\n",
    "boolvals = x.isin(['prob']).astype(int)\n",
    "\n",
    "print(sum(boolvals))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d01fb74-faa9-42c4-b426-35e12f73023f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#r = np.random.random(10)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb5b93-20c2-49d0-b98b-9420fdc3f4b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7147596f-79c5-4fa8-a924-9a673ec7b4ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5327845-9c7d-41c1-a5c1-fbc784c21ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_col.dropna(inplace=True)\n",
    "add_probas_to_dfs(workspace, df_col, df_sp)#.drop(columns=columns_to_drop))\n",
    "\n",
    "\n",
    "df_col#.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf25f826-7ee9-4d29-8229-21d750811b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4326879b-8fb3-400c-83aa-2153604e2fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = f\"DATAFRAME_SP_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "df_sp.to_parquet(outfilename)\n",
    "\n",
    "outfilename = f\"DATAFRAME_COL_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "df_col.to_parquet(outfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caa206f-cf56-4de9-ad80-7650ead65bf6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3de7e1-2832-4fb2-bbd2-77549dbd54e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = df_col['cut_-1']==True\n",
    "\n",
    "df_col[mask]['proba'].hist(bins=25, range=(0,0.99))\n",
    "#plt.yscale('log')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7efcbeac-7a9a-4218-a41b-ba3f021c9607",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(workspace.keys())\n",
    "workspace['idx_sig_not_train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba0c8a-aed5-4a00-9e5b-5345d2362579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for i in range(0,3):\n",
    "\n",
    "#idx = workspace['idx_sig_not_train']\n",
    "idx = workspace['idx_bkg_not_train']\n",
    "\n",
    "print(len(idx), len(df_sp))\n",
    "\n",
    "print(type(idx),idx)\n",
    "\n",
    "if len(idx)>0:\n",
    "    print(max(idx))\n",
    "\n",
    "print(df_sp.index)\n",
    "print(max(df_sp.index))\n",
    "#df_sp.loc[100240]\n",
    "df_tmp = df_sp.loc[idx]\n",
    "\n",
    "#for i in idx:\n",
    "\n",
    "#    print(f\"{i} {df_sp.loc[i].index}\")\n",
    "\n",
    "#'''\n",
    "#spmask = (df_tmp['spmode']=='998')\n",
    "#spmask = (df_tmp['spmode']=='-999')\n",
    "spmask = (df_tmp['spmode']!='-999')\n",
    "\n",
    "mask =   (df_tmp['cut_2']==True) & (df_tmp['cut_3']==True)  & (df_tmp['cut_4']==True)\n",
    "mask = mask & (df_tmp['proba'] > 0.97)\n",
    "\n",
    "#var = 'proba'\n",
    "var = 'BpostFitMes'\n",
    "#df_tmp[var].hist(bins=25)#, range=(0,0.99))\n",
    "df_tmp[spmask & mask][var].hist(bins=25)#, range=(0,0.99))\n",
    "#plt.yscale('log')\n",
    "\n",
    "print(df_tmp[spmask & mask]['spmode'])\n",
    "print(idx[0:10])\n",
    "#df_sp[spmask & mask]['proba'].loc[idx[0:10]]#, range=(0,0.99))\n",
    "\n",
    "print(df_sp.index)\n",
    "#'''\n",
    ";\n",
    "df_tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d28ced3-f8cd-42c7-b56f-20c2bfd1aa92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32c4eaf6-a790-4333-a43f-6aede6e26268",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = workspace['model']\n",
    "\n",
    "x_train = workspace['x_train']\n",
    "y_train = workspace['y_train']\n",
    "y_test = workspace['y_test']\n",
    "\n",
    "#x_train\n",
    "#y_train\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0cdcf5-1264-48f8-b6d5-f63f94e269a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.feature_names = ['hi']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e14e55e-7972-4541-9339-d2e9b55e6398",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741c8e75-a09d-4cc0-85b4-a6522f79d6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dcuts.keys()\n",
    "\n",
    "for key in dcuts.keys():\n",
    "    print(f\"key: {key:3d}   name: {dcuts[key]['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df3b1b3-723f-4970-a69e-61f387281e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def punzi_fom_nn(model_aft_train, sp_data, threshold, sp_998_df, sp_999_df, sig_disc= 4, scaling= 0.3):\n",
    "def punzi_fom_nn(df_sp, df_col, sig_sp_mode='-999', region_definitions = None, sigma = 4.0, BNC=False):\n",
    "\n",
    "    # Collision data\n",
    "    mask = (df_col['cut_-1'] == True) \n",
    "    if BNC is True:\n",
    "        mask = (df_col['cut_2'] == True) \n",
    "        mask = mask & (df_col['cut_3'] == True) \n",
    "        mask = mask & (df_col['cut_4'] == True) \n",
    "        \n",
    "    \n",
    "    df_col_tmp = df_col[mask]\n",
    "\n",
    "    # SP\n",
    "    mask = (df_sp['cut_-1'] == True) \n",
    "    if BNC is True:\n",
    "        mask = (df_sp['cut_2'] == True) \n",
    "        mask = mask & (df_sp['cut_3'] == True) \n",
    "        mask = mask & (df_sp['cut_4'] == True) \n",
    "\n",
    "    mask = mask & (df_sp['spmode'] == sig_sp_mode)\n",
    "    mask = mask & (df_sp['used_in_sig_train'] == False)\n",
    "    df_sp_tmp = df_sp[mask]\n",
    "\n",
    "    meslo = region_definitions['signal MES'][0]\n",
    "    meshi = region_definitions['signal MES'][1]\n",
    "    \n",
    "    delo = region_definitions['signal DeltaE'][0]\n",
    "    dehi = region_definitions['signal DeltaE'][1]\n",
    "\n",
    "    messidelo = region_definitions['sideband MES'][0]\n",
    "    messidehi = region_definitions['sideband MES'][1]\n",
    "    \n",
    "    desidelo1 = region_definitions['sideband 1 DeltaE'][0]\n",
    "    desidehi1 = region_definitions['sideband 1 DeltaE'][1]\n",
    "    \n",
    "    desidelo2 = region_definitions['sideband 2 DeltaE'][0]\n",
    "    desidehi2 = region_definitions['sideband 2 DeltaE'][1]\n",
    "\n",
    "    \n",
    "    fom_dict = {}\n",
    "    fom_dict['thresh'] = []\n",
    "    fom_dict['nbkg_sb1'] = []\n",
    "    fom_dict['nbkg_sb2'] = []\n",
    "    fom_dict['nbkg'] = []\n",
    "    fom_dict['nsig'] = []\n",
    "\n",
    "    # Collision data\n",
    "    mes_col = df_col_tmp['BpostFitMes']\n",
    "    de_col = df_col_tmp['BpostFitDeltaE']\n",
    "\n",
    "    mask1_col = (mes_col>messidelo) & (mes_col<messidehi) & (de_col>desidelo1) & (de_col<desidehi1)    \n",
    "    mask2_col = (mes_col>messidelo) & (mes_col<messidehi) & (de_col>desidelo2) & (de_col<desidehi2)\n",
    "\n",
    "    # SP\n",
    "    mes_sp = df_sp_tmp['BpostFitMes']\n",
    "    de_sp = df_sp_tmp['BpostFitDeltaE']\n",
    "\n",
    "    mask_sp = (mes_sp>meslo) & (mes_sp<meshi) & (de_sp>delo) & (de_sp<dehi)\n",
    "\n",
    "\n",
    "    for thresh in np.arange(0,1,0.01):\n",
    "        \n",
    "        # Collision data\n",
    "        mask_thresh_col = df_col_tmp['proba'] > thresh\n",
    "\n",
    "        nsb1 = len(df_col_tmp[mask1_col & mask_thresh_col])        \n",
    "        nsb2 = len(df_col_tmp[mask2_col & mask_thresh_col])\n",
    "    \n",
    "        # Collision data\n",
    "        mask_thresh_sp = df_sp_tmp['proba'] > thresh\n",
    "\n",
    "        nsig = len(df_sp_tmp[mask_sp & mask_thresh_sp])        \n",
    "    \n",
    "        #print(nsb1, nsb2, nsig)\n",
    "        \n",
    "        fom_dict['thresh'].append(thresh)\n",
    "        fom_dict['nbkg_sb1'].append(nsb1)\n",
    "        fom_dict['nbkg_sb2'].append(nsb2)\n",
    "        #fom_dict['nbkg'].append((nsb1 + nsb2)/2)\n",
    "        fom_dict['nbkg'].append(nsb1 + nsb2)\n",
    "        fom_dict['nsig'].append(nsig)\n",
    "\n",
    "    df_fom = pd.DataFrame.from_dict(fom_dict)\n",
    "    df_fom['sig_pct'] = df_fom['nsig'] / df_fom['nsig'].iloc[0]\n",
    "\n",
    "    sigma = 4.0\n",
    "    \n",
    "    df_fom['fom'] = df_fom['sig_pct'] / (np.sqrt(df_fom['nbkg']) + sigma/2.0)\n",
    "\n",
    "    return df_fom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573f4f2-1c37-4094-925b-2d59c5c4c0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fom = punzi_fom_nn(df_sp, df_col, region_definitions=region_definitions, BNC=BNC_bool)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0799d5ce-9848-4082-9610-28fe36cf535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fom.plot(x='thresh', y='fom')\n",
    "plt.ylabel(\"FOM\")\n",
    "plt.xlabel(\"threshold\")\n",
    "\n",
    "\n",
    "df_fom.plot(x='thresh',y='sig_pct')\n",
    "plt.ylabel(\"$\\%$ signal retained\")\n",
    "plt.xlabel(\"threshold\")\n",
    "\n",
    "\n",
    "df_fom.plot(x='thresh',y='nbkg')\n",
    "plt.ylabel(\"n bkg events\")\n",
    "plt.xlabel(\"threshold\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "942ad3cd-85e2-4218-9d8d-3915b57293ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "fom_max = df_fom['fom'].max()\n",
    "\n",
    "print(fom_max)\n",
    "\n",
    "filter = df_fom['fom'] == fom_max\n",
    "\n",
    "df_fom[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05215e52-a251-40ae-b512-543efbc025a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cut = df_fom[filter]['thresh'].values[0]\n",
    "print(f'max_cut: {max_cut}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7925e0-ff1c-424c-9b46-c08a3b327aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fom.sort_values(by='fom')[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "335c26a2-1c6a-4fc8-a66c-83209d05560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "probacut =max_cut\n",
    "#probacut = 0.90\n",
    "\n",
    "plt.figure(figsize=(8,8))\n",
    "\n",
    "for i in range(0,3):\n",
    "\n",
    "    idx = None\n",
    "    spmode = None\n",
    "    df_tmp = None\n",
    "    \n",
    "    if i==0:\n",
    "        idx = workspace['idx_bkg_not_train']\n",
    "        spmode = '998'\n",
    "        df_tmp = df_sp.loc[idx]\n",
    "\n",
    "    elif i==1:\n",
    "        idx = workspace['idx_sig_not_train']\n",
    "        spmode = '-999'\n",
    "        df_tmp = df_sp.loc[idx]\n",
    "    \n",
    "    elif i==2:\n",
    "        spmode = '0'\n",
    "        df_tmp = df_col\n",
    "    \n",
    "    spmask = (df_tmp['spmode']==spmode)\n",
    "\n",
    "    mask =   (df_tmp['cut_-1']==True)\n",
    "    if BNC_bool:\n",
    "        mask =   (df_tmp['cut_2']==True) & (df_tmp['cut_3']==True)  & (df_tmp['cut_4']==True)\n",
    "\n",
    "    mask = mask & (df_tmp['proba'] > probacut)\n",
    "    \n",
    "    mask = mask & (df_tmp['BpostFitDeltaE']<0.07) & (df_tmp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "    if BNC_bool:\n",
    "        mask = mask & (df_tmp['BpostFitDeltaE']<0.05) & (df_tmp['BpostFitDeltaE']>-0.05)\n",
    "\n",
    "    \n",
    "    #var = 'proba'\n",
    "    var = 'BpostFitMes'\n",
    "\n",
    "    plt.subplot(3,1,i+1)\n",
    "    df_tmp[spmask & mask][var].hist(bins=50, range=(5.2,5.3))#, range=(0,0.99))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deb5570-9e2c-46c1-87cc-aec5b9cf209e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp[['BpostFitMes', 'proba']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "114467bb-178f-4c37-963d-03ca52f9c5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_sp['spmode'] == '998')\n",
    "mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "\n",
    "mask = mask & (df_sp['BpostFitDeltaE']<0.07) & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "if BNC_bool:\n",
    "    mask = mask & (df_sp['BpostFitDeltaE']<0.05) & (df_sp['BpostFitDeltaE']>-0.05)\n",
    "\n",
    "\n",
    "mask = mask & (df_sp['proba'] > max_cut)\n",
    "\n",
    "\n",
    "df_sp[mask].plot.scatter(x='BpostFitMes', y='proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4392f7cd-2fb3-45b7-a8bc-e7927db5521f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp[mask][['BpostFitMes', 'proba']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb680dbc-d3a6-4ede-a88f-8c70cf474be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_sp['spmode'] == '-999')\n",
    "mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "\n",
    "mask = mask & (df_sp['BpostFitDeltaE']<0.05) & (df_sp['BpostFitDeltaE']>-0.05)\n",
    "\n",
    "df_sp[mask].hist('BpostFitMes', bins=500, range=(5.27,5.271))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e1f0b0-6db8-4902-8626-8ddcddde8da9",
   "metadata": {},
   "source": [
    "# Run many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc38ca-9fa3-44f7-80c3-bd37850e8300",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "\n",
    "df_sp[mask]['spmode'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4673246d-ee21-49c6-912a-2bf447636fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_a_full_trial(data, data_collision, features_to_drop=1, ntrain_sig=60000, ntrain_bkg=60000, trial=1):\n",
    "    subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "      'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "      'R2', 'R2All', \\\n",
    "      'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "      'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "      'BThrustROE', 'BcosthCM']\n",
    "\n",
    "    ###################################\n",
    "    # SP\n",
    "    mask_event= dcuts[1][\"event\"]\n",
    "    mask= mask_event\n",
    "    \n",
    "    df_sp = bat.dump_awkward_to_dataframe(data[mask], fields_to_dump=subset)#, dropna=True)\n",
    "    \n",
    "    # Put the cuts into the dataframe \n",
    "    cut1 = dcuts[1]['event'] # This is the main cut that gets rid of duplicates\n",
    "    cuts_to_add = [2, 3, 4, 6, -1]\n",
    "    for cut in cuts_to_add:\n",
    "        bools = dcuts[cut]['event']\n",
    "        colname = f'cut_{cut}'\n",
    "        print(colname, len(bools[cut1]), bools[cut1])\n",
    "    \n",
    "        df_sp[colname] = bools[cut1]\n",
    "    \n",
    "    # Drop entries where there are nans\n",
    "    print(len(df_sp))\n",
    "    df_sp.dropna(inplace=True)\n",
    "    print(len(df_sp))\n",
    "\n",
    "    ###################################################\n",
    "    # Collision\n",
    "    mask_event= dcuts_col[1][\"event\"]# & dcuts[2][\"event\"] & dcuts[3][\"event\"] \n",
    "    mask= mask_event\n",
    "    \n",
    "    df_col = bat.dump_awkward_to_dataframe(data_collision[mask], fields_to_dump=subset)\n",
    "    \n",
    "    # Put the cuts into the dataframe \n",
    "    cut1 = dcuts_col[1]['event'] # This is the main cut that gets rid of duplicates\n",
    "    cuts_to_add = [2, 3, 4, 6, -1]\n",
    "    for cut in cuts_to_add:\n",
    "        bools = dcuts_col[cut]['event']\n",
    "        colname = f'cut_{cut}'\n",
    "        print(colname, len(bools[cut1]), bools[cut1])\n",
    "    \n",
    "        df_col[colname] = bools[cut1]\n",
    "    \n",
    "    # Drop entries where there are nans\n",
    "    print(len(df_col))\n",
    "    df_col.dropna(inplace=True)\n",
    "    print(len(df_col))\n",
    "    \n",
    "    #df_sp\n",
    "\n",
    "    \n",
    "    mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "    \n",
    "    df_temp = df_sp[mask]\n",
    "\n",
    "    columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1']\n",
    "    if features_to_drop==1:\n",
    "        # Features 1\n",
    "        columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                           \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                          'BSphr', 'BThrust']\n",
    "\n",
    "    elif features_to_drop==2:\n",
    "        # Features 2\n",
    "        columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                           \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                          'BSphr', 'BThrust', 'R2', 'R2All', 'sphericityAll', 'BtagSideMes']\n",
    "\n",
    "    elif features_to_drop==3:\n",
    "        # Features 3\n",
    "        columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                           \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                          'BSphr', 'BThrust', 'R2',  'sphericityAll', 'BtagSideMes', \\\n",
    "               'thrustMag', 'sphericityAll', 'BCosSphr', 'BCosThrust', \\\n",
    "                           'thrustCosTh', 'thrustCosThAll', \\\n",
    "               'BR2ROE', \\\n",
    "                          ]\n",
    "\n",
    "    elif features_to_drop==4:\n",
    "        # Features 4\n",
    "        columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                           \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                          'BSphr', 'BThrust', 'R2',  'sphericityAll', 'BtagSideMes', \\\n",
    "                          'thrustMag', 'sphericityAll', 'BCosSphr', 'BCosThrust', \\\n",
    "                           'thrustCosTh', 'thrustCosThAll', 'BSphrROE', \\\n",
    "                           'BThrustROE',  'BR2ROE', \\\n",
    "                          ]\n",
    "    elif features_to_drop==5:\n",
    "        # Features 5\n",
    "        columns_to_drop = ['cut_2', 'cut_3', 'cut_4', 'cut_6', 'cut_-1', \\\n",
    "                           \"spmode\",\"BpostFitMes\",\"BpostFitDeltaE\",\"Lambda0_unc_Mass\", \\\n",
    "                          'BSphr', 'BThrust', 'R2',  'sphericityAll', 'BtagSideMes', \\\n",
    "                          'thrustMag', 'sphericityAll', 'BCosSphr', 'BCosThrust', \\\n",
    "                           'thrustCosTh', 'thrustCosThAll', 'BSphrROE', \\\n",
    "                           'BThrustROE',  'BR2ROE', 'R2All', 'thrustMagAll'\\\n",
    "                      ]\n",
    "\n",
    "    #ntrain_sig = 60000\n",
    "    #ntrain_bkg = 60000\n",
    "    #trial = 4\n",
    "    \n",
    "    ntrain_tag = f'features_{features_to_drop}_nsig_{ntrain_sig}_nbkg_{ntrain_bkg}_trial{trial:0d}'\n",
    "    \n",
    "    model_filename = f\"MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}_{BNC_tag}.pkl\"\n",
    "    \n",
    "    workspace = model_maker(df_temp, columns_to_drop=columns_to_drop, \n",
    "                            test_size_pct= 0.3, \\\n",
    "                            n_sig_bkg=[ntrain_sig, ntrain_bkg],\\\n",
    "                            model_filename=model_filename)#, \n",
    "    \n",
    "    print(f\"Saving to {model_filename}\")\n",
    "    \n",
    "    model = workspace['model']\n",
    "    x_train = workspace['x_train']\n",
    "    y_train = workspace['y_train']\n",
    "    x_test = workspace['x_test']\n",
    "    y_test = workspace['y_test']\n",
    "    \n",
    "    #model\n",
    "    add_probas_to_dfs(workspace, df_col, df_sp)#.drop(columns=columns_to_drop))\n",
    "    \n",
    "    outfilename = f\"DATAFRAME_SP_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "    df_sp.to_parquet(outfilename)\n",
    "    \n",
    "    outfilename = f\"DATAFRAME_COL_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "    df_col.to_parquet(outfilename)\n",
    "\n",
    "    return model, df_col, df_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0e3044-bae0-46d6-94c5-69d620df0cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1,6):\n",
    "    print(f\"--------------------------------------------------\\ntrial {i}\\n-------------------------------------\")\n",
    "    #model, df_col, df_sp = run_a_full_trial(data, data_collision, ntrain_sig=60000, ntrain_bkg=60000, features_to_drop=5, trial=i)\n",
    "    model, df_col, df_sp = run_a_full_trial(data, data_collision, ntrain_sig=30000, ntrain_bkg=30000, features_to_drop=2, trial=i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d694513-d942-4767-ba41-d42b76837b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673295c9-637a-413c-8750-56a66612187d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8573ed6b-6145-41ab-8fb6-a2f3de2b8bf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e269f151-70f0-47ea-bab1-ebe7cd9f5a01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463057d7-374c-400e-8969-f076cf99c2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82bdeda-a6e2-41db-a618-19fa7ea27008",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b809aa-1066-45c7-bff8-1964982967db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0891ae65-ce85-4155-804e-79ddbdbf25e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be685e-d464-441f-8b68-e3a4c02e32a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646f42d4-fab3-49f1-82f4-72a18a96eb53",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0acc3128-8c5f-4719-b1f5-7287c4805e3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0885b274-ba59-4ef7-82dd-b8f76ce078df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb45d2c3-0bc5-4d18-a4a9-ad9fef1a6780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b349b1f-de2c-474b-a19e-902348cd594d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "590114f7-6487-446c-a74e-a82e0f8b5597",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb41ba2e-28d6-4630-a9cb-d6978b036de8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539cb269-7ca7-493b-8223-5bbb9c849068",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f15c0c9-71df-4b7c-b812-f6ebc86dc556",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0505bc09-ba1b-4a7d-bdeb-c8b02d200c56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f85e57ce-4949-4b37-9cb0-670672c3aadc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7b29dce-ff42-4b3f-858f-0470ffa72497",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40af165-cfe2-44af-a6f9-c50149ea7c3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb78feb0-4727-4557-8e89-f0ddc87236e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69e2dc4-c062-42bc-a7fe-0f1288811460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9044803-41a1-463d-b430-2ec11c3fbd4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009e08f4-5856-4340-a6b3-d44af1a59841",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef65a52c-70b9-4036-98ff-6e793b37efc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71103319-bf7d-48cc-aa9b-1fe1405ff71b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e536139b-a519-4339-a0ec-b98db6b91d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebddf8a-bda6-47fb-83aa-5cd8151c5544",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcbf79d-4b39-4e25-a413-67fb4e2c2ac7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1497a41b-ce2a-4a67-8dfb-6146e5722fc2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea383a85-3908-405f-84b8-c3fda9db9bb6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523afe7-1ed8-4839-a3d0-5d0a330eecbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29908328-b703-46c7-9d6d-1751eb217253",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f110f55e-30c6-48e5-bd15-cd994523e3ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39e09b3-9373-4b10-86ef-b86afe039949",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
