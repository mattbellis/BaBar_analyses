{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "412b9c69-5cb4-4bb7-b9fd-19e6ee9dae74",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Drawing from my lecture\n",
    "\n",
    "https://colab.research.google.com/drive/12LHs9cL8-gXKr_ypaNfnwaO9bLF3I9tQ?usp=sharing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04188a2e-7692-4a47-bbfb-352ea7542c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from hist import Hist\n",
    "\n",
    "import babar_analysis_tools as bat\n",
    "\n",
    "from analysis_variables import *\n",
    "\n",
    "import myPIDselector\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad26f079-691b-4903-ac5c-4d268eca7e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "# At Siena\n",
    "#topdir = '/mnt/qnap/babar_data/bnv_plambda'\n",
    "\n",
    "##josie laptop \n",
    "#topdir = \"/Users/josieswann/Desktop/important documents\"\n",
    "\n",
    "# On Bellis' laptop\n",
    "#topdir = '/home/bellis/babar_data/bnv_plambda/'\n",
    "\n",
    "# At Bellis' home\n",
    "topdir = '/home/bellis/babar_data/bnv_plambda'\n",
    "\n",
    "# On Bellis' laptop\n",
    "#topdir = './'\n",
    "\n",
    "filename = f'{topdir}/Background_and_signal_SP_modes_Only_Run_1.parquet'\n",
    "#filename = f'{topdir}/Background_and_signal_SP_modes_All_runs.parquet'\n",
    "\n",
    "data = ak.from_parquet(filename)\n",
    "\n",
    "print(f\"Took {time.time() - start} s\")\n",
    "IS_MC=True\n",
    "\n",
    "\n",
    "#'''\n",
    "# Collision data\n",
    "#filename = f'{topdir}/Background_SP_modes_Only_Run_1.parquet'\n",
    "filename = f'{topdir}/Data_Only_Run_1_BLINDED.parquet'\n",
    "#filename = f'{topdir}/Data_All_runs_BLINDED.parquet'\n",
    "#filename = f'{topdir}/Data_All_runs_BLINDED.parquet'\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "data_collision = ak.from_parquet(filename)\n",
    "#data_collision = ak.from_parquet(filename)\n",
    "\n",
    "print(f\"Took {time.time() - start} s\")\n",
    "\n",
    "print(type(data_collision))\n",
    "#'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f7b80-b3dd-4209-9eca-4f3949efd4d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### information about cross section --> what we'll use to calculate scaling values for histograms \n",
    "\n",
    "dataset_information = pd.read_csv(\"dataset_statistics.csv\")\n",
    "cs_data= pd.read_csv(\"SP_cross_sections_and_labels.csv\")\n",
    "\n",
    "no_notes= cs_data.drop([\"Uncertainty\",\"Note: cross sections found at https://babar-wiki.heprc.uvic.ca/bbr_wiki/index.php/Physics/Cross_sections,_luminosities,_and_other_vital_stats\"], axis= 1)\n",
    "no_notes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8068641a-e203-4390-bc8d-c850a9655e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = data['spmode']\n",
    "\n",
    "np.unique(sp.to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9281ed-65ba-4dfc-a752-06cbf96fe921",
   "metadata": {},
   "outputs": [],
   "source": [
    "region_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ed3af0-1642-4d97-ac05-baea5d8cab8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bat.fill_new_entry_with_tag_side_B(data)\n",
    "data['BtagSideMes']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67aeaa0a-5f4d-4199-b84d-c085662c9cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make our histograms\n",
    "all_hists = bat.create_empty_histograms(hist_defs)\n",
    "\n",
    "bkg_spmodes = ['998', '1005', '1235', '1237', '3981']\n",
    "sig_spmodes = ['-999']\n",
    "\n",
    "spmodes = bkg_spmodes + sig_spmodes\n",
    "\n",
    "weights = {}\n",
    "for sp in spmodes:\n",
    "    weights[sp] = bat.scaling_value(int(sp), dataset_information=dataset_information, cs_data=cs_data, plot=False, verbose=False)\n",
    "    #weights[sp] = 1\n",
    "\n",
    "### bat.scaling_value is in Babar_analysis_tools.py \n",
    "\n",
    "# Scale the signal higher\n",
    "weights['-999'] = 1000\n",
    "weights['0'] = 1\n",
    "\n",
    "print(weights)\n",
    "print()\n",
    "print(spmodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d516dc98-aa3b-422c-a472-d9c794374571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to get the original duplicates mask for any other cuts we might generate outside the function\n",
    "dcuts = bat.get_final_masks(data, region_definitions=region_definitions)\n",
    "\n",
    "print([dcuts.keys()])\n",
    "print()\n",
    "\n",
    "for key in dcuts.keys():\n",
    "    print(f'{key:3d} {dcuts[key][\"name\"]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c3d2e3-ff11-4f5a-b945-47729471a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# Make the masks\n",
    "mask_event = dcuts[3]['event']\n",
    "#mask_event = dcuts[4]['event']\n",
    "#mask_event = dcuts[1]['event']\n",
    "#mask_event = dcuts[-1]['event']\n",
    "#mask_event = dcuts[2]['event'] & dcuts[3]['event'] & dcuts[4]['event']\n",
    "\n",
    "#tag = \"FINAL_CUTS\"\n",
    "tag = \"EARLY_CUT\"\n",
    "\n",
    "mask = mask_event\n",
    "################################################################################\n",
    "subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "          'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "          'R2', 'R2All', \\\n",
    "          'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "          'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "          'BThrustROE']\n",
    "\n",
    "ak_array_type = type(data['spmode'])\n",
    "\n",
    "df_dict = {}\n",
    "for var in subset:\n",
    "    x = data[mask][var]\n",
    "\n",
    "    # If this is nested, then flatten it\n",
    "    if type(x[0]) == ak_array_type:\n",
    "        x = ak.flatten(data[mask][var])\n",
    "        \n",
    "    df_dict[var] = x\n",
    "# Make the plot\n",
    "df_out = pd.DataFrame.from_dict(df_dict)\n",
    "\n",
    "# Write it\n",
    "outfilename = \"output_variables_{tag}.parquet\"\n",
    "df_out.to_parquet(outfilename)\n",
    "\n",
    "df = df_out\n",
    "\n",
    "df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49b1daa-4ce9-4285-90a0-730d987c2473",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('spmode').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e173108-711a-4daa-9fad-4244bd58f7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf74982-7233-4eb8-bc44-4b4996c7190e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a9d16a-9b89-4b30-8806-6bb3154ca228",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df['spmode'] == '-999'\n",
    "\n",
    "g = sns.PairGrid(df[filter].sample(500), vars=['BpostFitMes', 'BpostFitDeltaE'], hue='spmode')\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a116f277-c9c2-4bae-8db6-47666198f867",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "\n",
    "print(columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c562f0df-d1c3-4d11-8ec0-dccd04bb0655",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter = df['spmode'] != '-999'\n",
    "\n",
    "#g = sns.PairGrid(df[filter].sample(500), vars=['BpostFitMes', 'BpostFitDeltaE'], hue='spmode')\n",
    "g = sns.PairGrid(df[filter].sample(50), vars=columns[1:6], hue='spmode')\n",
    "\n",
    "g.map_diag(sns.histplot)\n",
    "g.map_offdiag(sns.scatterplot)\n",
    "g.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cffd0be-9671-442e-be4f-dfd8f696480f",
   "metadata": {},
   "source": [
    "# Neural net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "036affe4-138e-4527-81f0-21dc2187d8c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary sklearn libraries\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "\n",
    "from sklearn.metrics import roc_curve, auc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2075a9-b956-4bc9-aa5b-d19f363dcdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.columns\n",
    "\n",
    "print(columns)\n",
    "\n",
    "feature_names = columns[1:]\n",
    "print(feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "539fe204-892d-4ba8-87aa-d3a2d0a4fb87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('spmode').count()['R2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09591b86-4b8b-4ab7-aee4-200c92d68457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features and target variables\n",
    "#filter = (df['spmode'] == '-999') | (df['spmode'] == '998')  \n",
    "#df_ML = df[filter].dropna().sample(10000)\n",
    "\n",
    "filter_sig = df['spmode'] == '-999'\n",
    "filter_bkg = df['spmode'] == '998'\n",
    "\n",
    "df_sig = df[filter_sig].dropna().sample(2000)\n",
    "df_bkg = df[filter_bkg].dropna().sample(2000)\n",
    "\n",
    "df_ML = pd.concat([df_sig, df_bkg])\n",
    "\n",
    "\n",
    "all_vars = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass',\n",
    "       'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', 'R2', 'R2All',\n",
    "       'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll',\n",
    "       'sphericityAll', 'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2',\n",
    "       'BR2ROE', 'BSphrROE', 'BThrustROE']\n",
    "\n",
    "#vars_to_drop = [\"spmode\", 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass']\n",
    "vars_to_drop = [\"spmode\", 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass','BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', 'R2', 'R2All',\n",
    "       'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll',\n",
    "       'sphericityAll', 'BCosSphr', 'BCosThetaT', 'BCosThrust' ]\n",
    "\n",
    "\n",
    "x = df_ML.drop(columns=vars_to_drop)\n",
    "y = df_ML[\"spmode\"]\n",
    "\n",
    "\n",
    "# Save the feature name and target variables\n",
    "feature_names = x.columns\n",
    "labels = y.unique()\n",
    "\n",
    "print(\"We will train using the following features\")\n",
    "print(feature_names)\n",
    "print()\n",
    "\n",
    "print(\"Our labels (Outcome) are\")\n",
    "print(labels)\n",
    "print()\n",
    "\n",
    "print(\"The dataset (x) is the numbers, without the column names\")\n",
    "print(x)\n",
    "print()\n",
    "\n",
    "print(\"The variable y holds the 'truth' information about each sample\")\n",
    "print(y)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502e8317-62b3-46ea-902a-c82fcbe89330",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and train\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=4)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed5a0f00-f332-4471-b4c4-cc09178ac5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd053c-addc-49c3-bdcf-6e146b89d1ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac35dfa-3811-4620-b06f-8982da55382f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_train[y_train=='-999']))\n",
    "print(len(y_train[y_train=='998']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c1f5d-f86d-417b-ba8e-a053b46ce34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Neural Network Classifier\n",
    "model = MLPClassifier()\n",
    "\n",
    "# Training the model on the training data and labels\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c85030-f4e3-4d78-b006-084e8ea06bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the model i.e. predicting the labels of the test data.\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluating the results of the model\n",
    "accuracy = accuracy_score(y_test,y_pred)*100\n",
    "confusion_mat = confusion_matrix(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bf18e9-5c83-4a4b-b269-9c9d40bc3e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the Results\n",
    "print(\"Accuracy for Neural Network is:\",accuracy)\n",
    "print(\"Confusion Matrix\")\n",
    "print(confusion_mat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ee4ca5-4ccb-4ff5-9713-2ffbd6e7c42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn this into a dataframe\n",
    "matrix_df = pd.DataFrame(confusion_mat)\n",
    "\n",
    "# Plot the result\n",
    "fig, ax = plt.subplots(figsize=(10,7))\n",
    "\n",
    "sns.set(font_scale=1.3)\n",
    "\n",
    "sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "\n",
    "#labels = df['target_names'].tolist()\n",
    "#labels = ['998', '-999'] # NEED TO FIX THIS SO IT IS NOT HARDCODED\n",
    "\n",
    "# Formatting details here\n",
    "# Set axis titles\n",
    "ax.set_title('Confusion Matrix - MLP')\n",
    "ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "ax.set_xticklabels(labels)\n",
    "ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "ax.set_yticklabels(labels, rotation = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8aeda-5f99-47f0-9627-cbc4368738d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the predictions for the training and testing samples\n",
    "\n",
    "decisions = []\n",
    "for X, y in ((X_train, y_train), (X_test, y_test)):\n",
    "\n",
    "  # Use the outcome to select the truth information (>0.5 or <0.5)\n",
    "  d1 = model.predict_proba(X[y == '998'])[:, 1]\n",
    "  d2 = model.predict_proba(X[y == '-999'])[:, 1]\n",
    "  decisions += [d1, d2]\n",
    "\n",
    "# Use this for the histogram ranges\n",
    "low = min(np.min(d) for d in decisions)\n",
    "high = max(np.max(d) for d in decisions)\n",
    "low_high = (low, high)\n",
    "\n",
    "# Make a plot of the training sample predictions\n",
    "bins = 50\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.hist(decisions[0],\n",
    "          color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Pos for diabetes (train)')\n",
    "plt.hist(decisions[1],\n",
    "          color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "          histtype='stepfilled', density=True,\n",
    "          label='Neg for diabetes (train)')\n",
    "\n",
    "\n",
    "# Make a plot with error bars for the testing samples\n",
    "hist, bins = np.histogram(decisions[2],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hist)\n",
    "err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "width = (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "\n",
    "plt.errorbar(center, hist, yerr=err, fmt='o', c='r', label='Pos for diabetes (test)')\n",
    "\n",
    "hist, bins = np.histogram(decisions[3],density=True,\n",
    "                          bins=bins, range=low_high)\n",
    "scale = len(decisions[2]) / sum(hist)\n",
    "err = np.sqrt(hist * scale) / scale\n",
    "\n",
    "plt.errorbar(center, hist, yerr=err, fmt='o', c='b', label='Neg for diabetes (test)')\n",
    "\n",
    "plt.xlabel(\"Classifer output\")\n",
    "plt.ylabel(\"Arbitrary units\")\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e2e77f2-3558-4458-98c3-e7dcfb015737",
   "metadata": {},
   "outputs": [],
   "source": [
    "#decisions\n",
    "#y_test\n",
    "\n",
    "print(y_test)\n",
    "\n",
    "sig_bkg = np.ones_like(y_test, dtype=int)\n",
    "sig_bkg[y_test=='-999'] = 0\n",
    "\n",
    "print(sig_bkg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64859a5-c37b-487f-ba0a-a10c7172bf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "decisions = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Compute ROC curve and area under the curve\n",
    "fpr, tpr, thresholds = roc_curve(sig_bkg, decisions)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % (roc_auc))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5cbcff-44b3-4cf4-9a7f-74ac31febb91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29270cde-5272-4aaa-961f-29b53196f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_plot = X_test.copy()\n",
    "df_plot['spmode'] = y_test.values\n",
    "\n",
    "df_plot\n",
    "\n",
    "print(len(X_test), len(y_test))\n",
    "print(len(df_plot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6942e918-c0e7-4607-bd57-5a790241d564",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows = 5, ncols = 4)    # axes is 2d array (3x3)\n",
    "axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "for ax, col in zip(axes, df_plot.columns):\n",
    "  sns.histplot(df_plot, x=col, ax = ax, hue='spmode', stat='density', common_norm=False)\n",
    "  ax.set_title(col)\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebfe9299-ceaf-4bf1-82e6-0cbd9f8c6330",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78398757-b9d0-4ee4-859e-e24aa7969c9c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd4cce-8c6c-41c6-9166-d3b5405e6c56",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
