{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f0253a24-b397-41ad-b18f-cd9dc2558d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "from hist import Hist\n",
    "\n",
    "import babar_analysis_tools as bat\n",
    "from analysis_variables import *\n",
    "import myPIDselector\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ed45e11f-6791-4be6-a82f-c4f3ff1f255d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.26.4\n",
      "1.26.4\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)\n",
    "\n",
    "print(plt.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "beb1de09-1420-43d4-be1e-8393d6350846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening /home/bellis/babar_data_local/bnv_plambda/Background_and_signal_SP_modes_All_runs.parquet...\n",
      "Took 8.133 seconds\n",
      "\n",
      "Opening /home/bellis/babar_data_local/bnv_plambda/Data_All_runs_UNBLINDED.parquet...\n",
      "Took 1.910 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "BNC_tag = \"\"\n",
    "BNC_bool = False\n",
    "UNBLINDED_bool = True\n",
    "if UNBLINDED_bool is True:\n",
    "    BNC_tag = '_UNBLINDED'\n",
    "\n",
    "# BNC\n",
    "#BNC_tag = \"_BNC\"\n",
    "#BNC_bool = True\n",
    "\n",
    "#####################################################################\n",
    "# Where are we running this?\n",
    "#####################################################################\n",
    "## Bellis computer\n",
    "topdir= \"/home/bellis/babar_data_local/bnv_plambda\"\n",
    "\n",
    "if BNC_bool:\n",
    "    topdir= \"/home/bellis/babar_data/bnv_plambda_bnc\"\n",
    "\n",
    "## My laptop\n",
    "#topdir= \"/Users/josieswann/BaBar_analyses/BNV_pLambda/\"\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Get the BNV data\n",
    "#####################################################################\n",
    "#data, data_collision = bat.load_datasets(topdir=topdir, subset='Run1')\n",
    "data, data_collision = bat.load_datasets(topdir=topdir, subset='all', UNBLINDED=UNBLINDED_bool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e7906b2-d3ed-4571-8e64-ad937bb0aa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bellis/.local/lib/python3.11/site-packages/awkward/_nplikes/array_module.py:292: RuntimeWarning: invalid value encountered in sqrt\n",
      "  return impl(*broadcasted_args, **(kwargs or {}))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'998': 0.2506879075487834, '1005': 0.49619965664110677, '3981': 0.7950555869080849, '1235': 0.3191592629119508, '1237': 0.31492522877218293, '-999': 1000, '0': 1}\n"
     ]
    }
   ],
   "source": [
    "dataset_information= pd.read_csv(\"dataset_statistics.csv\")\n",
    "cs_data= pd.read_csv(\"SP_cross_sections_and_labels.csv\")\n",
    "\n",
    "no_notes= cs_data.drop([\"Uncertainty\",\"Note: cross sections found at https://babar-wiki.heprc.uvic.ca/bbr_wiki/index.php/Physics/Cross_sections,_luminosities,_and_other_vital_stats\"], axis= 1)\n",
    "no_notes\n",
    "\n",
    "sp= data[\"spmode\"]\n",
    "\n",
    "splist= np.unique(sp.to_list())\n",
    "splist\n",
    "\n",
    "'''\n",
    "dcuts= bat.get_final_masks(data, region_definitions= region_definitions)\n",
    "\n",
    "print([dcuts.keys()])\n",
    "print()\n",
    "\n",
    "for key in dcuts.keys():\n",
    "    print(f'{key:3d} {dcuts[key][\"name\"]}')\n",
    "\n",
    "dcuts[3]\n",
    "'''\n",
    "\n",
    "bat.fill_new_entry_with_tag_side_B(data)\n",
    "data[\"BtagSideMes\"]\n",
    "bat.fill_new_entry_with_tag_side_B(data_collision)\n",
    "data_collision[\"BtagSideMes\"]\n",
    "\n",
    "all_hists= bat.create_empty_histograms(hist_defs)\n",
    "\n",
    "bkg_spmodes= [\"998\",\"1005\",\"3981\",\"1235\",\"1237\"]\n",
    "sig_spmodes= [\"-999\"]\n",
    "\n",
    "spmodes= bkg_spmodes+sig_spmodes\n",
    "\n",
    "weights= {}\n",
    "for sp in spmodes: \n",
    "    weights[sp]= bat.scaling_value(int(sp),dataset_information=dataset_information, cs_data= cs_data, plot= False, verbose= False)\n",
    "    #weights[sp]=1\n",
    "\n",
    "weights[\"-999\"]= 1000 #scales signal higher \n",
    "weights[\"0\"]= 1 #idk what this is for;;; ASK\n",
    "\n",
    "print(weights)\n",
    "\n",
    "### ASK WHAT THESE MEAN\n",
    "#tag= \"EARLY_CUT\"\n",
    "cuts_tag= \"CUTS_cuts_1_2_3\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463b8bcf-d0c5-4bdc-89b2-cfe7a480e09d",
   "metadata": {},
   "source": [
    "# Generate cuts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a9e0960-2df6-48af-b28a-27b5d390964d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##################################################\n",
    "# SP\n",
    "dcuts= bat.get_final_masks(data, region_definitions= region_definitions)\n",
    "\n",
    "\n",
    "\n",
    "###################################\n",
    "# Collision\n",
    "dcuts_col= bat.get_final_masks(data_collision, region_definitions= region_definitions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec982d41-a659-4553-ae47-e395a715a828",
   "metadata": {},
   "outputs": [],
   "source": [
    "subset = ['spmode', 'BpostFitMes', 'BpostFitDeltaE', 'Lambda0_unc_Mass', \\\n",
    "      'BtagSideMes', 'BSphr', 'BThrust', 'BCosThetaS', \\\n",
    "      'R2', 'R2All', \\\n",
    "      'thrustMag', 'thrustMagAll', 'thrustCosTh', 'thrustCosThAll', 'sphericityAll', \\\n",
    "      'BCosSphr', 'BCosThetaT', 'BCosThrust', 'BLegendreP2', 'BR2ROE', 'BSphrROE', \\\n",
    "      'BThrustROE', 'BcosthCM']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c54caed5-d27c-4ca9-96a2-2bbab0ff0968",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_2 1347625 [ True False False ...  True  True  True]\n",
      "cut_3 1347625 [ True  True False ...  True  True False]\n",
      "cut_4 1347625 [False False False ...  True False  True]\n",
      "cut_6 1347625 [False False  True ...  True  True False]\n",
      "cut_-1 1347625 [False False False ...  True False False]\n",
      "1347625\n",
      "1345183\n"
     ]
    }
   ],
   "source": [
    "###################################\n",
    "# SP\n",
    "mask_event= dcuts[1][\"event\"]# & dcuts[2][\"event\"] & dcuts[3][\"event\"] \n",
    "mask= mask_event\n",
    "\n",
    "df_sp = bat.dump_awkward_to_dataframe(data[mask], fields_to_dump=subset)#, dropna=True)\n",
    "\n",
    "# Put the cuts into the dataframe \n",
    "cut1 = dcuts[1]['event'] # This is the main cut that gets rid of duplicates\n",
    "cuts_to_add = [2, 3, 4, 6, -1]\n",
    "for cut in cuts_to_add:\n",
    "    bools = dcuts[cut]['event']\n",
    "    colname = f'cut_{cut}'\n",
    "    print(colname, len(bools[cut1]), bools[cut1])\n",
    "\n",
    "    df_sp[colname] = bools[cut1]\n",
    "\n",
    "# Drop entries where there are nans\n",
    "print(len(df_sp))\n",
    "df_sp.dropna(inplace=True)\n",
    "print(len(df_sp))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a83d1fd-ec4f-4ca3-8a26-bc71b5615c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cut_2 725839 [False False False ...  True  True False]\n",
      "cut_3 725839 [ True  True  True ... False  True  True]\n",
      "cut_4 725839 [False False False ... False False False]\n",
      "cut_6 725839 [False  True  True ...  True  True  True]\n",
      "cut_-1 725839 [False False False ... False False False]\n",
      "725839\n",
      "724129\n"
     ]
    }
   ],
   "source": [
    "###################################################\n",
    "# Collision\n",
    "mask_event= dcuts_col[1][\"event\"]# & dcuts[2][\"event\"] & dcuts[3][\"event\"] \n",
    "mask= mask_event\n",
    "\n",
    "df_col = bat.dump_awkward_to_dataframe(data_collision[mask], fields_to_dump=subset)\n",
    "\n",
    "# Put the cuts into the dataframe \n",
    "cut1 = dcuts_col[1]['event'] # This is the main cut that gets rid of duplicates\n",
    "cuts_to_add = [2, 3, 4, 6, -1]\n",
    "for cut in cuts_to_add:\n",
    "    bools = dcuts_col[cut]['event']\n",
    "    colname = f'cut_{cut}'\n",
    "    print(colname, len(bools[cut1]), bools[cut1])\n",
    "\n",
    "    df_col[colname] = bools[cut1]\n",
    "\n",
    "# Drop entries where there are nans\n",
    "print(len(df_col))\n",
    "df_col.dropna(inplace=True)\n",
    "print(len(df_col))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "569e0e09-9ec3-4172-ae24-15784bbd02cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_4_nsig_30000_nbkg_30000_trial15\n",
      "MODEL_MLPClassifier_CUTS_1_2_3_features_4_nsig_30000_nbkg_30000_trial15_.pkl\n",
      "\n",
      "The file 'MODEL_MLPClassifier_CUTS_1_2_3_features_4_nsig_30000_nbkg_30000_trial15_.pkl' exists.\n"
     ]
    }
   ],
   "source": [
    "ntrain_sig = 30000\n",
    "ntrain_bkg = 30000\n",
    "trial = 15\n",
    "features = 4\n",
    "\n",
    "ntrain_tag = f'features_{features}_nsig_{ntrain_sig}_nbkg_{ntrain_bkg}_trial{trial:0d}'\n",
    "\n",
    "print(ntrain_tag)\n",
    "\n",
    "# NO BNC tag in the name\n",
    "model_filename = f\"MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}_.pkl\"\n",
    "\n",
    "print(model_filename)\n",
    "print()\n",
    "\n",
    "#\n",
    "if os.path.exists(model_filename):\n",
    "    print(f\"The file '{model_filename}' exists.\")\n",
    "else:\n",
    "    print(f\"The file '{model_filename}' does not exist.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d10cdce4-81f4-47a4-a419-33c3f00d9611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training vars initially: \n",
      "Index(['BCosThetaS', 'R2All', 'thrustMagAll', 'BCosThetaT', 'BLegendreP2',\n",
      "       'BcosthCM'],\n",
      "      dtype='object')\n",
      "6\n",
      "Checking for proba...\n",
      "Checking for used_in_sig_train...\n",
      "Checking for used_in_bkg_train...\n",
      "Training vars finally: \n",
      "Index(['BCosThetaS', 'R2All', 'thrustMagAll', 'BCosThetaT', 'BLegendreP2',\n",
      "       'BcosthCM'],\n",
      "      dtype='object')\n",
      "6\n",
      "[ 0.17588651  0.5814954  -0.2583879  ...  0.24225366 -0.6445146\n",
      " -0.4060091 ]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/bellis/micromamba/envs/pyhep/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "/home/bellis/micromamba/envs/pyhep/lib/python3.11/site-packages/sklearn/utils/validation.py:2739: UserWarning: X does not have valid feature names, but MLPClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load in the model\n",
    "workspace = joblib.load(model_filename)\n",
    "\n",
    "bat.add_probas_to_dfs(workspace, df_col, df_sp)#.drop(columns=columns_to_drop))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5f04c727-29d3-41d4-84fa-a440bc0d66bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features_4_nsig_30000_nbkg_30000_trial15_UNBLINDED\n"
     ]
    }
   ],
   "source": [
    "print(f'{ntrain_tag}{BNC_tag}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e53c4e9-3288-4720-ac60-dfa3100001d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outfilename = f\"DATAFRAME_SP_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "df_sp.to_parquet(outfilename)\n",
    "\n",
    "outfilename = f\"DATAFRAME_COL_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "df_col.to_parquet(outfilename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b8b354-29f2-4c41-bb38-4bca7ebaabd9",
   "metadata": {},
   "source": [
    "# Read in the files and plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de75a2-4eb2-4064-8470-b3703fb1906e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
