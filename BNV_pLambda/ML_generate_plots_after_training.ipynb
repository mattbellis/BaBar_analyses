{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610f7034-b22d-46f3-96a8-eb5156820c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "from hist import Hist\n",
    "\n",
    "import babar_analysis_tools as bat\n",
    "from analysis_variables import *\n",
    "import myPIDselector\n",
    "\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score \n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "import joblib\n",
    "\n",
    "import math\n",
    "\n",
    "# Some of the negative signs weren't being displayed on axes.\n",
    "plt.rc('axes', unicode_minus=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ce8ebd-d46e-4510-82e0-08b7a7179b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "BNC_tag = \"\"\n",
    "BNC_bool = False\n",
    "#ntrain_tag = 'nsig_20000_nbkg_20000'\n",
    "\n",
    "#BNC_tag = \"_BNC\"\n",
    "#BNC_bool = True\n",
    "\n",
    "#ntrain_tag = 'nsig_30000_nbkg_30000'\n",
    "#ntrain_tag = 'nsig_30000_nbkg_30000_trial6'\n",
    "#ntrain_tag = 'nsig_40000_nbkg_40000_trial0'\n",
    "#ntrain_tag = 'nsig_40000_nbkg_40000_trial1'\n",
    "#ntrain_tag = 'features_2_nsig_40000_nbkg_40000_trial0'\n",
    "#ntrain_tag = 'nsig_60000_nbkg_60000_trial4'\n",
    "#ntrain_tag = 'features_3_nsig_60000_nbkg_60000_trial1'\n",
    "ntrain_tag = 'features_4_nsig_30000_nbkg_30000_trial15'\n",
    "#ntrain_tag = 'features_2_nsig_30000_nbkg_30000_trial1'\n",
    "\n",
    "# Read in the dfs\n",
    "infilename = f\"DATAFRAME_SP_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "df_sp = pd.read_parquet(infilename)\n",
    "\n",
    "infilename = f\"DATAFRAME_COL_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "df_col = pd.read_parquet(infilename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace117a6-ae5e-4d89-bb21-f061651033c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "infilename = f'MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}_{BNC_tag}.pkl'\n",
    "workspace = joblib.load(infilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e0f708-0d99-4ef8-bec9-a1628b9df223",
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace['model'].feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570efed0-c493-4565-b282-a858e83776ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.iloc[62]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cf58d3-0bf3-425f-b09a-bae4e6e0e815",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.iloc[0:20].sample(frac=1, replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19a6c9-5910-49b9-b321-cf3a2dc3b520",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_correlation_matrix_with_bootstrap_uncertainties(data, n_bootstraps=1000):\n",
    "    # 2. Bootstrap Resampling and Correlation Calculation\n",
    "    #n_bootstraps = 1000  # Number of bootstrap samples\n",
    "    bootstrap_correlations = []\n",
    "\n",
    "    # For testing to see the differences with lower statistics\n",
    "    #data = data.iloc[0:50]\n",
    "    \n",
    "    for _ in range(n_bootstraps):\n",
    "        # Resample with replacement\n",
    "        resampled_data = data.sample(frac=1, replace=True)\n",
    "        # Calculate correlation matrix for the resampled data\n",
    "        arr_temp = resampled_data.corr().values\n",
    "        bootstrap_correlations.append(arr_temp)\n",
    "        #print('bootstrap_correlations')\n",
    "        #print(arr_temp)\n",
    "    #print(\"--------------\")\n",
    "    \n",
    "    # Convert list of arrays to a 3D NumPy array\n",
    "    bootstrap_correlations = np.array(bootstrap_correlations)\n",
    "    \n",
    "    # 3. Calculate Uncertainties (e.g., standard deviation)\n",
    "    #mean_correlations = np.mean(bootstrap_correlations, axis=0)\n",
    "    mean_correlations = data.corr()\n",
    "    std_correlations = np.std(bootstrap_correlations, axis=0)\n",
    "\n",
    "    #print('Mean and std correlations')\n",
    "    #print(mean_correlations)\n",
    "    #print(std_correlations)\n",
    "    \n",
    "    # 4. Display Uncertainties (e.g., as a formatted string in a DataFrame)\n",
    "    correlation_matrix_with_uncertainties = pd.DataFrame(\n",
    "        '', index=data.columns, columns=data.columns, dtype=object\n",
    "    )\n",
    "    \n",
    "    for i in range(mean_correlations.shape[0]):\n",
    "        for j in range(mean_correlations.shape[1]):\n",
    "            corr_val = mean_correlations.iloc[i, j]\n",
    "            std_val = std_correlations[i, j]\n",
    "            #print(corr_val, std_val)\n",
    "            correlation_matrix_with_uncertainties.iloc[i, j] = f\"{corr_val:.2f} Â± {std_val:.2f}\"\n",
    "    \n",
    "    print(\"Correlation Matrix with Bootstrap Uncertainties:\")\n",
    "    print(correlation_matrix_with_uncertainties)\n",
    "\n",
    "    return mean_correlations, correlation_matrix_with_uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92551982-9aab-45c0-9537-694fe229ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = './BNV_pLambda_plots/'\n",
    "\n",
    "def plot_training_variables(df, feature_names=None, tag='DEFAULT'):\n",
    "\n",
    "    #########################################################################\n",
    "    # Plot the variables for the different spmodes\n",
    "    #########################################################################\n",
    "\n",
    "    if '0' in list(df['spmode'].unique()):\n",
    "        tag += \"_plus_collision_data\"\n",
    "    print(f\"{tag = }\")\n",
    "\n",
    "    if feature_names is None:\n",
    "        feature_names = list(df.columns)\n",
    "    \n",
    "    print(\"Plotting the training variables...\")\n",
    "    nvars = len(feature_names)\n",
    "    print(f\"Plotting for {nvars} training variables\")\n",
    "    print(feature_names)\n",
    "    print()\n",
    "    print(\"Plotting for the following spmodes\")\n",
    "    print(df['spmode'].unique())\n",
    "\n",
    "    nrows, ncols = 4, 3\n",
    "    if nvars>10:\n",
    "        nrows = 4\n",
    "        ncols = math.ceil(nvars / nrows) \n",
    "    elif nvars==6:\n",
    "        nrows = 2\n",
    "        ncols = math.ceil(nvars / nrows) \n",
    "    elif nvars==4:\n",
    "        nrows = 2\n",
    "        ncols = math.ceil(nvars / nrows) \n",
    "    elif nvars==3:\n",
    "        nrows = 1\n",
    "        ncols = math.ceil(nvars / nrows) \n",
    "    elif nvars==5:\n",
    "        nrows = 2\n",
    "        ncols = math.ceil(nvars / nrows) \n",
    "    else:\n",
    "        nrows = 3\n",
    "        ncols = math.ceil(nvars / nrows) \n",
    "    \n",
    "    print(f\"nrows: {nrows}    ncols: {ncols}\")\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows = nrows, ncols = ncols)    # axes is 2d array (3x3)\n",
    "    axes = axes.flatten()         # Convert axes to 1d array of length 9\n",
    "    fig.set_size_inches(ncols*3, nrows*3)\n",
    "\n",
    "    for ax, col in zip(axes, feature_names):\n",
    "        print(f'Plotting {col}')\n",
    "        if col=='BtagSideMes':\n",
    "            sns.histplot(df, x=col, ax = ax, hue='spmode', stat='density', common_norm=False, binrange=(5.0, 5.3))\n",
    "        else:\n",
    "            sns.histplot(df, x=col, ax = ax, hue='spmode', stat='density', common_norm=False)\n",
    "        plt.setp(ax.get_legend().get_texts(), fontsize='8') # for legend text\n",
    "        plt.setp(ax.get_legend().get_title(), fontsize='8') # for legend title\n",
    "\n",
    "    #ax.set_title(col)\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{save_dir}/training_variables_{tag}.png')\n",
    "\n",
    "    #########################################################################\n",
    "    # Plot the correlation matrices\n",
    "    #########################################################################\n",
    "\n",
    "    spmodes_in_file = df['spmode'].unique()\n",
    "    # Drop the cuts columns\n",
    "    cols = df.columns\n",
    "\n",
    "    cols_temp = []\n",
    "    for col in cols:\n",
    "        #print(col)\n",
    "        if col[0:3]!='cut' and col[0:4]!='used' and col[0:5]!='proba':\n",
    "            cols_temp.append(col)\n",
    "    cols_temp\n",
    "\n",
    "    for spmode in spmodes_in_file:\n",
    "        print(f\"Making the correlation matrix for SP-{spmode}...\")\n",
    "        fig,ax = plt.subplots(figsize=(16,16))\n",
    "        mask = df['spmode'] == spmode\n",
    "        ###############################################\n",
    "        # Drop SP mode only\n",
    "        #sns.heatmap(df[mask][cols_temp].drop(columns=['spmode']).corr(), center=0, cmap='coolwarm', annot=True, fmt='.2f', annot_kws={\"size\": 8})\n",
    "        ###############################################\n",
    "        # Use everything that was used in training\n",
    "        cols_to_use_for_correlation = ['BpostFitMes', 'BpostFitDeltaE'] + feature_names\n",
    "        # Drop SP mode only\n",
    "\n",
    "        # PLOT EVERYTHING ALL TOGETHER\n",
    "        #cols_to_use_for_correlation = cols_temp \n",
    "        #if 'spmode' in cols_temp:\n",
    "        #    cols_temp.remove('spmode')\n",
    "\n",
    "        print(\"HERE IN THE LOOP\")\n",
    "        print(df[mask][cols_to_use_for_correlation].corr())\n",
    "        print()\n",
    "        print(df[mask][['R2All', 'BLegendreP2']].corr())\n",
    "        print()\n",
    "        print(df[mask]['R2All'].min(), df[mask]['BLegendreP2'].min())\n",
    "        print(df[mask]['R2All'].max(), df[mask]['BLegendreP2'].max())\n",
    "\n",
    "        \n",
    "        text_size = 16\n",
    "        ncols = len(cols_to_use_for_correlation) \n",
    "        if ncols>=15:\n",
    "            text_size = 6\n",
    "        elif ncols>=12 and ncols<15:\n",
    "            text_size = 8\n",
    "        elif ncols >= 9 and ncols<12:\n",
    "            text_size = 12\n",
    "\n",
    "        mean_correlations, correlation_matrix_with_uncertainties = \\\n",
    "                generate_correlation_matrix_with_bootstrap_uncertainties(df[mask][cols_to_use_for_correlation], n_bootstraps=1000)\n",
    "        sns.heatmap(mean_correlations, annot=correlation_matrix_with_uncertainties, center=0, \\\n",
    "                    cmap='coolwarm', fmt=\"\", vmin=-1, vmax=1, annot_kws={\"size\": text_size}) # Customize 'fmt' as needed\n",
    "        \n",
    "        # Just the normal correlations\n",
    "        #sns.heatmap(df[mask][cols_to_use_for_correlation].corr(), center=0, cmap='coolwarm', annot=True, fmt='.2f', annot_kws={\"size\": 8})\n",
    "\n",
    "        plt.title(f'Correlation matrix SP {spmode}')        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_dir}/correlation_matrix_{spmode}_{tag}.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c21f35-49c1-49ab-83a2-314323380d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp['spmode'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fcae62a-c6b8-441e-b7fa-491ac1643f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = f'{ntrain_tag}{BNC_tag}'\n",
    "\n",
    "print(tag)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56532f4f-0c23-4fd2-a204-d4b98f9ebb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "mask = (df_sp['spmode']=='-999') | (df_sp['spmode']=='998')\n",
    "sns.histplot(df_sp[mask], x='BtagSideMes', hue='spmode', stat='density', common_norm=False, binrange=(5.0, 5.3))\n",
    "plt.setp(plt.gca().get_legend().get_texts(), fontsize='8') # for legend text\n",
    "plt.setp(plt.gca().get_legend().get_title(), fontsize='8') # for legend title\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6067b912-2d74-477e-8b94-bcf7a080137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a temporary dataframe with the cuts\n",
    "\n",
    "# This worked before\n",
    "'''\n",
    "mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "df_temp = df_sp[mask]\n",
    "sp_mask = (df_temp['spmode']=='-999') | (df_temp['spmode']=='998')\n",
    "feature_names = list(workspace['model'].feature_names)\n",
    "plot_training_variables(df_temp[sp_mask], feature_names = feature_names, tag=tag)\n",
    "'''\n",
    "\n",
    "# This works to produce a data comparison\n",
    "#'''\n",
    "\n",
    "print(len(df_sp), len(df_col))\n",
    "\n",
    "df_stacked = pd.concat([df_sp, df_col], axis=0)\n",
    "print(len(df_stacked))\n",
    "mask = (df_stacked['cut_2']==True) & (df_stacked['cut_3']==True)\n",
    "df_temp = df_stacked[mask]\n",
    "\n",
    "sp_mask = (df_temp['spmode']=='-999') | (df_temp['spmode']=='998') | (df_temp['spmode']=='0')\n",
    "feature_names = list(workspace['model'].feature_names)\n",
    "\n",
    "print(len(df_temp))\n",
    "\n",
    "#print(df_temp[sp_mask])\n",
    "\n",
    "df_for_pts = df_temp[sp_mask].drop(['used_in_sig_train', 'used_in_bkg_train'], axis=1).dropna()\n",
    "\n",
    "# Some weird events in the collision data with R2All is around -10000\n",
    "mask_special = (df_for_pts['R2All']>-1)\n",
    "df_for_pts_v2 = df_for_pts[mask_special]\n",
    "    \n",
    "print(df_for_pts_v2)\n",
    "print('min: ', df_for_pts_v2['R2All'].min())\n",
    "\n",
    "plot_training_variables(df_for_pts_v2, feature_names = feature_names, tag=tag)\n",
    "#'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f74305-df7a-4abe-9fba-b9b120b204ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_for_pts['BCosThetaT']\n",
    "plt.hist(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fe5bb9-1b32-493e-bd3c-b42856047daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.histplot(df_for_pts.dropna(), x='R2All',  hue='spmode', stat='density', common_norm=False)\n",
    "\n",
    "#sns.histplot(df_for_pts.dropna(), x='R2All', stat='density')\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "varx = 'R2All'\n",
    "vary = 'BLegendreP2'\n",
    "\n",
    "for idx,spmode in enumerate(['0', '998']):\n",
    "    filter = df_for_pts['spmode']==spmode\n",
    "    \n",
    "    x = df_for_pts[filter][varx]\n",
    "    y = df_for_pts[filter][vary]\n",
    "    plt.subplot(1,2,1+idx)\n",
    "    plt.plot(x,y,'.', markersize=1, alpha=0.1)\n",
    "\n",
    "    print(df_for_pts[filter][[varx, vary]].corr())\n",
    "\n",
    "#plt.hist(x,bins=100, range=(-11000,0));\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4385328-6c1e-46e8-840f-28996a9b29f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp[['used_in_bkg_train', 'used_in_bkg_train']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b76be6a-55ad-4ddb-a19b-61b4ecf912e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = workspace['model']\n",
    "x_train = workspace['x_train']\n",
    "y_train = workspace['y_train']\n",
    "x_test = workspace['x_test']\n",
    "y_test = workspace['y_test']\n",
    "\n",
    "model.predict_proba(x_train[y_train=='-999'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92f40ee7-e4f5-43b0-8d19-00a7b59818fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "#def model_training_quality(model, x_train, y_train, x_test, y_test):\n",
    "def model_training_quality(workspace, tag='DEFAULT'):\n",
    "    model = workspace['model']\n",
    "    x_train = workspace['x_train']\n",
    "    y_train = workspace['y_train']\n",
    "    x_test = workspace['x_test']\n",
    "    y_test = workspace['y_test']\n",
    "    \n",
    "    #model\n",
    "    ###################################################################\n",
    "    # Get the predictions for the training and testing samples\n",
    "    ###################################################################\n",
    "    decisions = []\n",
    "    for X, y in ((x_train, y_train), (x_test, y_test)):\n",
    "\n",
    "      # Use the outcome to select the truth information (>0.5 or <0.5)\n",
    "      d1 = model.predict_proba(X[y == '998'])[:, 0]\n",
    "      d2 = model.predict_proba(X[y == '-999'])[:, 0]\n",
    "      decisions += [d1, d2]\n",
    "    \n",
    "    # Use this for the histogram ranges\n",
    "    low = min(np.min(d) for d in decisions)\n",
    "    high = max(np.max(d) for d in decisions)\n",
    "    low_high = (low, high)\n",
    "    \n",
    "    \n",
    "    #print(decisions)\n",
    "    ###################################################################\n",
    "    # Make a plot of the training sample predictions\n",
    "    ###################################################################\n",
    "\n",
    "    bins = 50\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(decisions[0],\n",
    "              color='r', alpha=0.5, range=low_high, bins=bins,\n",
    "              histtype='stepfilled', density=True,\n",
    "              label='Bkg (train)')\n",
    "    plt.hist(decisions[1],\n",
    "              color='b', alpha=0.5, range=low_high, bins=bins,\n",
    "              histtype='stepfilled', density=True,\n",
    "              label='Sig (train)')\n",
    "    \n",
    "    \n",
    "    # Make a plot with error bars for the testing samples\n",
    "    hists, bins = np.histogram(decisions[2],density=True,\n",
    "                              bins=bins, range=low_high)\n",
    "    scale = len(decisions[2]) / sum(hists)\n",
    "    err = np.sqrt(hists * scale) / scale\n",
    "    \n",
    "    width = (bins[1] - bins[0])\n",
    "    center = (bins[:-1] + bins[1:]) / 2\n",
    "    \n",
    "    plt.errorbar(center, hists, yerr=err, fmt='o', c='r', label='Bkg (test)')\n",
    "    \n",
    "    hists, bins = np.histogram(decisions[3],density=True,\n",
    "                              bins=bins, range=low_high)\n",
    "    scale = len(decisions[2]) / sum(hists)\n",
    "    err = np.sqrt(hists * scale) / scale\n",
    "    \n",
    "    plt.errorbar(center, hists, yerr=err, fmt='o', c='b', label='Sig (test)')\n",
    "    \n",
    "    plt.xlabel(\"Classifer output\")\n",
    "    plt.ylabel(\"Arbitrary units\")\n",
    "    plt.legend(loc='best')\n",
    "    plt.savefig(f'{save_dir}/classifier_output_{tag}.png')\n",
    "\n",
    "    ################################################################################\n",
    "    # Confusion matrix\n",
    "    # Testing the model i.e. predicting the labels of the test data.\n",
    "    y_pred = model.predict(x_test)\n",
    "    \n",
    "    # Evaluating the results of the model\n",
    "    accuracy = accuracy_score(y_test,y_pred)*100 ### returns the fraction of correctly classified samples \n",
    "    confusion_mat = confusion_matrix(y_test,y_pred)\n",
    "\n",
    "    print(\"Accuracy for Neural Network is:\",accuracy)\n",
    "    print(\"Confusion Matrix\")\n",
    "    print(confusion_mat)\n",
    "    \n",
    "    tot_correct= confusion_mat[1][1] + confusion_mat[0][0]\n",
    "    tot_wrong= confusion_mat[1][0] + confusion_mat[0][1]\n",
    "    \n",
    "    #print(tot_correct/(tot_correct+tot_wrong))\n",
    "    \n",
    "    ## The accuracy score is the total number classified correctly over the total number of classifications \n",
    "\n",
    "\n",
    "    # Turn this into a dataframe\n",
    "    matrix_df = pd.DataFrame(confusion_mat)\n",
    "    \n",
    "    # Plot the result\n",
    "    fig, ax = plt.subplots(figsize=(10,7))\n",
    "    \n",
    "    sns.set(font_scale=1.3)\n",
    "    \n",
    "    sns.heatmap(matrix_df, annot=True, fmt=\"g\", ax=ax, cmap=\"magma\")\n",
    "    \n",
    "    #labels = df['target_names'].tolist()\n",
    "    labels = ['998', '-999'] # NEED TO FIX THIS SO IT IS NOT HARDCODED\n",
    "    \n",
    "    # Formatting details here\n",
    "    # Set axis titles\n",
    "    ax.set_title('Confusion Matrix - MLP')\n",
    "    ax.set_xlabel(\"Predicted label\", fontsize =15)\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_ylabel(\"True Label\", fontsize=15)\n",
    "    ax.set_yticklabels(labels, rotation = 0)\n",
    "    #plt.show()\n",
    "    plt.savefig(f'{save_dir}/confusion_matrix_{tag}.png')\n",
    "\n",
    "    # ROC\n",
    "\n",
    "    decisions = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "    ###################################################################\n",
    "    # Compute ROC curve and area under the curve\n",
    "    ###################################################################\n",
    "\n",
    "    sig_bkg = np.ones_like(y_test, dtype=int)\n",
    "    sig_bkg[y_test=='-999'] = 0\n",
    "\n",
    "    fpr, tpr, thresholds = roc_curve(sig_bkg, decisions)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.plot(fpr, tpr, lw=1, label='ROC (area = %0.2f)' % (roc_auc))\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], '--', color=(0.6, 0.6, 0.6), label='Luck')\n",
    "    plt.xlim([-0.05, 1.05])\n",
    "    plt.ylim([-0.05, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver operating characteristic')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid()\n",
    "    #plt.show()\n",
    "    plt.savefig(f'{save_dir}/roc_curve_{tag}.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7a617-d62d-4432-a689-d81463c5a486",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_training_quality(workspace, tag=tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba82b34f-65b7-4138-8ccf-7317d82f19c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def punzi_fom_nn(model_aft_train, sp_data, threshold, sp_998_df, sp_999_df, sig_disc= 4, scaling= 0.3):\n",
    "def punzi_fom_nn(df_sp, df_col, sig_sp_mode='-999', region_definitions = None, sigma = 4.0, BNC=False):\n",
    "\n",
    "    # Collision data\n",
    "    mask = (df_col['cut_-1'] == True) \n",
    "    if BNC is True:\n",
    "        mask = (df_col['cut_2'] == True) \n",
    "        mask = mask & (df_col['cut_3'] == True) \n",
    "        mask = mask & (df_col['cut_4'] == True) \n",
    "        \n",
    "    \n",
    "    df_col_tmp = df_col[mask]\n",
    "\n",
    "    # SP\n",
    "    mask = (df_sp['cut_-1'] == True) \n",
    "    if BNC is True:\n",
    "        mask = (df_sp['cut_2'] == True) \n",
    "        mask = mask & (df_sp['cut_3'] == True) \n",
    "        mask = mask & (df_sp['cut_4'] == True) \n",
    "\n",
    "    mask = mask & (df_sp['spmode'] == sig_sp_mode)\n",
    "    mask = mask & (df_sp['used_in_sig_train'] == False)\n",
    "    df_sp_tmp = df_sp[mask]\n",
    "\n",
    "    meslo = region_definitions['signal MES'][0]\n",
    "    meshi = region_definitions['signal MES'][1]\n",
    "    \n",
    "    delo = region_definitions['signal DeltaE'][0]\n",
    "    dehi = region_definitions['signal DeltaE'][1]\n",
    "\n",
    "    messidelo = region_definitions['sideband MES'][0]\n",
    "    messidehi = region_definitions['sideband MES'][1]\n",
    "    \n",
    "    desidelo1 = region_definitions['sideband 1 DeltaE'][0]\n",
    "    desidehi1 = region_definitions['sideband 1 DeltaE'][1]\n",
    "    \n",
    "    desidelo2 = region_definitions['sideband 2 DeltaE'][0]\n",
    "    desidehi2 = region_definitions['sideband 2 DeltaE'][1]\n",
    "\n",
    "    # Print statements\n",
    "    print(f'{meslo = }        {meshi = }')\n",
    "    print(f'{messidelo = }    {messidehi = }')\n",
    "    print(f'{delo = }         {dehi = }')\n",
    "    print(f'{desidelo1 = }     {desidehi1 = }')\n",
    "    print(f'{desidelo2 = }     {desidehi2 = }')\n",
    "\n",
    "    \n",
    "    fom_dict = {}\n",
    "    fom_dict['thresh'] = []\n",
    "    fom_dict['nbkg_sb1'] = []\n",
    "    fom_dict['nbkg_sb2'] = []\n",
    "    fom_dict['nbkg'] = []\n",
    "    fom_dict['nsig'] = []\n",
    "\n",
    "    # Collision data\n",
    "    mes_col = df_col_tmp['BpostFitMes']\n",
    "    de_col = df_col_tmp['BpostFitDeltaE']\n",
    "\n",
    "    mask1_col = (mes_col>messidelo) & (mes_col<messidehi) & (de_col>desidelo1) & (de_col<desidehi1)    \n",
    "    mask2_col = (mes_col>messidelo) & (mes_col<messidehi) & (de_col>desidelo2) & (de_col<desidehi2)\n",
    "\n",
    "    # SP\n",
    "    mes_sp = df_sp_tmp['BpostFitMes']\n",
    "    de_sp = df_sp_tmp['BpostFitDeltaE']\n",
    "\n",
    "    mask_sp = (mes_sp>meslo) & (mes_sp<meshi) & (de_sp>delo) & (de_sp<dehi) \n",
    "\n",
    "    for thresh in np.arange(0,1,0.01):\n",
    "        \n",
    "        # Collision data\n",
    "        mask_thresh_col = df_col_tmp['proba'] > thresh\n",
    "\n",
    "        nsb1 = len(df_col_tmp[mask1_col & mask_thresh_col])        \n",
    "        nsb2 = len(df_col_tmp[mask2_col & mask_thresh_col])\n",
    "    \n",
    "        # Collision data\n",
    "        mask_thresh_sp = df_sp_tmp['proba'] > thresh\n",
    "\n",
    "        nsig = len(df_sp_tmp[mask_sp & mask_thresh_sp])        \n",
    "    \n",
    "        #print(nsb1, nsb2, nsig)\n",
    "        \n",
    "        fom_dict['thresh'].append(thresh)\n",
    "        fom_dict['nbkg_sb1'].append(nsb1)\n",
    "        fom_dict['nbkg_sb2'].append(nsb2)\n",
    "        #fom_dict['nbkg'].append((nsb1 + nsb2)/2)\n",
    "        fom_dict['nbkg'].append(nsb1 + nsb2)\n",
    "\n",
    "        fom_dict['nsig'].append(nsig)\n",
    "\n",
    "    df_fom = pd.DataFrame.from_dict(fom_dict)\n",
    "    df_fom['sig_pct'] = df_fom['nsig'] / df_fom['nsig'].iloc[0]\n",
    "\n",
    "    # Number of signal estimation\n",
    "    N_S0 = 20\n",
    "    df_fom['N_S'] = N_S0*df_fom['sig_pct']\n",
    "\n",
    "    #sigma = 4.0\n",
    "    \n",
    "    df_fom['fom'] = df_fom['sig_pct'] / (np.sqrt(df_fom['nbkg']) + sigma/2.0)\n",
    "    df_fom['fom_std'] = df_fom['N_S'] / np.sqrt(df_fom['N_S'] + df_fom['nbkg'])\n",
    "\n",
    "    return df_fom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da8d952-07e6-4173-8d19-b21670e87755",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fom = punzi_fom_nn(df_sp, df_col, region_definitions=region_definitions, BNC=BNC_bool, sigma=4.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "311fca90-6e84-41fd-981b-28a9f9c3c9b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2,figsize=(12,6), sharex=True)\n",
    "\n",
    "df_fom.plot(x='thresh', y='fom', ax=axes[0])\n",
    "df_fom.plot(x='thresh', y='fom_std', ax=axes[1])\n",
    "axes[0].set_ylabel(\"FOM\")\n",
    "#plt.xlabel(\"threshold\")\n",
    "\n",
    "\n",
    "###################################################\n",
    "\n",
    "fig, axes = plt.subplots(3,1,figsize=(9,12), sharex=True)\n",
    "\n",
    "df_fom.plot(x='thresh', y='fom', ax=axes[0])\n",
    "axes[0].set_ylabel(\"FOM\")\n",
    "#plt.xlabel(\"threshold\")\n",
    "\n",
    "\n",
    "df_fom.plot(x='thresh',y='sig_pct', ax=axes[1])\n",
    "axes[1].set_ylabel(\"$\\%$ signal retained\")\n",
    "#plt.xlabel(\"threshold\")\n",
    "\n",
    "\n",
    "df_fom.plot(x='thresh',y='nbkg', ax=axes[2])\n",
    "axes[2].set_ylabel(\"# bkg events surviving\")\n",
    "axes[2].set_xlabel(\"NN value\", fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f'{save_dir}/FOM_calculation_{tag}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd48faa4-b3b4-44df-9f2e-147d5c30c414",
   "metadata": {},
   "outputs": [],
   "source": [
    "fom_max = df_fom['fom'].max()\n",
    "\n",
    "print(fom_max)\n",
    "\n",
    "filter = df_fom['fom'] == fom_max\n",
    "\n",
    "df_fom[filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d10ed-e264-4b11-8278-688bf40de0e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_cut = df_fom[filter]['thresh'].values[0]\n",
    "print(f'max_cut: {max_cut}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9e7dce-dcb5-4794-9be3-21cf98c8f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fom.sort_values(by='fom')[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61725e6b-f30a-4761-98c9-99c48b26bd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb808d-4ded-4d2f-937d-ffcaa5d00f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_sp['BCosThetaS']\n",
    "#col = 'BCosThetaT'\n",
    "col = 'BCosThetaS'\n",
    "\n",
    "mask = (df_sp['spmode']=='998') | (df_sp['spmode']=='-999')\n",
    "sns.histplot(df_sp[mask], x=col, hue='spmode', stat='density', common_norm=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58dabf95-2910-4e4b-9766-753f9225b6f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BNV\n",
    "proba_cut = max_cut\n",
    "#proba_cut = 0.00\n",
    "\n",
    "if BNC_bool:\n",
    "    proba_cut = max_cut\n",
    "    #proba_cut = 0.88\n",
    "\n",
    "print(f'{proba_cut = }')\n",
    "\n",
    "fig, axes = plt.subplots(3,1, sharex=True, figsize=(8,8))\n",
    "\n",
    "labels = ['SP - bkg', 'SP - sig', 'Collision data']\n",
    "\n",
    "for i in range(0,3):\n",
    "\n",
    "    idx = None\n",
    "    spmode = None\n",
    "    df_tmp = None\n",
    "    \n",
    "    if i==0:\n",
    "        #idx = workspace['idx_bkg_not_train']\n",
    "        #spmode = '998'\n",
    "        #df_tmp = df_sp.loc[idx]\n",
    "\n",
    "        # Use them all\n",
    "        mask = (~df_sp['used_in_bkg_train']) | (df_sp['used_in_bkg_train'])\n",
    "        spmode = '998'\n",
    "        df_tmp = df_sp[mask]\n",
    "\n",
    "    elif i==1:\n",
    "        #idx = workspace['idx_sig_not_train']\n",
    "        #spmode = '-999'\n",
    "        #df_tmp = df_sp.loc[idx]\n",
    "\n",
    "        mask = (~df_sp['used_in_sig_train'])\n",
    "        spmode = '-999'\n",
    "        df_tmp = df_sp[mask]\n",
    "    \n",
    "    elif i==2:\n",
    "        spmode = '0'\n",
    "        df_tmp = df_col\n",
    "    \n",
    "    spmask = (df_tmp['spmode']==spmode)\n",
    "    if i==0:# Background\n",
    "        spmask = (df_tmp['spmode']!='-999')\n",
    "    \n",
    "    mask =   (df_tmp['cut_-1']==True)\n",
    "    if BNC_bool:\n",
    "        print(\"Making BNC cuts\")\n",
    "        mask = (df_tmp['cut_2']==True) & (df_tmp['cut_3']==True)  & (df_tmp['cut_4']==True)\n",
    "\n",
    "    mask = mask & (df_tmp['proba'] > proba_cut)\n",
    "    #mask = mask & ((df_tmp['BCosThetaT']<-0.8) | (df_tmp['BCosThetaT']>0.999))\n",
    "    #mask = mask & ((df_tmp['BCosThetaS']<-0.9) | (df_tmp['BCosThetaS']>0.999))\n",
    "    \n",
    "    if BNC_bool:\n",
    "        mask = mask & (df_tmp['BpostFitDeltaE']<0.05) & (df_tmp['BpostFitDeltaE']>-0.05)\n",
    "    else:\n",
    "        mask = mask & (df_tmp['BpostFitDeltaE']<0.05) & (df_tmp['BpostFitDeltaE']>-0.05)\n",
    "\n",
    "    #var = 'proba'\n",
    "    var = 'BpostFitMes'\n",
    "\n",
    "    #plt.subplot(3,1,i+1)\n",
    "    df_tmp[spmask & mask][var].hist(bins=50, range=(5.2,5.3), label=labels[i], ax=axes[i])#, range=(0,0.99))\n",
    "    axes[i].legend()\n",
    "axes[2].set_xlabel(r'$M_{ES}$ (GeV/c$^2$)', fontsize=18)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{save_dir}/mes_tight_de_probcut_{proba_cut:.2f}_{tag}{BNC_tag}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea5631-020a-4c4e-a275-b860a0c23292",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp[['BpostFitMes', 'proba']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861184ac-4831-4fbf-a092-442fa29dff3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (~df_sp['used_in_sig_train'])\n",
    "df_tmp = df_sp[mask]\n",
    "\n",
    "spmask = (df_tmp['spmode']=='-999')\n",
    "mask =   (df_tmp['cut_-1']==True)\n",
    "#mask = (df_tmp['cut_2']==True) & (df_tmp['cut_3']==True)  & (df_tmp['cut_4']==True)\n",
    "\n",
    "mask = mask & (df_tmp['proba'] > proba_cut)\n",
    "#mask = mask & ((df_tmp['BCosThetaT']<-0.8) | (df_tmp['BCosThetaT']>0.999))\n",
    "#mask = mask & ((df_tmp['BCosThetaS']<-0.9) | (df_tmp['BCosThetaS']>0.999))\n",
    "\n",
    "mask = mask & (df_tmp['BpostFitDeltaE']<0.05) & (df_tmp['BpostFitDeltaE']>-0.05)\n",
    "\n",
    "df_tmp[mask & spmask].hist('BpostFitMes', bins=100, range=(5.2, 5.3))\n",
    "\n",
    "m1 = df_tmp[mask & spmask]['BpostFitMes'] > 5.27\n",
    "m2 = df_tmp[mask & spmask]['BpostFitMes'] <= 5.27\n",
    "m3 = (df_tmp[mask & spmask]['BpostFitMes'] > 5.27) & (df_tmp[mask & spmask]['BpostFitMes'] < 5.285)\n",
    "m4 = (df_tmp[mask & spmask]['BpostFitMes'] >= 5.285)\n",
    "\n",
    "print(f'{len(m1[m1])}  {len(m2[m2])}    {len(m3[m3])}   {len(m4[m4])}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5a9d0-17d8-44ef-9eae-69ece1d3af4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (df_sp['spmode'] == '998')\n",
    "mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "mask = mask & (df_sp['BpostFitDeltaE']<0.07) & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "mask = mask & (df_sp['proba'] > 0.5)\n",
    "\n",
    "\n",
    "df_sp[mask].plot.scatter(x='BpostFitMes', y='proba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf234bc5-9188-4183-9e3b-f37a438c8914",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "fig,axes = plt.subplots(1,3, figsize=(12,4))\n",
    "\n",
    "# BNV\n",
    "proba_cut = max_cut\n",
    "#proba_cut = 0.0\n",
    "\n",
    "if BNC_bool:\n",
    "    proba_cut = max_cut\n",
    "    #proba_cut = 0.90\n",
    "\n",
    "deloline, dehiline = -0.05, 0.05\n",
    "\n",
    "#de_cut = 0.07\n",
    "de_cut = 0.2\n",
    "\n",
    "# SP bkg\n",
    "mask = (df_sp['spmode'] != '-999')\n",
    "\n",
    "if BNC_bool:\n",
    "    mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "else:\n",
    "    mask = mask &  (df_sp['cut_-1']==True)\n",
    "\n",
    "mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "mask = mask & (df_sp['BpostFitDeltaE']<de_cut) & (df_sp['BpostFitDeltaE']>-de_cut)\n",
    "\n",
    "mask = mask & (df_sp['proba'] > proba_cut)\n",
    "\n",
    "df_sp[mask & (df_sp['spmode']=='998')].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[0])#, label='SP-998')#, label='SP')\n",
    "df_sp[mask & (df_sp['spmode']=='1005')].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[0], c='orange')#, label='SP-1005')#, label='SP')\n",
    "\n",
    "axes[0].plot([5.2, 5.29], [deloline, deloline], 'r--', lw=3)\n",
    "axes[0].plot([5.2, 5.29], [dehiline, dehiline], 'r--', lw=3)\n",
    "#plt.legend()\n",
    "axes[0].set_title(f'Bkg SP (NN > {proba_cut:.2f})')\n",
    "\n",
    "# SP sig\n",
    "mask = (df_sp['spmode'] == '-999')\n",
    "\n",
    "if BNC_bool:\n",
    "    mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "else:\n",
    "    mask = mask &  (df_sp['cut_-1']==True)\n",
    "\n",
    "mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "mask = mask & (df_sp['BpostFitDeltaE']<de_cut) & (df_sp['BpostFitDeltaE']>-de_cut)\n",
    "\n",
    "mask = mask & (df_sp['proba'] > proba_cut)\n",
    "\n",
    "\n",
    "df_sp[mask].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[1], s=0.1, alpha=0.1)#, label='SP')\n",
    "axes[1].plot([5.2, 5.29], [deloline, deloline], 'r--', lw=3)\n",
    "axes[1].plot([5.2, 5.29], [dehiline, dehiline], 'r--', lw=3)\n",
    "axes[1].set_ylim(-0.2, 0.2)\n",
    "#plt.legend()\n",
    "axes[1].set_title(f'Sig SP (NN > {proba_cut:.2f})')\n",
    "\n",
    "\n",
    "# Data\n",
    "mask = (df_col['spmode'] == '0')\n",
    "\n",
    "if BNC_bool:\n",
    "    mask = mask &  (df_col['cut_2']==True) & (df_col['cut_3']==True)  & (df_col['cut_4']==True)\n",
    "else:\n",
    "    mask = mask &  (df_col['cut_-1']==True)\n",
    "\n",
    "\n",
    "mask = mask & (df_col['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "mask = mask & (df_col['BpostFitDeltaE']<de_cut) & (df_col['BpostFitDeltaE']>-de_cut)\n",
    "\n",
    "mask = mask & (df_col['proba'] > proba_cut)\n",
    "\n",
    "\n",
    "df_col[mask].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[2])#, label='Collision data')\n",
    "axes[2].plot([5.2, 5.29], [deloline, deloline], 'r--', lw=3)\n",
    "axes[2].plot([5.2, 5.29], [dehiline, dehiline], 'r--', lw=3)\n",
    "axes[2].set_ylim(-0.2, 0.2)\n",
    "#plt.legend()\n",
    "axes[2].set_title(f'Collision data (NN > {proba_cut:.2f})')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.savefig(f'{save_dir}/sp_and_collision_de_vs_mes_probcut_{proba_cut:.2f}_{tag}{BNC_tag}.png')\n",
    "\n",
    "mask_de = (df_col['BpostFitDeltaE']<0.05) & (df_col['BpostFitDeltaE']>-0.05)\n",
    "df_col[mask & mask_de]['BpostFitMes'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55c9d7f-f314-44fb-804c-a77e28bbe538",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP\n",
    "mask = (df_sp['spmode'] != '-999')\n",
    "\n",
    "# BNC\n",
    "#mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "\n",
    "# BNV\n",
    "mask = mask &  (df_sp['cut_-1']==True)\n",
    "\n",
    "#mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "\n",
    "# Region 1\n",
    "mask = mask & (df_sp['BpostFitMes']>5.20) & (df_sp['BpostFitDeltaE']>-0.05) & (df_sp['BpostFitDeltaE']<0.05)\n",
    "\n",
    "# Region 2\n",
    "#mask = mask & (df_sp['BpostFitMes']>5.27) & (df_sp['BpostFitDeltaE']>-0.20) & (df_sp['BpostFitDeltaE']<0.05)\n",
    "\n",
    "# Region 3\n",
    "#mask = mask & (df_sp['BpostFitMes']>5.27) & (df_sp['BpostFitDeltaE']>-0.05) & (df_sp['BpostFitDeltaE']<0.20)\n",
    "\n",
    "#mask = mask & (df_sp['BpostFitDeltaE']<de_cut) & (df_sp['BpostFitDeltaE']>-de_cut)\n",
    "#mask = mask & (df_sp['BpostFitDeltaE']<de_cut) & (df_sp['BpostFitDeltaE']>-0.05)\n",
    "#mask = mask & (df_sp['BpostFitDeltaE']<0.05) & (df_sp['BpostFitDeltaE']>-de_cut)\n",
    "\n",
    "mask = mask & (df_sp['proba'] > 0.7)\n",
    "\n",
    "#df_sp[mask][['BpostFitMes', 'proba']].corr()\n",
    "print(df_sp[mask][['BpostFitMes', 'proba']].corr())\n",
    "print()\n",
    "print(df_sp[mask][['BpostFitDeltaE', 'proba']].corr())\n",
    "print()\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,3,1)\n",
    "sns.scatterplot(df_sp[mask], x='BpostFitMes', y='BpostFitDeltaE')\n",
    "plt.ylim(-0.2, 0.2)\n",
    "plt.xlim(5.2, 5.3)\n",
    "\n",
    "plt.subplot(1,3,2)\n",
    "sns.scatterplot(df_sp[mask], x='proba', y='BpostFitDeltaE')\n",
    "\n",
    "plt.subplot(1,3,3)\n",
    "\n",
    "#plt.figure()\n",
    "sns.scatterplot(df_sp[mask], x='proba', y='BpostFitMes')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f5c582-4dfd-4651-b4f1-6810b9b94fa2",
   "metadata": {},
   "source": [
    "# Correlations and uncertainties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f68bef38-303b-4d40-8242-d4a98f166459",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "486a7ceb-cb17-40ff-81e5-42492669d8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x,y =  df_sp[mask]['BpostFitMes'].values, df_sp[mask]['proba'].values\n",
    "x,y =  df_sp[mask]['BpostFitDeltaE'].values, df_sp[mask]['proba'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367d01e5-ebdd-45c6-8490-87f4dcbc4355",
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc96c35b-751c-461d-920d-8d49bcd2eb37",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correlation_statistic(x, y):\n",
    "       return np.corrcoef(x, y)[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c8e548-9324-49e3-8a7a-664bdbf0b5f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_statistic(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c8f384-0f3d-4050-94dc-b5746dc0be6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform bootstrap resampling with `scipy.stats.bootstrap`\n",
    "bootstrap_result = bootstrap(\n",
    "   (x, y),\n",
    "   correlation_statistic,\n",
    "   paired=True,\n",
    "   random_state=1,\n",
    "   n_resamples=1000, # Adjust as needed\n",
    "   confidence_level=0.95 # Adjust as needed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057253ef-c5ae-4785-9703-0805958f3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "confidence_interval = bootstrap_result.confidence_interval\n",
    "print(f\"Bootstrap confidence interval: {confidence_interval}\")\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.hist(bootstrap_result.bootstrap_distribution, bins=50)\n",
    "ax.set_title('Bootstrap Distribution')\n",
    "ax.set_xlabel('statistic value')\n",
    "ax.set_ylabel('frequency')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d695c-7b80-4d49-8165-af67c0e8eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#bootstrap_result.bootstrap_distribution[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40173221-4ad7-4ce2-b200-786687ffe377",
   "metadata": {},
   "source": [
    "# Plotting many"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07bfbdca-2204-4683-a1ff-ff295163e17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_trainings(features = 5, nsig = 60000, nbkg = 60000, trials = [1], BNC_tag=\"\", BNC_bool=False, make_features_plots=False):\n",
    "\n",
    "    for trial in trials:\n",
    "    \n",
    "        ntrain_tag = f'features_{features}_nsig_{nsig}_nbkg_{nbkg}_trial{trial}'\n",
    "        tag = f'{ntrain_tag}{BNC_tag}'\n",
    "        \n",
    "        # Read in the dfs\n",
    "        infilename = f\"DATAFRAME_SP_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "        print(f\"Reading in {infilename}\")\n",
    "        df_sp = pd.read_parquet(infilename)\n",
    "        \n",
    "        infilename = f\"DATAFRAME_COL_MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}{BNC_tag}.pkl\"\n",
    "        print(f\"Reading in {infilename}\")\n",
    "        df_col = pd.read_parquet(infilename)\n",
    "\n",
    "        infilename = f'MODEL_MLPClassifier_CUTS_1_2_3_{ntrain_tag}_{BNC_tag}.pkl'\n",
    "        print(f\"Reading in {infilename}\")\n",
    "        workspace = joblib.load(infilename)\n",
    "    \n",
    "        # FOM\n",
    "        df_fom = punzi_fom_nn(df_sp, df_col, region_definitions=region_definitions, BNC=BNC_bool, sigma=4.0)\n",
    "    \n",
    "        fom_max = df_fom['fom'].max()\n",
    "    \n",
    "        #print(fom_max)\n",
    "        \n",
    "        filter = df_fom['fom'] == fom_max\n",
    "        \n",
    "        df_fom[filter]\n",
    "        \n",
    "        max_cut = df_fom[filter]['thresh'].values[0]\n",
    "        print(f'max_cut: {max_cut}')\n",
    "    \n",
    "        # Plot the variables\n",
    "        # Make a temporary dataframe with the cuts\n",
    "        if make_features_plots:\n",
    "            mask = (df_sp['cut_2']==True) & (df_sp['cut_3']==True)\n",
    "            df_temp = df_sp[mask]\n",
    "            sp_mask = (df_temp['spmode']=='-999') | (df_temp['spmode']=='998')\n",
    "            feature_names = list(workspace['model'].feature_names)\n",
    "            plot_training_variables(df_temp[sp_mask], feature_names = feature_names, tag=tag)\n",
    "        \n",
    "\n",
    "        #####################################################\n",
    "        # Quality\n",
    "        #####################################################\n",
    "        model_training_quality(workspace, tag=f'{ntrain_tag}{BNC_tag}')\n",
    "\n",
    "        #####################################################\n",
    "        # FOM stuff\n",
    "        #####################################################\n",
    "        fig, axes = plt.subplots(3,1,figsize=(9,12), sharex=True)\n",
    "        \n",
    "        df_fom.plot(x='thresh', y='fom', ax=axes[0])\n",
    "        axes[0].set_ylabel(\"FOM\")\n",
    "        #plt.xlabel(\"threshold\")\n",
    "        \n",
    "        \n",
    "        df_fom.plot(x='thresh',y='sig_pct', ax=axes[1])\n",
    "        axes[1].set_ylabel(\"$\\%$ signal retained\")\n",
    "        #plt.xlabel(\"threshold\")\n",
    "        \n",
    "        \n",
    "        df_fom.plot(x='thresh',y='nbkg', ax=axes[2])\n",
    "        axes[2].set_ylabel(\"# bkg events surviving\")\n",
    "        axes[2].set_xlabel(\"NN value\", fontsize=18)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'{save_dir}/FOM_calculation_{tag}.png')\n",
    "    \n",
    "        #####################################################\n",
    "        # 2D plots\n",
    "        #####################################################\n",
    "    \n",
    "        fig,axes = plt.subplots(1,3, figsize=(12,4))\n",
    "        \n",
    "        # BNV\n",
    "        proba_cut = max_cut\n",
    "        #proba_cut = 0.0\n",
    "        \n",
    "        if BNC_bool:\n",
    "            proba_cut = max_cut\n",
    "            #proba_cut = 0.90\n",
    "        \n",
    "        deloline, dehiline = -0.05, 0.05\n",
    "        \n",
    "        #de_cut = 0.07\n",
    "        de_cut = 0.2\n",
    "        \n",
    "        # SP bkg\n",
    "        mask = (df_sp['spmode'] != '-999')\n",
    "        \n",
    "        if BNC_bool:\n",
    "            mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "        else:\n",
    "            mask = mask &  (df_sp['cut_-1']==True)\n",
    "        \n",
    "        mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "        \n",
    "        mask = mask & (df_sp['BpostFitDeltaE']<de_cut) & (df_sp['BpostFitDeltaE']>-de_cut)\n",
    "        \n",
    "        mask = mask & (df_sp['proba'] > proba_cut)\n",
    "        \n",
    "        df_sp[mask & (df_sp['spmode']=='998')].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[0])#, label='SP-998')#, label='SP')\n",
    "        df_sp[mask & (df_sp['spmode']=='1005')].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[0], c='orange')#, label='SP-1005')#, label='SP')\n",
    "        \n",
    "        axes[0].plot([5.2, 5.29], [deloline, deloline], 'r--', lw=3)\n",
    "        axes[0].plot([5.2, 5.29], [dehiline, dehiline], 'r--', lw=3)\n",
    "        #plt.legend()\n",
    "        axes[0].set_title(f'Bkg SP (NN > {proba_cut:.2f})')\n",
    "        \n",
    "        # SP sig\n",
    "        mask = (df_sp['spmode'] == '-999')\n",
    "        \n",
    "        if BNC_bool:\n",
    "            mask = mask &  (df_sp['cut_2']==True) & (df_sp['cut_3']==True)  & (df_sp['cut_4']==True)\n",
    "        else:\n",
    "            mask = mask &  (df_sp['cut_-1']==True)\n",
    "        \n",
    "        mask = mask & (df_sp['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "        \n",
    "        mask = mask & (df_sp['BpostFitDeltaE']<de_cut) & (df_sp['BpostFitDeltaE']>-de_cut)\n",
    "        \n",
    "        mask = mask & (df_sp['proba'] > proba_cut)\n",
    "        \n",
    "        \n",
    "        df_sp[mask].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[1], s=0.1, alpha=0.1)#, label='SP')\n",
    "        axes[1].plot([5.2, 5.29], [deloline, deloline], 'r--', lw=3)\n",
    "        axes[1].plot([5.2, 5.29], [dehiline, dehiline], 'r--', lw=3)\n",
    "        axes[1].set_ylim(-0.2, 0.2)\n",
    "        #plt.legend()\n",
    "        axes[1].set_title(f'Sig SP (NN > {proba_cut:.2f})')\n",
    "        \n",
    "        \n",
    "        # Data\n",
    "        mask = (df_col['spmode'] == '0')\n",
    "        \n",
    "        if BNC_bool:\n",
    "            mask = mask &  (df_col['cut_2']==True) & (df_col['cut_3']==True)  & (df_col['cut_4']==True)\n",
    "        else:\n",
    "            mask = mask &  (df_col['cut_-1']==True)\n",
    "        \n",
    "        \n",
    "        mask = mask & (df_col['BpostFitMes']>5.20)# & (df_sp['BpostFitDeltaE']>-0.07)\n",
    "        \n",
    "        mask = mask & (df_col['BpostFitDeltaE']<de_cut) & (df_col['BpostFitDeltaE']>-de_cut)\n",
    "        \n",
    "        mask = mask & (df_col['proba'] > proba_cut)\n",
    "        \n",
    "        \n",
    "        df_col[mask].plot.scatter(x='BpostFitMes', y='BpostFitDeltaE', ax=axes[2])#, label='Collision data')\n",
    "        axes[2].plot([5.2, 5.29], [deloline, deloline], 'r--', lw=3)\n",
    "        axes[2].plot([5.2, 5.29], [dehiline, dehiline], 'r--', lw=3)\n",
    "        axes[2].set_ylim(-0.2, 0.2)\n",
    "        #plt.legend()\n",
    "        axes[2].set_title(f'Collision data (NN > {proba_cut:.2f})')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f'{save_dir}/sp_and_collision_de_vs_mes_probcut_{proba_cut:.2f}_{tag}{BNC_tag}.png')\n",
    "    \n",
    "    \n",
    "        ##########################################\n",
    "        # 1D cuts\n",
    "        ##########################################\n",
    "        \n",
    "        # BNV\n",
    "        proba_cut = max_cut\n",
    "        #proba_cut = 0.00\n",
    "        \n",
    "        if BNC_bool:\n",
    "            proba_cut = max_cut\n",
    "            #proba_cut = 0.88\n",
    "        \n",
    "        print(f'{proba_cut = }')\n",
    "        \n",
    "        fig, axes = plt.subplots(3,1, sharex=True, figsize=(8,8))\n",
    "        \n",
    "        labels = ['SP - bkg', 'SP - sig', 'Collision data']\n",
    "        \n",
    "        for i in range(0,3):\n",
    "        \n",
    "            idx = None\n",
    "            spmode = None\n",
    "            df_tmp = None\n",
    "            \n",
    "            if i==0:\n",
    "                #idx = workspace['idx_bkg_not_train']\n",
    "                #spmode = '998'\n",
    "                #df_tmp = df_sp.loc[idx]\n",
    "        \n",
    "                # Use them all\n",
    "                mask = (~df_sp['used_in_bkg_train']) | (df_sp['used_in_bkg_train'])\n",
    "                spmode = '998'\n",
    "                df_tmp = df_sp[mask]\n",
    "        \n",
    "            elif i==1:\n",
    "                #idx = workspace['idx_sig_not_train']\n",
    "                #spmode = '-999'\n",
    "                #df_tmp = df_sp.loc[idx]\n",
    "        \n",
    "                mask = (~df_sp['used_in_sig_train'])\n",
    "                spmode = '-999'\n",
    "                df_tmp = df_sp[mask]\n",
    "            \n",
    "            elif i==2:\n",
    "                spmode = '0'\n",
    "                df_tmp = df_col\n",
    "            \n",
    "            spmask = (df_tmp['spmode']==spmode)\n",
    "            if i==0:# Background\n",
    "                spmask = (df_tmp['spmode']!='-999')\n",
    "            \n",
    "            mask =   (df_tmp['cut_-1']==True)\n",
    "            if BNC_bool:\n",
    "                print(\"Making BNC cuts\")\n",
    "                mask = (df_tmp['cut_2']==True) & (df_tmp['cut_3']==True)  & (df_tmp['cut_4']==True)\n",
    "        \n",
    "            mask = mask & (df_tmp['proba'] > proba_cut)\n",
    "            #mask = mask & ((df_tmp['BCosThetaT']<-0.8) | (df_tmp['BCosThetaT']>0.999))\n",
    "            #mask = mask & ((df_tmp['BCosThetaS']<-0.9) | (df_tmp['BCosThetaS']>0.999))\n",
    "            \n",
    "            if BNC_bool:\n",
    "                mask = mask & (df_tmp['BpostFitDeltaE']<0.05) & (df_tmp['BpostFitDeltaE']>-0.05)\n",
    "            else:\n",
    "                mask = mask & (df_tmp['BpostFitDeltaE']<0.05) & (df_tmp['BpostFitDeltaE']>-0.05)\n",
    "        \n",
    "            #var = 'proba'\n",
    "            var = 'BpostFitMes'\n",
    "        \n",
    "            #plt.subplot(3,1,i+1)\n",
    "            df_tmp[spmask & mask][var].hist(bins=50, range=(5.2,5.3), label=labels[i], ax=axes[i])#, range=(0,0.99))\n",
    "            axes[i].legend()\n",
    "        \n",
    "        axes[2].set_xlabel(r'$M_{ES}$ (GeV/c$^2$)', fontsize=18)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        plt.savefig(f'{save_dir}/mes_tight_de_probcut_{proba_cut:.2f}_{tag}{BNC_tag}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f2c640-a258-4b22-a52b-f736e876104e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.arange(1,21,1,dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "538ad21a-ed05-4cfe-a6a3-0906c1b2fc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "BNC_tag = \"\"\n",
    "BNC_bool = False\n",
    "\n",
    "#BNC_tag = \"_BNC\"\n",
    "#BNC_bool = True\n",
    "\n",
    "#for idx_feature in [2, 4, 5]:\n",
    "#for idx_feature in [2, 4]:\n",
    "#for idx_feature in [2, 4, 5, 6, 7]:\n",
    "#for idx_feature in [2]:\n",
    "#for idx_feature in [6,7]:\n",
    "for idx_feature in [2, 4, 5, 6, 7, 8]:\n",
    "#for idx_feature in [8]:\n",
    "    \n",
    "    #summarize_trainings(features = idx_feature, nsig = 30000, nbkg = 30000, trials = np.arange(1,21,1,dtype=int), \\\n",
    "    #                    BNC_tag=BNC_tag, BNC_bool=BNC_bool)\n",
    "    summarize_trainings(features = idx_feature, nsig = 30000, nbkg = 30000, trials = np.arange(1,2,1,dtype=int), \\\n",
    "                        BNC_tag=BNC_tag, BNC_bool=BNC_bool, make_features_plots=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d24a52-817f-43da-b5f6-0304e613dcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b68bd573-9ced-49ad-a515-0e17e6bd7d19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830da73d-02de-49f6-bcd8-703620d8d344",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b4628d-af6d-49be-b333-8020083af160",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617db2ed-02d3-4137-a50d-38bced672e74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee79df1-394f-4aee-b575-6e0b491368ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00530c2f-0542-42c3-943b-80e73e66e82d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aed8b8c-4da5-4cbc-9098-7482dcfc2fba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ebf9fc-f644-4d12-8b5d-6d4d35424512",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72613bc-d15f-4c6a-aa31-96d91ab3dae2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fff92799-f2dd-495c-a948-085e22d00c2b",
   "metadata": {},
   "source": [
    "# Boostrap uncertainties on the correlation matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c06fbc-1cbc-40b3-9b12-552d072c67bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(np.random.rand(100, 4), columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "#np.corrcoef(data.T)\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f01764-7a4f-4d58-8d14-f2916f0620f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. Create a sample DataFrame\n",
    "data = pd.DataFrame(np.random.rand(100, 4), columns=['A', 'B', 'C', 'D'])\n",
    "\n",
    "# 2. Bootstrap Resampling and Correlation Calculation\n",
    "n_bootstraps = 1000  # Number of bootstrap samples\n",
    "bootstrap_correlations = []\n",
    "\n",
    "for _ in range(n_bootstraps):\n",
    "    # Resample with replacement\n",
    "    resampled_data = data.sample(frac=1, replace=True)\n",
    "    # Calculate correlation matrix for the resampled data\n",
    "    bootstrap_correlations.append(resampled_data.corr().values)\n",
    "\n",
    "# Convert list of arrays to a 3D NumPy array\n",
    "bootstrap_correlations = np.array(bootstrap_correlations)\n",
    "\n",
    "# 3. Calculate Uncertainties (e.g., standard deviation)\n",
    "#mean_correlations = np.mean(bootstrap_correlations, axis=0)\n",
    "#mean_correlations = np.corrcoef(data.T)\n",
    "mean_correlations = data.corr()\n",
    "print(mean_correlations)\n",
    "\n",
    "std_correlations = np.std(bootstrap_correlations, axis=0)\n",
    "\n",
    "# 4. Display Uncertainties (e.g., as a formatted string in a DataFrame)\n",
    "correlation_matrix_with_uncertainties = pd.DataFrame(\n",
    "    '', index=data.columns, columns=data.columns, dtype=object\n",
    ")\n",
    "\n",
    "for i in range(mean_correlations.shape[0]):\n",
    "    for j in range(mean_correlations.shape[1]):\n",
    "        corr_val = mean_correlations.iloc[i, j]\n",
    "        std_val = std_correlations[i, j]\n",
    "        correlation_matrix_with_uncertainties.iloc[i, j] = f\"{corr_val:.2f} Â± {std_val:.2f}\"\n",
    "\n",
    "print(\"Correlation Matrix with Bootstrap Uncertainties:\")\n",
    "print(correlation_matrix_with_uncertainties)\n",
    "\n",
    "print(type(mean_correlations), type(correlation_matrix_with_uncertainties))\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "#sns.heatmap(mean_correlations, annot=correlation_matrix_with_uncertainties, fmt=\"\", cmap='coolwarm', vmin=-1, vmax=1) # Customize 'fmt' as needed\n",
    "sns.heatmap(mean_correlations, fmt=\"\", cmap='coolwarm', vmin=-1, vmax=1) # Customize 'fmt' as needed\n",
    "\n",
    "plt.title('Correlation Matrix with Bootstrap Confidence Intervals')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c94204-7497-4977-a29a-25e279b55a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_matrix_with_uncertainties.iloc[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
