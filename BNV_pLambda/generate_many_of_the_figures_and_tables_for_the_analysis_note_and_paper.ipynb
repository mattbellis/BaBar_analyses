{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b95adfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import uproot\n",
    "import awkward as ak\n",
    "\n",
    "import matplotlib.pylab as plt\n",
    "import numpy as np\n",
    "\n",
    "import time\n",
    "\n",
    "from hist import Hist\n",
    "\n",
    "import babar_analysis_tools as bat\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from analysis_variables import *\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22acfa0-958c-4bc5-8d72-e82ce2584f6c",
   "metadata": {},
   "source": [
    "# Open the data file or files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9e75f-90bb-4fb8-b5d9-c5bb85d183da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################################\n",
    "# Where are we running this?\n",
    "#####################################################################\n",
    "## Bellis computer\n",
    "topdir= \"/home/bellis/babar_data_local/bnv_plambda\"\n",
    "\n",
    "## My laptop\n",
    "#topdir= \"/Users/josieswann/BaBar_analyses/BNV_pLambda/\"\n",
    "#####################################################################\n",
    "\n",
    "\n",
    "#####################################################################\n",
    "# Get the BNV data\n",
    "#####################################################################\n",
    "data, data_collision = bat.load_datasets(topdir=topdir, subset='Run1')\n",
    "\n",
    "#####################################################################\n",
    "# Get the BNC data\n",
    "#####################################################################\n",
    "#topdir= \"/home/bellis/babar_data/bnv_plambda_bnc\"\n",
    "#data, data_collision = bat.load_datasets(topdir=topdir, BNC=True, subset='all')\n",
    "#data, data_collision = bat.load_datasets(topdir=topdir, BNC=True, subset='Run1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a48f893-739d-4dca-ae06-e869c2cbb5b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362f5d33-3461-476d-9435-6da58c25d3a0",
   "metadata": {},
   "source": [
    "# Plots and tables for signal and blinding area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1696cd3d-0647-4a67-a71b-df07d22a92ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from analysis_variables import *\n",
    "region_definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e179f3a2-1b8c-479a-9a23-4bd78092ab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def table_from_df(df):\n",
    "    output = df.to_latex(index=False,\n",
    "                  float_format=\"{:.4f}\".format,\n",
    "    )  # converts dataframe into latex readable text\n",
    "    full_table = \"\\\\begin{table}\\n\" # initializes the table before the beginning of the tabular \n",
    "    full_table += \"\\\\caption{This could be the caption}\\n\" \n",
    "    full_table += output #includes the converted dataframe in the table\n",
    "    full_table += \"\\\\end{table}\" # ends the table, same purpose as begin{table} \n",
    "    return full_table #make sure to return the print() of the full_table, otherwise it'll be one big string that latex can't handle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be48fe7-4723-4342-973d-72425160e3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd = region_definitions\n",
    "\n",
    "dict_temp = {}\n",
    "dict_temp['Region'] = ['Fitting', 'Blinding']\n",
    "dict_temp['MES low'] = [rd['fitting MES'][0], rd['signal MES'][0]]\n",
    "dict_temp['MES high'] = [rd['fitting MES'][1], rd['signal MES'][1]]\n",
    "\n",
    "dict_temp['DeltaE low'] = [rd['fitting DeltaE'][0], rd['signal DeltaE'][0]]\n",
    "dict_temp['DeltaE high'] = [rd['fitting DeltaE'][1], rd['signal DeltaE'][1]]\n",
    "\n",
    "\n",
    "dftmp = pd.DataFrame.from_dict(dict_temp)\n",
    "\n",
    "dftmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54d41e1-6a48-4c43-8c0a-74496662b95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#table = table_from_df(dftmp)\n",
    "\n",
    "header = ['Region', '$MES$ low', '$MES$ high', '$\\Delta E$ low', '$\\Delta E$ high']\n",
    "\n",
    "output = dftmp.to_latex(index=False, header=header, \n",
    "              float_format=\"{:.2f}\".format,\n",
    ")  # converts dataframe into latex readable text\n",
    "\n",
    "full_table = \"\\\\begin{table}\\n\" # initializes the table before the beginning of the tabular \n",
    "full_table += \"\\\\centering\"\n",
    "full_table += \"\\\\caption{Definition of the fitting region and blinding region for this analysis.\\\\label{tab:def_regions}}\\n\" \n",
    "full_table += output #includes the converted dataframe in the table\n",
    "full_table += \"\\\\end{table}\" # ends the table, same purpose as begin{table} \n",
    "#return full_table #make sure to return the print() of the full_table, otherwise it'll be one big string that latex can't handle\n",
    "\n",
    "table = full_table\n",
    "\n",
    "\n",
    "print(table)\n",
    "\n",
    "outfilename = 'tables/table_def_regions.tex'\n",
    "outfile = open(outfilename, 'w')\n",
    "outfile.write(table)\n",
    "outfile.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612960ab-74bc-4886-bafc-8c05040fe40b",
   "metadata": {},
   "source": [
    "# Tables of dataset statistics\n",
    "\n",
    "Make LaTeX tables for the number of entries in each file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ceaaf5-773e-4ef0-86d3-3a6eba231693",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = bat.create_table_of_data_skims_statistics()\n",
    "\n",
    "print(output)\n",
    "print()\n",
    "\n",
    "# Write it out\n",
    "current_dir= os.getcwd()\n",
    "print(f\"Writing to {current_dir}\")\n",
    "directory = \"tables\"\n",
    "path= os.path.join(current_dir,directory)\n",
    "if os.path.isdir(path)== False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "print(f\"Writing to {directory}\")\n",
    "\n",
    "outfilename = current_dir+\"/\"+directory+\"/table_data_skim_statistics.tex\"\n",
    "outfile = open(outfilename,'w+')\n",
    "outfile.write(output)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a2bcaa-a204-47ec-8412-cfa39e5e7911",
   "metadata": {},
   "outputs": [],
   "source": [
    "### information about cross section --> what we'll use to calculate scaling values for histograms \n",
    "\n",
    "dataset_information = pd.read_csv(\"dataset_statistics.csv\")\n",
    "cs_data= pd.read_csv(\"SP_cross_sections_and_labels.csv\")\n",
    "\n",
    "\n",
    "no_notes= cs_data.drop([\"Uncertainty\",\"Note: cross sections found at https://babar-wiki.heprc.uvic.ca/bbr_wiki/index.php/Physics/Cross_sections,_luminosities,_and_other_vital_stats\"], axis= 1)\n",
    "no_notes\n",
    "\n",
    "bat.table_from_df(no_notes,\"shortened_stats\", \\\n",
    "                  label='tab:shstat', \\\n",
    "                  caption='Summary of meaning of SP mode codes and the relevant cross sections used for scaling Monte Carlo and collision data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af94736-4a44-41b3-b5c8-fccae601da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "cs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a32b32f2-f731-4ef0-8b2e-4e1afebab52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights\n",
    "bkg_spmodes = ['998', '1005', '1235', '1237', '3981']\n",
    "sig_spmodes = ['-999']\n",
    "\n",
    "spmodes = bkg_spmodes + sig_spmodes\n",
    "\n",
    "weights = {}\n",
    "for sp in spmodes:\n",
    "    weights[sp] = bat.scaling_value(int(sp), dataset_information=dataset_information, cs_data=cs_data, plot=False, verbose=False)\n",
    "    #weights[sp] = 1\n",
    "\n",
    "for sp,weight in weights.items():\n",
    "    print(f\"{sp:6s}   {weight:.2f}     {1/weight:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6d5d15-0428-475c-898b-740776d11482",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SP\n",
    "\n",
    "dataset_information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8760b7cb-b176-4d2f-b2d5-27720831fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= bat.read_in_dataset_statistics()\n",
    "dfspinfo = bat.get_SP_cross_sections_and_labels()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c310566e-c1a3-45d0-9964-f7106932de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SP mode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea7b80c-cb94-491a-a345-38b27af1365f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for spmode in [998, 1005]:\n",
    "    \n",
    "    mask = (df['Data or MC']=='MC')# & (df['Skim']=='LambdaVeryVeryLoose')\n",
    "    mask = mask & (df['SP mode']==spmode)\n",
    "    mask1 = mask & (df['Skim']!= 'LambdaVeryVeryLoose')\n",
    "    mask2 = mask & (df['Skim']== 'LambdaVeryVeryLoose')\n",
    "    \n",
    "    nevents_col = '# of events (Data or MC)'\n",
    "    \n",
    "    nevents_org =  df[mask1][nevents_col].sum()\n",
    "    nevents_skim = df[mask2][nevents_col].sum()\n",
    "\n",
    "    wt = weights[str(spmode)]\n",
    "    \n",
    "    print(f'{spmode:6d}   {nevents_org} {nevents_org/1e6:.1f}   {nevents_skim} {nevents_skim/1e6:.1f}   {wt:.2f}  {1/wt:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c7f1ec-dd9b-4797-b988-f6eeef99a054",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table_of_SP_skims_statistics():\n",
    "    df = bat.read_in_dataset_statistics()\n",
    "\n",
    "    dfspinfo = bat.get_SP_cross_sections_and_labels()\n",
    "\n",
    "    mask = dfspinfo['SP Mode']==1235\n",
    "    bbbar_xsec = dfspinfo[mask]['Cross section [nb]'].values[0]\n",
    "\n",
    "    mask = dfspinfo['SP Mode']==1237\n",
    "    bbbar_xsec += dfspinfo[mask]['Cross section [nb]'].values[0]\n",
    "\n",
    "    print(f\"The total BBbar cross section is {bbbar_xsec} nb\")\n",
    "\n",
    "    #mask = df['Data or MC']=='MC'\n",
    "    #df[mask]\n",
    "\n",
    "    mask = (df['Data or MC']=='MC') & (df['Skim']=='LambdaVeryVeryLoose')\n",
    "    dftmp = df[mask][['Run', 'Luminosity (Data only) 1/pb','# of events (Data or MC)', '# of events (Data or MC) NOT SURE WHICH NUMBER TO USE']]\n",
    "\n",
    "    dftmp['# of BBbar pairs'] = dftmp['Luminosity (Data only) 1/pb']*bbbar_xsec*1000\n",
    "\n",
    "    dftmp['Run'] = dftmp['Run'].astype(int).astype(str)\n",
    "    dftmp.loc['Total'] = dftmp.sum(numeric_only=True)\n",
    "\n",
    "    dftmp.at['Total','Run'] = 'Total'\n",
    "\n",
    "    header = []\n",
    "    header.append('Run')\n",
    "    header.append('Luminosity (1/pb)')\n",
    "    header.append('\\# skimmed events')\n",
    "    header.append('\\# org. events')\n",
    "    header.append('\\# BB pairs')\n",
    "\n",
    "    caption = \"Details of the numbers of events and luminosity from the {\\\\tt LambdaVeryVeryLoose} skim used in this analysis.\"\n",
    "    label = 'tab:dataskims'\n",
    "\n",
    "    df.style.to_latex(position_float='centering')\n",
    "\n",
    "    output = dftmp.to_latex(index=False, header=header, float_format=\"%.1f\", caption=caption, label=label, position='h')\n",
    "\n",
    "    # Add in centering by replacing the first EOL with \"EOL + \\centering + EOL\"\n",
    "    output = output.replace('\\n','\\n\\centering\\n', 1)\n",
    "\n",
    "    # Add an hline learn the bottom above the total\n",
    "    output = output.replace('Total','\\hline\\nTotal', 1)\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "##############################################################\n",
    "output = create_table_of_SP_skims_statistics()\n",
    "\n",
    "print(output)\n",
    "print()\n",
    "\n",
    "# Write it out\n",
    "current_dir= os.getcwd()\n",
    "print(f\"Writing to {current_dir}\")\n",
    "directory = \"tables\"\n",
    "path= os.path.join(current_dir,directory)\n",
    "if os.path.isdir(path)== False:\n",
    "    os.mkdir(path)\n",
    "\n",
    "print(f\"Writing to {directory}\")\n",
    "\n",
    "outfilename = current_dir+\"/\"+directory+\"/table_SP_skim_statistics.tex\"\n",
    "outfile = open(outfilename,'w+')\n",
    "outfile.write(output)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2805bb67-551b-4f04-b19d-4f2e1fc041f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e35142-d920-450c-8e47-2dd3f06df683",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec240db-ccdc-4189-b30f-bb9e09524a17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe6c67e-9c37-4751-979f-7fc53e79772b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "832d8ef1-dcc9-4344-86d4-90c243a71f8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d5f0cd-c874-4b71-b91d-66df516b8470",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
